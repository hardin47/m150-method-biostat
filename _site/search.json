[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Schedule",
    "section": "",
    "text": "Here’s your roadmap for the semester! Each week, follow the general process outlined below:\n\nEnjoy the notes / text \nAttend class, review the warm-up and solutions if you have any questions after completing it during class.\nComplete the HW assignment ( pdf &  Rmd linked below),  submit the assignment via Gradescope accessed on the course Canvas site. HW is due weekly on Wednesday at 11:59pm.\nDiscuss the reflection questions  and ethics considerations  (see the  class notes) with your classmates, mentor, and professor.\nThe textbook is Practicing Statistics, by Kuiper and Sklar.\n\n\n\n\n\n\n\n\n \n  \n    date \n    agenda \n    readings \n    homework \n    article (Tues) \n    warm-ups \n  \n \n\n  \n    Week 1  1.17.23 \n    • t-tests + • SLR \n    Kuiper & Sklar: 2   introduction   t-test   t-test as SLR \n     \n     none   Emma Benn \n     WU 1   WU 2 \n  \n  \n    Week 2  1.24.23 \n    • SLR  • contingency analysis \n    Kuiper & Sklar: 2 & 6   SLR   Fisher's Exact Test   categorical analysis \n     HW1 pdf   HW1 Rmd   HW1 turn-in \n    A/B testing at Netflix   Rafael Irizarry \n     WU 3   WU 4 \n  \n  \n    Week 3  1.31.23 \n    • contingency analysis \n    Kuiper & Sklar: 6   types of studies   RR and CI   OR and CI \n     HW2 pdf   HW2 Rmd   HW2 turn-in \n    what is efficacy?  efficacy   Desi Small-Rodriguez \n     WU 5   WU 6 \n  \n  \n    Week 4  2.7.23 \n    • logistic regression \n    Kuiper & Sklar: 7   logistic regression   MLE \n     HW3 pdf   HW3 Rmd   HW3 turn-in \n    Obesity in Children Plummets   JAMA article here (see Table 6)   growth curves  David Blackwell \n     WU 7   WU 8 \n  \n  \n    Week 5  2.14.23 \n    • logistic regression \n    Kuiper & Sklar: 7   inference, logistic regression   multiple logistic regression \n     HW4 pdf   HW4 Rmd   HW4 turn-in \n    intersectional data   Kim Sellers \n     WU 9      Simpson's Paradox \n  \n  \n    Week 6  2.21.23 \n    • logistic regression \n    Kuiper & Sklar: 7   model process   cross validation   ROC \n     HW5 pdf   HW5 Rmd   HW5 turn-in \n    missing data   Robert Santos \n     WU 10   WU 11    tidymodels \n  \n  \n    Week 7  2.28.23 \n    • modeling \n     model building \n     HW6 pdf   HW6 Rmd   HW6 turn-in \n    many models   Jacqueline Hughes-Oliver \n     WU 12   WU 13     ROC + one variable building  variable handout \n  \n  \n    Week 8  3.7.23 \n    review & catch-up \n    exam 1 in class +  3.9.23 \n     HW7 pdf   HW7 Rmd  not due ever \n     see Canvas for sample exam 1 Q & sol \n     \n  \n  \n    3.14.23 \n    Spring Break \n     \n     \n     \n     \n  \n  \n    Week 9  3.21.23 \n    • survival analysis \n    Kuiper & Sklar: 9   time to event    KM curves   KM CI \n     \n    placebo effect (read abstract and Fig 3)   Alejandra Castillo \n     WU 14   WU 15  WU 16 \n  \n  \n    Week 10  3.28.23 \n    • survival analysis \n    Kuiper & Sklar: 9   log rank tests    hazard functions \n     HW8 pdf   HW8 Rmd   HW8 turn-in \n    Alzheimer's   Lester Mackey \n     \n  \n  \n    Week 11  4.4.23 \n    • survival analysis \n    Kuiper & Sklar: 9   Cox PH model    multiple Cox PH \n     \n    race-conscious medicine   Mike Dairyko \n     \n  \n  \n    Week 12  4.11.23 \n    • survival analysis \n    Kuiper & Sklar: 9   assessing PH    most published research \n     \n    most published research  science problems  abuse of power \n     \n  \n  \n    Week 13  4.18.23 \n    • multiple comparisons \n     multiple comparisons    false discovery rate   interim analyses \n     \n    pausing trials \n     \n  \n  \n    Week 14  4.25.23 \n    review & catch-up \n    exam 2 in class +  4.27.23 \n     \n     see Canvas for sample exam 2 Q & sol \n     \n  \n  \n    Week 15  5.2.23 \n    • Poisson regression \n    Kuiper & Sklar: 9   Poisson regression  \n     \n     \n     \n  \n  \n    Tuesday  5.9.23  2-5pm \n    Final Project  \n     \n     \n     \n     \n  \n\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "clicker_study.html",
    "href": "clicker_study.html",
    "title": "Methods in Biostatistics",
    "section": "",
    "text": "Clicker Q\nto go with Practicing Statistics by Kuiper & Sklar. Math 150 - Methods in Biostatistics.\n\n\n\n\n\nIn terms of the prerequisite for Math 150, Methods in Biostatistics, you should know at least a little bit (hopefully a lotta bit) about the following topics.\n\nHypothesis test, confidence interval, sample mean, central limit theorem, standard deviation, standard error of a statistics, p-value, t-test, chi-square test.1\n\nNever heard of it\nHeard of it, but don’t know anything about it\nKnow a little about it (or did once)\nKnow something about it\nConfident about it\n\n\n\nIn terms of the prerequisite for Math 150, Methods in Biostatisitcs, you do not need to know the following topics\n\nInteraction, simple linear regression, multiple linear regression, logistic regression, survival analysis, R.2\n\nNever heard of it\nHeard of it, but don’t know anything about it\nKnow a little about it (or did once)\nKnow something about it\nConfident about it\n\n\n\n\nThe Central Limit Theorem (CLT) says:3\n\nThe sample average (statistic) converges to the true average (parameter)\nThe sample average (statistic) converges to some point\nThe distribution of the sample average (statistic) converges to a normal distribution\nThe distribution of the sample average (statistic) converges to some distribution\nI have no idea what the CLT says\n\n\n\n\nThe p-value is the probability:4\n\nthat the null hypothesis is true given the observed data.\nof data as or more extreme than the observed data given that the null hypothesis is true.\n\n\n\n\nWhy do we use a t distribution (instead of a z / normal distribution) in the t-test?5\n\nthe technical conditions don’t hold\nthe means are quite variable\nwe like the letter t\nwe have two samples\nwe don’t know the true standard deviation parameter\n\n\n\n\nWhat happens if a t-test is used but isn’t appropriate (technical conditions don’t hold)?6\n\nthe p-value isn’t actually the probability of our data or more extreme if H0 is true.\nthe software won’t give a p-value as output\nthe rejection region needs to be calculated in the opposite direction\nthe world blows up\n\n\n\n\nWe use linear regression to run a test of means (\\(x_i = 0\\) for controls, group 1; \\(x_i = 1\\) for cases, group 2) What is: \\(\\sum_i x_i\\)?7\n\n\\(n\\)\n\\(n_1\\)\n\\(n_2\\)\n\\(n_1 \\cdot \\overline{y}_1\\)\n\\(n_2 \\cdot \\overline{y}_2\\)\n\n\n\n\nWe use linear regression to run a test of means (\\(x_i = 0\\) for controls, group 1; \\(x_i = 1\\) for cases, group 2) What is: \\(\\sum_i x_iy_i\\)?8\n\n\\(n\\)\n\\(n_1\\)\n\\(n_2\\)\n\\(n_1 \\cdot \\overline{y}_1\\)\n\\(n_2 \\cdot \\overline{y}_2\\)\n\n\n\n\nThe regression technical conditions include:9\n\nThe Y variable is normally distributed\nThe X variable is normally distributed\nThe residuals are normally distributed\nThe slope coefficient is normally distributed\nThe intercept coefficient is normally distributed\n\n\n\n\nWe need the technical conditions to hold in order to calculate \\(b_0\\) and \\(b_1.\\)10\n\nTRUE\nFALSE\nIt depends\n\n\n\n\nWhy do we check technical conditions?11\n\nso that the inference is valid\nso that the estimates are valid\nso that the p-value is more likely to be small\nso that the confidence level is right\nfor fun\n\n\n\n\nWhen writing the regression equation, why is there a hat ( ^) on the response variable?12\n\nbecause the prediction is an estimate\nbecause the prediction is an average\nbecause the prediction may be due to extrapolation\na & b\nall of the above\n\n\n\n\nWith a strong correlation and very small p-value, what can we conclude about happiness and life expectancy?13\n\nhappiness causes longer lives\nlonger lives cause happiness\nhappiness and longer life are correlated\nhappiness and longer life are perfectly predictive\nhappiness and longer life are unrelated\n\n\n\n\nIf there is no relationship in the population (true correlation = 0), then r = 0.14\n\nTRUE\nFALSE\n\n\n\n\nIf there is no relationship in the population (true slope \\(\\beta_1 = 0\\)), then \\(b_1=0\\).15\n\nTRUE\nFALSE\n\n\n\n\nSmaller variability around the regression line (\\(\\sigma\\)):16\n\nincreases the variability of \\(b_1\\).\ndecreases the variability of \\(b_1\\).\ndoesn’t necessarily change the variability of \\(b_1\\).\n\n\n\n\nSmaller variability in the explanatory variable (SD(X) = \\(s_X\\)):17\n\nincreases the variability of \\(b_1\\).\ndecreases the variability of \\(b_1\\).\ndoesn’t necessarily change the variability of \\(b_1\\).\n\n\n\n\nA smaller sample size (\\(n\\)):18\n\nincreases the variability of \\(b_1\\).\ndecreases the variability of \\(b_1\\).\ndoesn’t necessarily change the variability of \\(b_1\\).\n\n\n\n\nWe transform our variables…19\n\n… to find the highest \\(r^2\\) value.\n… when the X variable is not normally distributed.\n… to make the model easier to interpret.\n… so that the technical conditions are met.\n\n\n\n\nIn the Botox and Pain Relief example, the p-value is calculated. What does “probability” refer to?20\n\nrandom allocation\nrandom sample\n\n\n\np-value = probability of the observed data or more extreme given the null hypothesis is true.\n\n\n“Observed data or more extreme” is:21\n\nfewer than 9\n9 or fewer\n9 or more\nmore than 9\n\n\n\n\nWhat is the mean value of the null sampling distribution for the number of Botox therapy who showed pain reduction?22\n\n0\n9\n5.3\n11\n15\n\n\n\n\nWhat conclusion would you draw from the Back Pain and Botox study?23\n\nNot enough evidence to conclude that Botox is more effective than the placebo.\nStrong evidence that Botox is equally as effective as the placebo.\nStrong evidence that Botox is more effective than the placebo.\n\n\n\n\nIf we consider those in the study with back pain to be representative of all people with back pain, what would you conclude about the percentage of people who will have reduced back pain if they use Botox?24\n\nSubstantially greater than 50%\nSubstantially less than 50%\nClose to 50%\n\n\n\n\nMaterial check-in\n\nSo far, so good\nConcepts are good, R is confusing\nR is good, concepts are confusing\nEverything is confusing\n\n\n\n\nPeople check-in\n\nSo far, so good\nI can go to office hours / mentor sessions, but I didn’t happen to this week.\nI can’t make the scheduled office hours / mentor sessions\nI’m looking for someone to study with\n\n\n\nSee Canvas front page for anonymous survey / feedback for the class. Also, if you are looking for people to work with, you could contact me directly (non-anonymously!) so that I can connect you to people.\n\n\nSample 1,000,000 people who are over 6’ tall and 1,000,000 people who are under 6’ tall. Record if the person is in the NBA. What is measurable?25\n\nP(NBA if 6’ tall)\nP(6’ tall if in the NBA)\nboth\nneither\n\n\n\n\nSample 100 people who are in the NBA and 100 people who are not in the NBA. Record if the person is over 6’ tall. What is measurable?26\n\nP(NBA if 6’ tall)\nP(6’ tall if in the NBA)\nboth\nneither\n\n\n\n\nSample 10,000,000 people. Record their height and whether or not they are in the NBA. What is measurable?27\n\nP(NBA if 6’ tall)\nP(6’ tall if in the NBA)\nboth\nneither\n\n\n\n\nCalcium channel blockers have recently been reported to be associated with increased mortality. Cardiac patients who recently died of their heart disease were compared to control cardiac patients with similar disease who survive. Assume such a study had found that 40% of the recent cardiac deaths were taking calcium channel blockers at the time of death, as compared to 25% of the controls.28\n\nCase-control\nCohort\nCross-classification\n\n\n\n\nIt is well known that the use of urinary catheters conveys a substantial risk of urinary tract infection (UTI). A group of physicians believe that, in an intensive care setting, use of one particular type of urinary catheter is more likely to encourage infection than use of other types. They therefore review medical records over a recent period for all uses of urinary catheters in an ICU. They find that 200 new UTIs occurred during 1000 ICU patient-days of catheterization with the suspect type of catheter, as compared to 100 new UTIs during 5000 ICU-patient days of catheterization with all other types. Noting the increased frequency of new UTIs when the suspect catheter type is used, they regard their hypothesis as confirmed. To reduce nosocomial UTIs, they recommend discontinuing use of that type of catheter in the ICU.29\n\nCase-control\nCohort\nCross-classification\n\n\n\n\nWhen we select individuals based on the explanatory variable, we cannot accurately measure30\n\nthe proportion of people in the population in each explanatory category\nthe proportion of people in the population in each response group\nanything about the population\nconfounding variables\n\n\n\n\nRelative Risk is31\n\nthe difference of two proportions\nthe ratio of two proportions\nthe log of the ratio of two proportions\nthe log of the difference of two proportions\n\n\n\n\nThe odds ratio is “invariant to which variable is explanatory and which is response” means:32\n\nwe always put the bigger odds in the numerator\nwe must collect data so that we can estimate the response in the population\nwhich variable is called the explanatory changes the value of the OR\nwhich variable is called the explanatory does not change the value of the OR\n\n\n\n\nIn finding a CI for RR = p1/p2, why is it okay to exponentiate the end points of the interval for ln(p1/p2)?33\n\nBecause if ln(p1/p2) is in the original interval, p1/p2 will be in the exponentiated interval.\nBecause taking the natural log of the RR makes the distribution approximately normal.\nBecause the natural log compresses values that are bigger than 1 and spreads values that are smaller than 1.\nBecause we can get exact p-values using Fisher’s Exact Test.\n\n\n\n\nIn order to find a CI for the true OR, our steps are:34\n\n\nfind \\(\\widehat{\\ln(\\mbox{OR})}\\)\nadd \\(\\pm \\ z^* \\sqrt{\\frac{1}{n_1 \\hat{p}_1 (1-\\hat{p}_1)} + \\frac{1}{n_2 \\hat{p}_2 (1-\\hat{p}_2)}}\\)\ntake exp of the endpoints\n\n\nbecause the sampling distribution of \\(\\widehat{\\mbox{OR}}\\) is normal\nbecause OR is typically greater than 1\nbecause the \\(\\ln\\) transformation makes the sampling distribution almost normal\nbecause OR is invariant to the choice of explanatory or response variable\n\n\n\nI know where to find: the solutions to the warm-ups, the clicker questions (with solutions), and the HW solutions35\n\nTRUE\nFALSE\n\n\n\n\nAt the value \\(x = -\\beta_0 / \\beta_1\\), the probability of success is:36\n\n0\n0.5\n1\ndepends on \\(\\beta_0\\)\ndepends on \\(\\beta_1\\)\n\n\n\n\nThe logistic model gives probability of failure:37\n\n\\(\\frac{e^{\\beta_0+ \\beta_1 x}}{1+ e^{\\beta_0+ \\beta_1 x}}\\)\n\\(\\frac{1}{1+ e^{\\beta_0+ \\beta_1 x}}\\)\n\\(e^{\\beta_0+ \\beta_1 x}\\)\n\\(e^{-(\\beta_0+ \\beta_1 x)}\\)\n\\(\\beta_0+ \\beta_1 x\\)\n\n\n\n\nThe logistic model gives odds of success:38\n\n\\(\\frac{e^{\\beta_0+ \\beta_1 x}}{1+ e^{\\beta_0+ \\beta_1 x}}\\)\n\\(\\frac{1}{1+ e^{\\beta_0+ \\beta_1 x}}\\)\n\\(e^{\\beta_0+ \\beta_1 x}\\)\n\\(e^{-(\\beta_0+ \\beta_1 x)}\\)\n\\(\\beta_0+ \\beta_1 x\\)\n\n\n\n\nThe logistic model gives odds of failure:39\n\n\\(\\frac{e^{\\beta_0+ \\beta_1 x}}{1+ e^{\\beta_0+ \\beta_1 x}}\\)\n\\(\\frac{1}{1+ e^{\\beta_0+ \\beta_1 x}}\\)\n\\(e^{\\beta_0+ \\beta_1 x}\\)\n\\(e^{-(\\beta_0+ \\beta_1 x)}\\)\n\\(\\beta_0+ \\beta_1 x\\)\n\n\n\n\nWith a logistic regression model, the relative risk of success (for a one unit increase in X) is:40\n\n\\(- \\beta_0/\\beta_1\\)\n\\(\\beta_0+ \\beta_1 x\\)\n\\(e^{\\beta_0+ \\beta_1 x}\\)\na non-linear function of X (which depends on X )\n\n\n\n\nIf we want the relative risk of survival (for a one unit increase in X) to be independent of X, we should use which link:41\n\nlinear\nlogistic\ncomplementary log-log\nlog-linear\n\n\n\n\nYou take a sample of size 4 from a binary population and get: FSFF. (failure, success, failure, failure) What is your guess for p = P(success)?42\n\n0.05\n0.15\n0.25\n0.5\n0.75\n\n\n\n\nIn a logistic regression model, the variability is given by43\n\nNormal Y given X\nBinomial Y given X\nBernoulli Y given X\nPoisson Y given X\n\n\n\n\nWhen trying to find estimates for \\(\\beta_0\\) and \\(\\beta_1\\), we maximize the likelihood. \\[\\prod_{i=1}^n \\bigg(\\frac{e^{\\beta_0+ \\beta_1 x_i}}{1+ e^{\\beta_0+ \\beta_1 x_i}}\\bigg)^{y_i}\\bigg(\\frac{1}{1+ e^{\\beta_0+ \\beta_1 x_i}}\\bigg)^{1 - y_i}\\] Take the derivative with respect to which variable(s):44\n\nX\nY\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\\(\\beta_0\\) and \\(\\beta_1\\)\n\n\n\n\nMaximum likelihood estimation seeks to:45\n\nFind the data which are most likely under the model.\nFind the parameters which are most likely under the model.\nFind the parameters which make the data most likely under the model.\nFind the data which make the parameters most likely under the model.\n\n\n\n\nWe use maximum likelihood estimation because:46\n\nIt gives an principled approach for estimating the parameters.\nThe estimates are asymptotically normally distributed.\nThe estimates are always easy to compute.\nAll of the above.\nSome of the above.\n\n\n\n\nWe know that for a given data set (with MLEs of \\(b_0\\),\\(b_1\\)):47\n\n\\(L(b_0,b_1)< L(b_0,\\beta_1=0)\\) always\n\\(L(b_0,b_1)> L(b_0,\\beta_1=0)\\) always\n\\(L(b_0,b_1) \\leq L(b_0,\\beta_1=0)\\) always\n\\(L(b_0,b_1) \\geq L(b_0,\\beta_1=0)\\) always\n\n\n\n\nHow many parameters did we estimate in the HERS warm-up with the additive model?48\n\n1\n3\n4\n2757\n2761\n\n\n\n\nHow many parameters did we estimate in the HERS warm-up with the interaction model?49\n\n3\n4\n6\n7\n12\n\n\n\n\nWhat are the df for the LRT addressing whether interaction is needed in the HERS warm-up?50\n\n2\n3\n2760\n2754\n2757\n\n\n\n\n(Bird nest example) How many parameters do we estimate when considering Length as a categorical variable? (the only variable)51\n\n0\n1\n2\n33\n34\n\n\n\n\n(Bird nest example) How many df for the LRT addressing whether Length (as a categorical variable) belongs in the model?52\n\n0\n1\n2\n33\n34\n\n\n\n\n(Bird nest example) How many df for the LRT addressing whether Incubate and Color belong in the model (given Length is determined to be in the model)?53\n\n0\n1\n2\n3\n4\n\n\n\n\nAn interaction term in a multiple logistic regression model may be used when:54\n\nthe model fit is poor.\nthere is a quadratic relationship between the response and explanatory variables.\nneither one of two explanatory variables contribute significantly to the regression model.\nthe relationship between X1 and P(success) changes for differing values of X2.\n\n\n\n\nThe interpretations of the main effects (on their own) make sense only when the interaction component is not significant.55\n\nTRUE\nFALSE\n\n\n\n\nIf the interaction is significant but the main effects aren’t:56\n\nreport on the significance of the main effects\nremove the main effects from the model\navoid talking about main effects on their own\ntest whether the main effects are significant without interaction in the model\n\n\n\n\nWith two variables of interest, what should you test first?57\n\nVariable 1.\nVariable 2.\nThe interaction between variables 1 and 2.\nNone of the above.\n\n\n\n\nConsider variable 1 is continuous and variable 2 has 4 levels. How many degrees of freedom are associated with the drop in deviance test (LRT) of their overall interaction?58\n\n1\n2\n3\n4\n5\n\n\n\n\nWhen selecting variables, it is important that59\n\nThe model predicts training data well\nThe model predicts test data well\nThe coefficients on the variables are all significant\nThe relationships between the variables make sense\n\n\n\n\nTo get a sense of the true accuracy of the model, the test data should be assessed (for accuracy)60\n\non the first model only.\non the last model only.\non every model in the process.\n\n\n\n\nIf I am using all features of my dataset and I achieve 100% accuracy on my training set, but ~70% on testing set, what should I look out for?61\n\nUnderfitting\nNothing, the model is perfect\nOverfitting\n\n\n\n\nIf I am picking and choosing between features of my dataset and I achieve 30% accuracy on my training set, and ~30% on testing set, what should I look out for?62\n\nUnderfitting\nNothing, the model is perfect\nOverfitting\n\n\n\n\nCross validating will guarantee that the model does not overfit.63\n\nTRUE\nFALSE\n\n\n\n\nSuppose we want to compute 10-Fold Cross-Validation error on 200 training examples. We need to compute a model error rate N1 times, and the Cross-Validation error is the average of the errors. To compute each error, we need to train a model with data of size N2, and test the model on the data of size N3. What are the numbers for N1, N2, N3?64\n\nN1 = 1, N2 = 180, N3 = 20\nN1 = 10, N2 = 180, N3 = 20\nN1 = 10, N2 = 200, N3 = 20\nN1 = 10, N2 = 200, N3 = 200\nN1 = 20, N2 = 180, N3 = 20\n\n\n\n\nYou are reviewing papers for Fancy Conference, and you see submissions with the following claims. Which ones would you consider accepting?65\n\nMy method achieves a training error lower than all previous methods!\nMy method achieves a test error lower than all previous methods! (Footnote: When variables are chosen so as to min test error.)\nMy method achieves a test error lower than all previous methods! (Footnote: When variables are chosen so as to min CV error.)\nMy method achieves a CV error lower than all previous methods! (Footnote: When variables are chosen so as to min CV error.)\n\n\n\n\n\n\n\nWhich model is better (according to ROC)?66\n\npink because it goes closer to (1,1)\npink because it is closer to y=x\nblue because it is farther from y=x\nblue because it is steeper\nneither\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn ROC curve, the x-axis measures67\n\nTrue Pos Rate which we want high\nFalse Pos Rate which we want low\nTrue Neg Rate which we want high\nFalse Neg Rate which we want low\n\n\n\n\nQuiz on 11 topics (you know nothing). Your friends know topics:\nA: {1, 2, 3, 4, 5, 6, 7}\nB: {8, 9, 10}\nC: {1, 2, 3, 4, 8, 10}\nD: {5, 6, 7, 9, 11}\nWho should you choose to help you answer the questions?68\n\nA\nB\nC\nD\ncan’t tell\n\n\n\n\nWho do you want to choose next?69\nA: {1, 2, 3, 4, 5, 6, 7}\nB: {8, 9, 10}\nC: {1, 2, 3, 4, 8, 10}\nD: {5, 6, 7, 9, 11}\n\nA\nB\nC\nD\ncan’t tell\n\n\n\n\nIf you can pick two people, who do you pick?70\nA: {1, 2, 3, 4, 5, 6, 7}\nB: {8, 9, 10}\nC: {1, 2, 3, 4, 8, 10}\nD: {5, 6, 7, 9, 11}\n\nA, B\nA, C\nA, D\nC, B\nC, D\n\n\n\n\nThe variables in the k-variable model identified by forward selection are a subset of the variables in the (k+1)-variable model identified by forward selection.71\n\nTRUE (always TRUE)\nFALSE (not always TRUE)\n\n\n\n\nThe variables in the k-variable model identified by backward selection are a subset of the variables in the (k+1)-variable model identified by backward selection.72\n\nTRUE (always TRUE)\nFALSE (not always TRUE)\n\n\n\n\nThe variables in the k-variable model identified by backward selection are a subset of the variables in the (k+1)-variable model identified by forward selection.73\n\nTRUE (always TRUE)\nFALSE (not always TRUE)\n\n\n\n\nThe variables in the k-variable model identified by forward selection are a subset of the variables in the (k+1)-variable model identified by backward selection.74\n\nTRUE (always TRUE)\nFALSE (not always TRUE)\n\n\n\n\nThe variables in the k-variable model identified by best-subsets selection are a subset of the variables in the (k+1)-variable model identified by best-subsets selection.75\n\nTRUE (always TRUE)\nFALSE (not always TRUE)\n\n\n\n\nIn a drop-in-deviance test (LRT), the reduced model corresponds to the null hypothesis being true.76\n\nTRUE\nFALSE\n\n\n\n\nIn a drop-in-deviance test (LRT), the full model corresponds to the alternative hypothesis being true.77\n\nTRUE\nFALSE\n\n\n\n\nWith model building:78\n\nThere are many ways to find a good model.\nThere is always one right answer.\nThere is no end to the fun.\nCan we take a pure math class yet?\n\n\n\n\nWhen probability of being able to buy a candy bar is modeled as a function of the number of coins, the coefficient on number of coins is:79\n\npositive\nnegative\nzero\nno intuition exists for being able to answer this question\n\n\n\n\nWhen probability of being able to buy a candy bar is modeled as a function of the number of low coins, the coefficient on number of low coins is:80\n\npositive\nnegative\nzero\nno intuition exists for being able to answer this question\n\n\n\n\nWhen probability of being able to buy a candy bar is modeled as a function of the number of coins and number of low coins, the coefficient on number of coins is:81\n\npositive\nnegative\nzero\nno intuition exists for being able to answer this question\n\n\n\n\nWhen probability of being able to buy a candy bar is modeled as a function of the number of coins and number of low coins, the coefficient on number of low coins is:82\n\npositive\nnegative\nzero\nno intuition exists for being able to answer this question\n\n\n\n\nIf we consider the censored times to be event times, the empirical survival curve will (on average)83\n\nunderestimate the parameter\noverestimate the parameter\nsometimes under and sometimes overestimate the parameter\n\n\n\n\n\\(n_i - d_i = n_{i+1}\\) when:84\n\nthere are no deaths at time \\(t_i\\)\nthere is no censoring at time \\(t_i\\)\nthere are no deaths at time \\(t_{i+1}\\)\nthere is no censoring at time \\(t_{i+1}\\)\nthere is no censoring at time \\(t_{i-1}\\)\n\n\n\n\n\\(\\frac{(n_i - d_i)}{n_i} = 1\\) when:85\n\nthere are no deaths at time \\(t_i\\)\nthere is no censoring at time \\(t_i\\)\nthere are no deaths at time \\(t_{i+1}\\)\nthere is no censoring at time \\(t_{i+1}\\)\nthere is no censoring at time \\(t_{i-1}\\)\n\n\n\n\nProp survive > 50 days, treated (turquoise line)86\n\n~0.65\n~0.35\n~0.45\nwe only know it’s bigger than red\nwe only know it’s smaller than red\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKaplan Meier curves (Log-Rank p-value),87\n\nblue is clearly better\nred is clearly better\ncan’t tell because they cross\ncan’t tell because the p-value is big\ncan’t tell because the p-value is small\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe hazard at time \\(t\\) represents:88\n\nthe probability of the event\nthe instantaneous rate of the event\nthe relative risk of the event\nthe odds ratio of the event\n\n\n\n\nThe last entry in the table for the h(t) column is NA because:89\n\nthe last observation was a death\nthe last observation was censored\nthe time interval is too big\nthe time interval is too small\n\n\n\n\n\n\n\nTable 9.6 [@KuiperSklar]\n\n\n\n\n\n\nCensored observations are\\(\\ldots\\)?90\n\nMore important than non-censored ones in survival analysis\nAre assumed to be normally distributed over time\nAre assumed to have the same survival chances as uncensored observations\nAre essential to allow calculation of the Kaplan Meier plot\nAre allocated to the baseline survival curve\n\n\n\n\n\n\n\n\nFootnotes\n\n\npreferably d or e. maybe c on some of them.↩︎\nthese are the topics we will be covering. Would be nice if you have heard of them.↩︎\n\nThe distribution of the sample average (statistic) converges to a normal distribution\n\n↩︎\n\nof data as or more extreme than the observed data given that the null hypothesis is true.\n\n↩︎\n\nwe don’t know the true standard deviation parameter\n\n↩︎\n\nthe p-value isn’t actually the probability of our data or more extreme if H0 is true.\n\n↩︎\n\n\\(n_2\\)\n\n↩︎\n\n\\(n_2 \\cdot \\overline{y}_2\\)\n\n↩︎\n\nThe residuals are normally distributed (which induces a., d., and e.). There is nothing in the technical conditions about the distribution of X (remember, X can be binary!).\n\n↩︎\nFALSE. We can always minimize the sums of squares, regardless of whether or not the model is any good.↩︎\n\nso that the inference is valid (and also for fun). Note that d. so that the confidence level is right is also a correct answer because confidence intervals are all part of the “inference” paradigm.\n\n↩︎\n\ndue to estimation and average\n\n↩︎\n\nhappiness and longer life are correlated\n\n↩︎\n\nFALSE, there is no reason that the statistic will equal the parameter.\n\n↩︎\n\nFALSE, there is no reason that the statistic will equal the parameter.\n\n↩︎\n\ndecreases the variability of \\(b_1\\).\n\n↩︎\n\nincreases the variability of \\(b_1\\).\n\n↩︎\n\nincreases the variability of \\(b_1\\).\n\n↩︎\n\nso that the technical conditions are met.\n\n↩︎\n\nrandom allocation\n\n↩︎\n\n9 or more\n\n↩︎\n\n5.3 because (15/31)*11 = 5.3\n\n↩︎\n\nStrong evidence that Botox is more effective than the placebo.\n\n↩︎\n\nClose to 50% (the point estimate is 0.6)\n\n↩︎\n\nP(NBA if 6’ tall) (cohort: cannot measure the probability of the explanatory variable given the response)\n\n↩︎\n\nP(6’ tall if in the NBA) (case-control: cannot measure the probability of the response variable given a level of the explanatory variable)\n\n↩︎\n\nboth (cross-classification: can measure all the probabilities)\n\n↩︎\n\ncase-control (they selected based on people who had died or not)\n\n↩︎\n\ncross-classification (they selected all uses of catheters)\n\n↩︎\n\nthe proportion of people in the population in each explanatory category (tbh, we can’t measure b either, but we can measure the proportion of people in each response group, separated by the explanatory variable)\n\n↩︎\n\nthe ratio of two proportions\n\n↩︎\n\nwhich variable is called the explanatory does not change the value of the OR\n\n↩︎\n\nBecause if ln(p1/p2) is in the original interval, p1/p2 will be in the exponentiated interval.\n\n↩︎\n\nbecause the \\(\\ln\\) transformation makes the sampling distribution almost normal\n\n↩︎\nThe warm-up solutions and clicker questions are on the main course website. The HW solutions are on Canvas under Files.↩︎\n\n0.5\n\n↩︎\n\n\\(\\frac{1}{1+ e^{\\beta_0+ \\beta_1 x}}\\)\n\n↩︎\n\n\\(e^{\\beta_0+ \\beta_1 x}\\)\n\n↩︎\n\n\\(e^{-(\\beta_0+ \\beta_1 x)}\\)\n\n↩︎\n\na non-linear function of X (which depends on X )\n\n↩︎\n\nlog-linear\n\n↩︎\n\n0.25\n\n↩︎\n\nBernoulli Y given X\n\n↩︎\n\n\\(\\beta_0\\) and \\(\\beta_1\\)\n\n↩︎\n\nFind the parameters which make the data most likely under the model.\n\n↩︎\n\nSome of the above (a. It gives an principled approach for estimating the parameters. and b. The estimates are asymptotically normally distributed.)\n\n↩︎\n\n\\(L(b_0,b_1) \\geq L(b_0,\\beta_1=0)\\) always\n\n↩︎\n\n4 parameter estimates: \\(b_0, b_1, b_2, b_3\\)\n\n↩︎\n\n7 parameter estimates: \\(b_0, b_1, b_2, b_3, b_4, b_5, b_6\\)\n\n↩︎\n\n3 (7 - 4 = 3)\n\n↩︎\n\n34\n\n↩︎\n\n33 (34 - 1 = 33)\n\n↩︎\n\n2 (4 - 2 = 2)\n\n↩︎\n\nthe relationship between X1 and P(success) changes for differing values of X2.\n\n↩︎\n\nTRUE\n\n↩︎\n\navoid talking about main effects on their own\n\n↩︎\n\nThe interaction between variables 1 and 2. (probably… although there are many schools of thought on how to build models)\n\n↩︎\n\n3 (1 * (4-1) = 3)\n\n↩︎\n\nThe model predicts test data well\n\n↩︎\n\non the last model only.\n\n↩︎\n\noverfitting\n\n↩︎\n\nunderfitting\n\n↩︎\n\nFALSE. CV reduces the effect of overfitting, but at the end of the day, you are still building a model on the dataset at hand, and it is possible that you will overfit that dataet.\n\n↩︎\n\nN1 = 10, N2 = 180, N3 = 20\n\n↩︎\n\nMy method achieves a test error lower than all previous methods! (Footnote: When variables are chosen so as to min CV error.)\n\n↩︎\n\nblue because it is farther from the line y=x\n\n↩︎\n\nFalse Pos Rate which we want low\n\n↩︎\n\nA\n\n↩︎\n\nB\n\n↩︎\n\nC and D\n\n↩︎\n\nTRUE\n\n↩︎\n\nTRUE\n\n↩︎\n\nFALSE\n\n↩︎\n\nFALSE\n\n↩︎\n\nFALSE\n\n↩︎\n\nTRUE (the coefficient values are forced to be zero)\n\n↩︎\n\nFALSE (the null model can exist within the full model because there is flexibility in the values of the coefficients)\n\n↩︎\n\nThere are many ways to find a good model. Also, c. there is no end to the fun.\n\n↩︎\n\npositive\n\n↩︎\n\npositive\n\n↩︎\n\npositive\n\n↩︎\n\nnegative\n\n↩︎\n\nunderestimate the parameter\n\n↩︎\n\nthere is no censoring at time \\(t_i\\)\n\n↩︎\n\nthere are no deaths at time \\(t_i\\)\n\n↩︎\n\n~0.65\n\n↩︎\n\ncan’t tell because they cross (and also because d. the p-value is big)\n\n↩︎\n\nthe instantaneous rate of the event\n\n↩︎\n\nthe last observation was censored\n\n↩︎\n\nAre assumed to have the same survival chances as uncensored observations\n\n↩︎\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "syllabus",
    "section": "",
    "text": "Class: Tuesdays & Thursdays, 1:15-2:30pm\nJo Hardin\n2351 Estella\njo.hardin@pomona.edu\n\n\nMondays 1:30-3pm\nTuesdays 2:30-3:30pm\nWednesday 9-11am\nThursday 3-4pm\nor by appointment\n\n\nMonday 6-8pm\nWednesday 8-10pm\nEstella 2131\n\n\n\n\n\nArtwork by @allison_horst.\n\n\n\n\n\n\n\n\n\nMethods in Biostatistics is a second course in biostatistics, designed to follow either an Introduction to Statistics or Introduction to Biostatistics course. No biology background is needed, but examples and methods will be focused on those found in the life sciences. In particular, the main statistical topics covered include a logistic regression, survival analysis, and methods to ameliorate multiple comparison issues.\n\n\n\n\n\n\nAnonymous Feedback\n\n\n\nAs someone who is, myself, constantly learning and growing in many ways, I welcome your feedback about the course, the classroom dynamics, or anything else you’d like me to know. There is a link to an anonymous feedback form on the landing page of our Canvas webpage. Please provide me with feedback at any time!\n\n\n\n\n\nBy the end of the semester, students will be able to do the following:\n\nevaluate quantitative information with regards to clinical and biological data. We’ll be sure to keep in mind:\n\nCareful presentation of data\nConsideration of variability\nMeaningful comparisons\n\ncritically evaluate the medical literature with respect to design, analysis, and interpretation of results.\nunderstand the role of inherent variability and keep it in perspective when inferring results to a population.\ncritically evaluate medical results given in the mainstream media.\nread published studies with skepticism. Some people (in all fields!) wrongly believe that all studies published in a peer review publication must be 100% accurate and/or well designed studies. In this course, you will learn the tools to recognize, interpret, and critique statistical results in medical literature.\n\n\n\n\nIn an ideal world, science would be objective. However, much of science is subjective and is historically built on a small subset of privileged voices. In this class, we will make an effort to recognize how science (and statistics!) has played a role in both understanding diversity as well as in promoting systems of power and privilege. I acknowledge that there may be both overt and covert biases in the material due to the lens with which it was written, even though the material is primarily of a scientific nature. Integrating a diverse set of experiences is important for a more comprehensive understanding of science. I would like to discuss issues of diversity in statistics as part of the course from time to time.\nPlease contact me if you have any suggestions to improve the quality of the course materials.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities (including race, gender, class, sexuality, religion, ability, etc.) To help accomplish this:\n\nIf you have a name and/or set of pronouns that differ from those that appear in your official records, please let me know!\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. You can also relay information to me via your mentors. I want to be a resource for you. If you prefer to speak with someone outside of the course, the math liaisons, Dean of Students, or QSC staff are all excellent resources.\n\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it. As a participant in course discussions, you should also strive to honor the diversity of your classmates.\n\n\n\n\n\nPracticing Statistics, by Kuiper & Sklar\n\n\n\n\n\n\nExam dates\n\n\n\nExam 1 – Thursday, March 9th\nExam 2 – Thursday, April 27th\nFinal Project due – Tuesday, May 9th, 5pm\n\n\n\n\n\n\nEnough R\nR tutorial\nGreat tutorials through the Coding Club\nA true beginner’s introduction to the tidyverse, the introverse.\nfor a good start to R in general\nA fantastic ggplot2 tutorial\nGreat tutorials through the Coding Club\nGoogle for R\nsome R ideas that I wrote up\nIncredibly helpful cheatsheets from RStudio.\n\ndata wrangling\nggplot2\nR Markdown\nRStudio IDE\n\n\n\n\n\nR will be used for all homework assignments. You can use R on the Pomona server: https://rstudio.pomona.edu/ (All Pomona students will be able to log in immediately. Non-Pomona students need to get Pomona login information.)\nAlternatively, feel free to download R onto your own computer. R is freely available at http://www.r-project.org/ and is already installed on college computers. Additionally, you are required to install RStudio and turn in all R assignments using RMarkdown. http://rstudio.org/. (You can use the LaTeX compiler at: https://yihui.name/tinytex/)\n\n\n\nThis course uses Canvas as the main learning management system. The Canvas login is http://canvas.pomona.edu/. If you haven’t used Canvas before, I recommend bookmarking Canvas Student Guides and Canvas Student Videos for easy reference to tips and tutorials. If you run into an issue with Canvas, help is available.\n\nFrom anywhere in Canvas, select the Help button, located in the blue Global Navigation menu on the left.\n\nClick on Pomona Service Desk - Canvas Support to report a problem by submitting a service request ticket. Be sure to include “Canvas Issue” in your subject line.\nFor additional assistance, you can click on Ask Your Instructor or simply send me an email.\n\n\nPlease be proactive and reach out for help as soon as possible to resolve the issue you are experiencing.\n\n\n\n\n\n\nThe prerequisites for this class are Introductory Statistics (Math 58 or equivalent) and completion of one semester of calculus. We rely heavily on these prerequisites, and students with no background in statistics or very light mathematics background will find themselves trying to catch up throughout the semester. You should be familiar with topics such as probability, confidence intervals, hypothesis testing, p-values, linear regression.\n\n\n\nHomework will be assigned from the text and due every Wednesday at 11:59pm. One homework grade will be automatically dropped, so there are no late assignments. Homework will be turned in via Gradescope on Canvas.\n\n\n\nThere will be one project at the end of the semester based primarily on the survival analysis material. You will be able to work in pairs or alone. More information to come on the project.\n\n\n\nThroughout the semester, you will be challenged, and you may find yourself stuck. Every single one of us has been there, I promise. Below, I’ve provided Pomona’s academic honesty policy. But before the policy, I’ve given some thoughts on cheating which I have taken from Nick Ball’s CHEM 147 Collective (thank you, Prof Ball!). Prof Ball gives us all something to think about when we are learning in a classroom as well as on our journey to become scientists and professionals:\n\n\n\n\n\n\nWhy Cheat?\n\n\n\nThere are many known reasons why we may feel the need to “cheat” on problem sets or exams:\n\nAn academic environment that values grades above learning.\nFinancial aid is critical for remaining in school that places undue pressure on maintaining a high GPA.\nNavigating school, work, and/or family obligations that have diverted focus from class.\nChallenges balancing coursework and mental health.\nBalancing academic, family, peer, or personal issues.\n\nBeing accused of cheating – whether it has occurred or not – can be devastating for students. The college requires me to respond to potential academic dishonesty with a process that is very long and damaging. As your instructor, I care about you and want to offer alternatives to prevent us from having to go through this process.\n\n\nIf you find yourself in a situation where “cheating” seems like the only option, please come talk to me. We will figure this out together.\nPomona College is an academic community, all of whose members are expected to abide by ethical standards both in their conduct and in their exercise of responsibilities toward other members of the community. The college expects students to understand and adhere to basic standards of honesty and academic integrity. These standards include, but are not limited to, the following:\n\nIn projects and assignments prepared independently, students never represent the ideas or the language of others as their own.\nStudents do not destroy or alter either the work of other students or the educational resources and materials of the College.\nStudents neither give nor receive assistance in examinations.\nStudents do not take unfair advantage of fellow students by representing work completed for one course as original work for another or by deliberately disregarding course rules and regulations.\nIn laboratory or research projects involving the collection of data, students accurately report data observed and do not alter these data for any reason.\n\n\n\n\nPlease email and / or set up a time to talk if you have any questions about or difficulty with the material, the computing, or the course. Talk to me as soon as possible if you find yourself struggling. The material will build on itself, so it will be much easier to catch up if the concepts get clarified earlier rather than later. This semester is going to be fun. Let’s do it.\n\n\n\n\n\n\nGrading\n\n\n\n\n25% Homework\n50% Midterms\n20% Final Project\n5% Class Participation"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "clicker.html",
    "href": "clicker.html",
    "title": "Methods in Biostatistics",
    "section": "",
    "text": "Clicker Q\nto go with Practicing Statistics by Kuiper & Sklar. Math 150 - Methods in Biostatistics.\n\n\n\n\n\nIn terms of the prerequisite for Math 150, Methods in Biostatistics, you should know at least a little bit (hopefully a lotta bit) about the following topics.\n\nHypothesis test, confidence interval, sample mean, central limit theorem, standard deviation, standard error of a statistics, p-value, t-test, chi-square test.1\n\nNever heard of it\nHeard of it, but don’t know anything about it\nKnow a little about it (or did once)\nKnow something about it\nConfident about it\n\n\n\nIn terms of the prerequisite for Math 150, Methods in Biostatisitcs, you do not need to know the following topics\n\nInteraction, simple linear regression, multiple linear regression, logistic regression, survival analysis, R.2\n\nNever heard of it\nHeard of it, but don’t know anything about it\nKnow a little about it (or did once)\nKnow something about it\nConfident about it\n\n\n\n\nThe Central Limit Theorem (CLT) says:3\n\nThe sample average (statistic) converges to the true average (parameter)\nThe sample average (statistic) converges to some point\nThe distribution of the sample average (statistic) converges to a normal distribution\nThe distribution of the sample average (statistic) converges to some distribution\nI have no idea what the CLT says\n\n\n\n\nThe p-value is the probability:4\n\nthat the null hypothesis is true given the observed data.\nof data as or more extreme than the observed data given that the null hypothesis is true.\n\n\n\n\nWhy do we use a t distribution (instead of a z / normal distribution) in the t-test?5\n\nthe technical conditions don’t hold\nthe means are quite variable\nwe like the letter t\nwe have two samples\nwe don’t know the true standard deviation parameter\n\n\n\n\nWhat happens if a t-test is used but isn’t appropriate (technical conditions don’t hold)?6\n\nthe p-value isn’t actually the probability of our data or more extreme if H0 is true.\nthe software won’t give a p-value as output\nthe rejection region needs to be calculated in the opposite direction\nthe world blows up\n\n\n\n\nWe use linear regression to run a test of means (\\(x_i = 0\\) for controls, group 1; \\(x_i = 1\\) for cases, group 2) What is: \\(\\sum_i x_i\\)?7\n\n\\(n\\)\n\\(n_1\\)\n\\(n_2\\)\n\\(n_1 \\cdot \\overline{y}_1\\)\n\\(n_2 \\cdot \\overline{y}_2\\)\n\n\n\n\nWe use linear regression to run a test of means (\\(x_i = 0\\) for controls, group 1; \\(x_i = 1\\) for cases, group 2) What is: \\(\\sum_i x_iy_i\\)?8\n\n\\(n\\)\n\\(n_1\\)\n\\(n_2\\)\n\\(n_1 \\cdot \\overline{y}_1\\)\n\\(n_2 \\cdot \\overline{y}_2\\)\n\n\n\n\nThe regression technical conditions include:9\n\nThe Y variable is normally distributed\nThe X variable is normally distributed\nThe residuals are normally distributed\nThe slope coefficient is normally distributed\nThe intercept coefficient is normally distributed\n\n\n\n\nWe need the technical conditions to hold in order to calculate \\(b_0\\) and \\(b_1.\\)10\n\nTRUE\nFALSE\nIt depends\n\n\n\n\nWhy do we check technical conditions?11\n\nso that the inference is valid\nso that the estimates are valid\nso that the p-value is more likely to be small\nso that the confidence level is right\nfor fun\n\n\n\n\nWhen writing the regression equation, why is there a hat ( ^) on the response variable?12\n\nbecause the prediction is an estimate\nbecause the prediction is an average\nbecause the prediction may be due to extrapolation\na & b\nall of the above\n\n\n\n\nWith a strong correlation and very small p-value, what can we conclude about happiness and life expectancy?13\n\nhappiness causes longer lives\nlonger lives cause happiness\nhappiness and longer life are correlated\nhappiness and longer life are perfectly predictive\nhappiness and longer life are unrelated\n\n\n\n\nIf there is no relationship in the population (true correlation = 0), then r = 0.14\n\nTRUE\nFALSE\n\n\n\n\nIf there is no relationship in the population (true slope \\(\\beta_1 = 0\\)), then \\(b_1=0\\).15\n\nTRUE\nFALSE\n\n\n\n\nSmaller variability around the regression line (\\(\\sigma\\)):16\n\nincreases the variability of \\(b_1\\).\ndecreases the variability of \\(b_1\\).\ndoesn’t necessarily change the variability of \\(b_1\\).\n\n\n\n\nSmaller variability in the explanatory variable (SD(X) = \\(s_X\\)):17\n\nincreases the variability of \\(b_1\\).\ndecreases the variability of \\(b_1\\).\ndoesn’t necessarily change the variability of \\(b_1\\).\n\n\n\n\nA smaller sample size (\\(n\\)):18\n\nincreases the variability of \\(b_1\\).\ndecreases the variability of \\(b_1\\).\ndoesn’t necessarily change the variability of \\(b_1\\).\n\n\n\n\nWe transform our variables…19\n\n… to find the highest \\(r^2\\) value.\n… when the X variable is not normally distributed.\n… to make the model easier to interpret.\n… so that the technical conditions are met.\n\n\n\n\nIn the Botox and Pain Relief example, the p-value is calculated. What does “probability” refer to?20\n\nrandom allocation\nrandom sample\n\n\n\np-value = probability of the observed data or more extreme given the null hypothesis is true.\n\n\n“Observed data or more extreme” is:21\n\nfewer than 9\n9 or fewer\n9 or more\nmore than 9\n\n\n\n\nWhat is the mean value of the null sampling distribution for the number of Botox therapy who showed pain reduction?22\n\n0\n9\n5.3\n11\n15\n\n\n\n\nWhat conclusion would you draw from the Back Pain and Botox study?23\n\nNot enough evidence to conclude that Botox is more effective than the placebo.\nStrong evidence that Botox is equally as effective as the placebo.\nStrong evidence that Botox is more effective than the placebo.\n\n\n\n\nIf we consider those in the study with back pain to be representative of all people with back pain, what would you conclude about the percentage of people who will have reduced back pain if they use Botox?24\n\nSubstantially greater than 50%\nSubstantially less than 50%\nClose to 50%\n\n\n\n\nMaterial check-in\n\nSo far, so good\nConcepts are good, R is confusing\nR is good, concepts are confusing\nEverything is confusing\n\n\n\n\nPeople check-in\n\nSo far, so good\nI can go to office hours / mentor sessions, but I didn’t happen to this week.\nI can’t make the scheduled office hours / mentor sessions\nI’m looking for someone to study with\n\n\n\nSee Canvas front page for anonymous survey / feedback for the class. Also, if you are looking for people to work with, you could contact me directly (non-anonymously!) so that I can connect you to people.\n\n\nSample 1,000,000 people who are over 6’ tall and 1,000,000 people who are under 6’ tall. Record if the person is in the NBA. What is measurable?25\n\nP(NBA if 6’ tall)\nP(6’ tall if in the NBA)\nboth\nneither\n\n\n\n\nSample 100 people who are in the NBA and 100 people who are not in the NBA. Record if the person is over 6’ tall. What is measurable?26\n\nP(NBA if 6’ tall)\nP(6’ tall if in the NBA)\nboth\nneither\n\n\n\n\nSample 10,000,000 people. Record their height and whether or not they are in the NBA. What is measurable?27\n\nP(NBA if 6’ tall)\nP(6’ tall if in the NBA)\nboth\nneither\n\n\n\n\nCalcium channel blockers have recently been reported to be associated with increased mortality. Cardiac patients who recently died of their heart disease were compared to control cardiac patients with similar disease who survive. Assume such a study had found that 40% of the recent cardiac deaths were taking calcium channel blockers at the time of death, as compared to 25% of the controls.28\n\nCase-control\nCohort\nCross-classification\n\n\n\n\nIt is well known that the use of urinary catheters conveys a substantial risk of urinary tract infection (UTI). A group of physicians believe that, in an intensive care setting, use of one particular type of urinary catheter is more likely to encourage infection than use of other types. They therefore review medical records over a recent period for all uses of urinary catheters in an ICU. They find that 200 new UTIs occurred during 1000 ICU patient-days of catheterization with the suspect type of catheter, as compared to 100 new UTIs during 5000 ICU-patient days of catheterization with all other types. Noting the increased frequency of new UTIs when the suspect catheter type is used, they regard their hypothesis as confirmed. To reduce nosocomial UTIs, they recommend discontinuing use of that type of catheter in the ICU.29\n\nCase-control\nCohort\nCross-classification\n\n\n\n\nWhen we select individuals based on the explanatory variable, we cannot accurately measure30\n\nthe proportion of people in the population in each explanatory category\nthe proportion of people in the population in each response group\nanything about the population\nconfounding variables\n\n\n\n\nRelative Risk is31\n\nthe difference of two proportions\nthe ratio of two proportions\nthe log of the ratio of two proportions\nthe log of the difference of two proportions\n\n\n\n\nThe odds ratio is “invariant to which variable is explanatory and which is response” means:32\n\nwe always put the bigger odds in the numerator\nwe must collect data so that we can estimate the response in the population\nwhich variable is called the explanatory changes the value of the OR\nwhich variable is called the explanatory does not change the value of the OR\n\n\n\n\nIn finding a CI for RR = p1/p2, why is it okay to exponentiate the end points of the interval for ln(p1/p2)?33\n\nBecause if ln(p1/p2) is in the original interval, p1/p2 will be in the exponentiated interval.\nBecause taking the natural log of the RR makes the distribution approximately normal.\nBecause the natural log compresses values that are bigger than 1 and spreads values that are smaller than 1.\nBecause we can get exact p-values using Fisher’s Exact Test.\n\n\n\n\nIn order to find a CI for the true OR, our steps are:34\n\n\nfind \\(\\widehat{\\ln(\\mbox{OR})}\\)\nadd \\(\\pm \\ z^* \\sqrt{\\frac{1}{n_1 \\hat{p}_1 (1-\\hat{p}_1)} + \\frac{1}{n_2 \\hat{p}_2 (1-\\hat{p}_2)}}\\)\ntake exp of the endpoints\n\n\nbecause the sampling distribution of \\(\\widehat{\\mbox{OR}}\\) is normal\nbecause OR is typically greater than 1\nbecause the \\(\\ln\\) transformation makes the sampling distribution almost normal\nbecause OR is invariant to the choice of explanatory or response variable\n\n\n\nI know where to find: the solutions to the warm-ups, the clicker questions (with solutions), and the HW solutions35\n\nTRUE\nFALSE\n\n\n\n\nAt the value \\(x = -\\beta_0 / \\beta_1\\), the probability of success is:36\n\n0\n0.5\n1\ndepends on \\(\\beta_0\\)\ndepends on \\(\\beta_1\\)\n\n\n\n\nThe logistic model gives probability of failure:37\n\n\\(\\frac{e^{\\beta_0+ \\beta_1 x}}{1+ e^{\\beta_0+ \\beta_1 x}}\\)\n\\(\\frac{1}{1+ e^{\\beta_0+ \\beta_1 x}}\\)\n\\(e^{\\beta_0+ \\beta_1 x}\\)\n\\(e^{-(\\beta_0+ \\beta_1 x)}\\)\n\\(\\beta_0+ \\beta_1 x\\)\n\n\n\n\nThe logistic model gives odds of success:38\n\n\\(\\frac{e^{\\beta_0+ \\beta_1 x}}{1+ e^{\\beta_0+ \\beta_1 x}}\\)\n\\(\\frac{1}{1+ e^{\\beta_0+ \\beta_1 x}}\\)\n\\(e^{\\beta_0+ \\beta_1 x}\\)\n\\(e^{-(\\beta_0+ \\beta_1 x)}\\)\n\\(\\beta_0+ \\beta_1 x\\)\n\n\n\n\nThe logistic model gives odds of failure:39\n\n\\(\\frac{e^{\\beta_0+ \\beta_1 x}}{1+ e^{\\beta_0+ \\beta_1 x}}\\)\n\\(\\frac{1}{1+ e^{\\beta_0+ \\beta_1 x}}\\)\n\\(e^{\\beta_0+ \\beta_1 x}\\)\n\\(e^{-(\\beta_0+ \\beta_1 x)}\\)\n\\(\\beta_0+ \\beta_1 x\\)\n\n\n\n\nWith a logistic regression model, the relative risk of success (for a one unit increase in X) is:40\n\n\\(- \\beta_0/\\beta_1\\)\n\\(\\beta_0+ \\beta_1 x\\)\n\\(e^{\\beta_0+ \\beta_1 x}\\)\na non-linear function of X (which depends on X )\n\n\n\n\nIf we want the relative risk of survival (for a one unit increase in X) to be independent of X, we should use which link:41\n\nlinear\nlogistic\ncomplementary log-log\nlog-linear\n\n\n\n\nYou take a sample of size 4 from a binary population and get: FSFF. (failure, success, failure, failure) What is your guess for p = P(success)?42\n\n0.05\n0.15\n0.25\n0.5\n0.75\n\n\n\n\nIn a logistic regression model, the variability is given by43\n\nNormal Y given X\nBinomial Y given X\nBernoulli Y given X\nPoisson Y given X\n\n\n\n\nWhen trying to find estimates for \\(\\beta_0\\) and \\(\\beta_1\\), we maximize the likelihood. \\[\\prod_{i=1}^n \\bigg(\\frac{e^{\\beta_0+ \\beta_1 x_i}}{1+ e^{\\beta_0+ \\beta_1 x_i}}\\bigg)^{y_i}\\bigg(\\frac{1}{1+ e^{\\beta_0+ \\beta_1 x_i}}\\bigg)^{1 - y_i}\\] Take the derivative with respect to which variable(s):44\n\nX\nY\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\\(\\beta_0\\) and \\(\\beta_1\\)\n\n\n\n\nMaximum likelihood estimation seeks to:45\n\nFind the data which are most likely under the model.\nFind the parameters which are most likely under the model.\nFind the parameters which make the data most likely under the model.\nFind the data which make the parameters most likely under the model.\n\n\n\n\nWe use maximum likelihood estimation because:46\n\nIt gives an principled approach for estimating the parameters.\nThe estimates are asymptotically normally distributed.\nThe estimates are always easy to compute.\nAll of the above.\nSome of the above.\n\n\n\n\nWe know that for a given data set (with MLEs of \\(b_0\\),\\(b_1\\)):47\n\n\\(L(b_0,b_1)< L(b_0,\\beta_1=0)\\) always\n\\(L(b_0,b_1)> L(b_0,\\beta_1=0)\\) always\n\\(L(b_0,b_1) \\leq L(b_0,\\beta_1=0)\\) always\n\\(L(b_0,b_1) \\geq L(b_0,\\beta_1=0)\\) always\n\n\n\n\nHow many parameters did we estimate in the HERS warm-up with the additive model?48\n\n1\n3\n4\n2757\n2761\n\n\n\n\nHow many parameters did we estimate in the HERS warm-up with the interaction model?49\n\n3\n4\n6\n7\n12\n\n\n\n\nWhat are the df for the LRT addressing whether interaction is needed in the HERS warm-up?50\n\n2\n3\n2760\n2754\n2757\n\n\n\n\n(Bird nest example) How many parameters do we estimate when considering Length as a categorical variable? (the only variable)51\n\n0\n1\n2\n33\n34\n\n\n\n\n(Bird nest example) How many df for the LRT addressing whether Length (as a categorical variable) belongs in the model?52\n\n0\n1\n2\n33\n34\n\n\n\n\n(Bird nest example) How many df for the LRT addressing whether Incubate and Color belong in the model (given Length is determined to be in the model)?53\n\n0\n1\n2\n3\n4\n\n\n\n\nAn interaction term in a multiple logistic regression model may be used when:54\n\nthe model fit is poor.\nthere is a quadratic relationship between the response and explanatory variables.\nneither one of two explanatory variables contribute significantly to the regression model.\nthe relationship between X1 and P(success) changes for differing values of X2.\n\n\n\n\nThe interpretations of the main effects (on their own) make sense only when the interaction component is not significant.55\n\nTRUE\nFALSE\n\n\n\n\nIf the interaction is significant but the main effects aren’t:56\n\nreport on the significance of the main effects\nremove the main effects from the model\navoid talking about main effects on their own\ntest whether the main effects are significant without interaction in the model\n\n\n\n\nWith two variables of interest, what should you test first?57\n\nVariable 1.\nVariable 2.\nThe interaction between variables 1 and 2.\nNone of the above.\n\n\n\n\nConsider variable 1 is continuous and variable 2 has 4 levels. How many degrees of freedom are associated with the drop in deviance test (LRT) of their overall interaction?58\n\n1\n2\n3\n4\n5\n\n\n\n\nWhen selecting variables, it is important that59\n\nThe model predicts training data well\nThe model predicts test data well\nThe coefficients on the variables are all significant\nThe relationships between the variables make sense\n\n\n\n\nTo get a sense of the true accuracy of the model, the test data should be assessed (for accuracy)60\n\non the first model only.\non the last model only.\non every model in the process.\n\n\n\n\nIf I am using all features of my dataset and I achieve 100% accuracy on my training set, but ~70% on testing set, what should I look out for?61\n\nUnderfitting\nNothing, the model is perfect\nOverfitting\n\n\n\n\nIf I am picking and choosing between features of my dataset and I achieve 30% accuracy on my training set, and ~30% on testing set, what should I look out for?62\n\nUnderfitting\nNothing, the model is perfect\nOverfitting\n\n\n\n\nCross validating will guarantee that the model does not overfit.63\n\nTRUE\nFALSE\n\n\n\n\nSuppose we want to compute 10-Fold Cross-Validation error on 200 training examples. We need to compute a model error rate N1 times, and the Cross-Validation error is the average of the errors. To compute each error, we need to train a model with data of size N2, and test the model on the data of size N3. What are the numbers for N1, N2, N3?64\n\nN1 = 1, N2 = 180, N3 = 20\nN1 = 10, N2 = 180, N3 = 20\nN1 = 10, N2 = 200, N3 = 20\nN1 = 10, N2 = 200, N3 = 200\nN1 = 20, N2 = 180, N3 = 20\n\n\n\n\nYou are reviewing papers for Fancy Conference, and you see submissions with the following claims. Which ones would you consider accepting?65\n\nMy method achieves a training error lower than all previous methods!\nMy method achieves a test error lower than all previous methods! (Footnote: When variables are chosen so as to min test error.)\nMy method achieves a test error lower than all previous methods! (Footnote: When variables are chosen so as to min CV error.)\nMy method achieves a CV error lower than all previous methods! (Footnote: When variables are chosen so as to min CV error.)\n\n\n\n\n\n\n\nWhich model is better (according to ROC)?66\n\npink because it goes closer to (1,1)\npink because it is closer to y=x\nblue because it is farther from y=x\nblue because it is steeper\nneither\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn ROC curve, the x-axis measures67\n\nTrue Pos Rate which we want high\nFalse Pos Rate which we want low\nTrue Neg Rate which we want high\nFalse Neg Rate which we want low\n\n\n\n\nQuiz on 11 topics (you know nothing). Your friends know topics:\nA: {1, 2, 3, 4, 5, 6, 7}\nB: {8, 9, 10}\nC: {1, 2, 3, 4, 8, 10}\nD: {5, 6, 7, 9, 11}\nWho should you choose to help you answer the questions?68\n\nA\nB\nC\nD\ncan’t tell\n\n\n\n\nWho do you want to choose next?69\nA: {1, 2, 3, 4, 5, 6, 7}\nB: {8, 9, 10}\nC: {1, 2, 3, 4, 8, 10}\nD: {5, 6, 7, 9, 11}\n\nA\nB\nC\nD\ncan’t tell\n\n\n\n\nIf you can pick two people, who do you pick?70\nA: {1, 2, 3, 4, 5, 6, 7}\nB: {8, 9, 10}\nC: {1, 2, 3, 4, 8, 10}\nD: {5, 6, 7, 9, 11}\n\nA, B\nA, C\nA, D\nC, B\nC, D\n\n\n\n\nThe variables in the k-variable model identified by forward selection are a subset of the variables in the (k+1)-variable model identified by forward selection.71\n\nTRUE (always TRUE)\nFALSE (not always TRUE)\n\n\n\n\nThe variables in the k-variable model identified by backward selection are a subset of the variables in the (k+1)-variable model identified by backward selection.72\n\nTRUE (always TRUE)\nFALSE (not always TRUE)\n\n\n\n\nThe variables in the k-variable model identified by backward selection are a subset of the variables in the (k+1)-variable model identified by forward selection.73\n\nTRUE (always TRUE)\nFALSE (not always TRUE)\n\n\n\n\nThe variables in the k-variable model identified by forward selection are a subset of the variables in the (k+1)-variable model identified by backward selection.74\n\nTRUE (always TRUE)\nFALSE (not always TRUE)\n\n\n\n\nThe variables in the k-variable model identified by best-subsets selection are a subset of the variables in the (k+1)-variable model identified by best-subsets selection.75\n\nTRUE (always TRUE)\nFALSE (not always TRUE)\n\n\n\n\nIn a drop-in-deviance test (LRT), the reduced model corresponds to the null hypothesis being true.76\n\nTRUE\nFALSE\n\n\n\n\nIn a drop-in-deviance test (LRT), the full model corresponds to the alternative hypothesis being true.77\n\nTRUE\nFALSE\n\n\n\n\nWith model building:78\n\nThere are many ways to find a good model.\nThere is always one right answer.\nThere is no end to the fun.\nCan we take a pure math class yet?\n\n\n\n\nWhen probability of being able to buy a candy bar is modeled as a function of the number of coins, the coefficient on number of coins is:79\n\npositive\nnegative\nzero\nno intuition exists for being able to answer this question\n\n\n\n\nWhen probability of being able to buy a candy bar is modeled as a function of the number of low coins, the coefficient on number of low coins is:80\n\npositive\nnegative\nzero\nno intuition exists for being able to answer this question\n\n\n\n\nWhen probability of being able to buy a candy bar is modeled as a function of the number of coins and number of low coins, the coefficient on number of coins is:81\n\npositive\nnegative\nzero\nno intuition exists for being able to answer this question\n\n\n\n\nWhen probability of being able to buy a candy bar is modeled as a function of the number of coins and number of low coins, the coefficient on number of low coins is:82\n\npositive\nnegative\nzero\nno intuition exists for being able to answer this question\n\n\n\n\nIf we consider the censored times to be event times, the empirical survival curve will (on average)83\n\nunderestimate the parameter\noverestimate the parameter\nsometimes under and sometimes overestimate the parameter\n\n\n\n\n\\(n_i - d_i = n_{i+1}\\) when:84\n\nthere are no deaths at time \\(t_i\\)\nthere is no censoring at time \\(t_i\\)\nthere are no deaths at time \\(t_{i+1}\\)\nthere is no censoring at time \\(t_{i+1}\\)\nthere is no censoring at time \\(t_{i-1}\\)\n\n\n\n\n\\(\\frac{(n_i - d_i)}{n_i} = 1\\) when:85\n\nthere are no deaths at time \\(t_i\\)\nthere is no censoring at time \\(t_i\\)\nthere are no deaths at time \\(t_{i+1}\\)\nthere is no censoring at time \\(t_{i+1}\\)\nthere is no censoring at time \\(t_{i-1}\\)\n\n\n\n\nProp survive > 50 days, treated (turquoise line)86\n\n~0.65\n~0.35\n~0.45\nwe only know it’s bigger than red\nwe only know it’s smaller than red\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKaplan Meier curves (Log-Rank p-value),87\n\nblue is clearly better\nred is clearly better\ncan’t tell because they cross\ncan’t tell because the p-value is big\ncan’t tell because the p-value is small\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe hazard at time \\(t\\) represents:88\n\nthe probability of the event\nthe instantaneous rate of the event\nthe relative risk of the event\nthe odds ratio of the event\n\n\n\n\nThe last entry in the table for the h(t) column is NA because:89\n\nthe last observation was a death\nthe last observation was censored\nthe time interval is too big\nthe time interval is too small\n\n\n\n\n\n\n\nTable 9.6 [@KuiperSklar]\n\n\n\n\n\n\nCensored observations are\\(\\ldots\\)?90\n\nMore important than non-censored ones in survival analysis\nAre assumed to be normally distributed over time\nAre assumed to have the same survival chances as uncensored observations\nAre essential to allow calculation of the Kaplan Meier plot\nAre allocated to the baseline survival curve\n\n\n\n\n\n\n\n\nFootnotes\n\n\npreferably d or e. maybe c on some of them.↩︎\nthese are the topics we will be covering. Would be nice if you have heard of them.↩︎\n\nThe distribution of the sample average (statistic) converges to a normal distribution\n\n↩︎\n\nof data as or more extreme than the observed data given that the null hypothesis is true.\n\n↩︎\n\nwe don’t know the true standard deviation parameter\n\n↩︎\n\nthe p-value isn’t actually the probability of our data or more extreme if H0 is true.\n\n↩︎\n\n\\(n_2\\)\n\n↩︎\n\n\\(n_2 \\cdot \\overline{y}_2\\)\n\n↩︎\n\nThe residuals are normally distributed (which induces a., d., and e.). There is nothing in the technical conditions about the distribution of X (remember, X can be binary!).\n\n↩︎\nFALSE. We can always minimize the sums of squares, regardless of whether or not the model is any good.↩︎\n\nso that the inference is valid (and also for fun). Note that d. so that the confidence level is right is also a correct answer because confidence intervals are all part of the “inference” paradigm.\n\n↩︎\n\ndue to estimation and average\n\n↩︎\n\nhappiness and longer life are correlated\n\n↩︎\n\nFALSE, there is no reason that the statistic will equal the parameter.\n\n↩︎\n\nFALSE, there is no reason that the statistic will equal the parameter.\n\n↩︎\n\ndecreases the variability of \\(b_1\\).\n\n↩︎\n\nincreases the variability of \\(b_1\\).\n\n↩︎\n\nincreases the variability of \\(b_1\\).\n\n↩︎\n\nso that the technical conditions are met.\n\n↩︎\n\nrandom allocation\n\n↩︎\n\n9 or more\n\n↩︎\n\n5.3 because (15/31)*11 = 5.3\n\n↩︎\n\nStrong evidence that Botox is more effective than the placebo.\n\n↩︎\n\nClose to 50% (the point estimate is 0.6)\n\n↩︎\n\nP(NBA if 6’ tall) (cohort: cannot measure the probability of the explanatory variable given the response)\n\n↩︎\n\nP(6’ tall if in the NBA) (case-control: cannot measure the probability of the response variable given a level of the explanatory variable)\n\n↩︎\n\nboth (cross-classification: can measure all the probabilities)\n\n↩︎\n\ncase-control (they selected based on people who had died or not)\n\n↩︎\n\ncross-classification (they selected all uses of catheters)\n\n↩︎\n\nthe proportion of people in the population in each explanatory category (tbh, we can’t measure b either, but we can measure the proportion of people in each response group, separated by the explanatory variable)\n\n↩︎\n\nthe ratio of two proportions\n\n↩︎\n\nwhich variable is called the explanatory does not change the value of the OR\n\n↩︎\n\nBecause if ln(p1/p2) is in the original interval, p1/p2 will be in the exponentiated interval.\n\n↩︎\n\nbecause the \\(\\ln\\) transformation makes the sampling distribution almost normal\n\n↩︎\nThe warm-up solutions and clicker questions are on the main course website. The HW solutions are on Canvas under Files.↩︎\n\n0.5\n\n↩︎\n\n\\(\\frac{1}{1+ e^{\\beta_0+ \\beta_1 x}}\\)\n\n↩︎\n\n\\(e^{\\beta_0+ \\beta_1 x}\\)\n\n↩︎\n\n\\(e^{-(\\beta_0+ \\beta_1 x)}\\)\n\n↩︎\n\na non-linear function of X (which depends on X )\n\n↩︎\n\nlog-linear\n\n↩︎\n\n0.25\n\n↩︎\n\nBernoulli Y given X\n\n↩︎\n\n\\(\\beta_0\\) and \\(\\beta_1\\)\n\n↩︎\n\nFind the parameters which make the data most likely under the model.\n\n↩︎\n\nSome of the above (a. It gives an principled approach for estimating the parameters. and b. The estimates are asymptotically normally distributed.)\n\n↩︎\n\n\\(L(b_0,b_1) \\geq L(b_0,\\beta_1=0)\\) always\n\n↩︎\n\n4 parameter estimates: \\(b_0, b_1, b_2, b_3\\)\n\n↩︎\n\n7 parameter estimates: \\(b_0, b_1, b_2, b_3, b_4, b_5, b_6\\)\n\n↩︎\n\n3 (7 - 4 = 3)\n\n↩︎\n\n34\n\n↩︎\n\n33 (34 - 1 = 33)\n\n↩︎\n\n2 (4 - 2 = 2)\n\n↩︎\n\nthe relationship between X1 and P(success) changes for differing values of X2.\n\n↩︎\n\nTRUE\n\n↩︎\n\navoid talking about main effects on their own\n\n↩︎\n\nThe interaction between variables 1 and 2. (probably… although there are many schools of thought on how to build models)\n\n↩︎\n\n3 (1 * (4-1) = 3)\n\n↩︎\n\nThe model predicts test data well\n\n↩︎\n\non the last model only.\n\n↩︎\n\noverfitting\n\n↩︎\n\nunderfitting\n\n↩︎\n\nFALSE. CV reduces the effect of overfitting, but at the end of the day, you are still building a model on the dataset at hand, and it is possible that you will overfit that dataet.\n\n↩︎\n\nN1 = 10, N2 = 180, N3 = 20\n\n↩︎\n\nMy method achieves a test error lower than all previous methods! (Footnote: When variables are chosen so as to min CV error.)\n\n↩︎\n\nblue because it is farther from the line y=x\n\n↩︎\n\nFalse Pos Rate which we want low\n\n↩︎\n\nA\n\n↩︎\n\nB\n\n↩︎\n\nC and D\n\n↩︎\n\nTRUE\n\n↩︎\n\nTRUE\n\n↩︎\n\nFALSE\n\n↩︎\n\nFALSE\n\n↩︎\n\nFALSE\n\n↩︎\n\nTRUE (the coefficient values are forced to be zero)\n\n↩︎\n\nFALSE (the null model can exist within the full model because there is flexibility in the values of the coefficients)\n\n↩︎\n\nThere are many ways to find a good model. Also, c. there is no end to the fun.\n\n↩︎\n\npositive\n\n↩︎\n\npositive\n\n↩︎\n\npositive\n\n↩︎\n\nnegative\n\n↩︎\n\nunderestimate the parameter\n\n↩︎\n\nthere is no censoring at time \\(t_i\\)\n\n↩︎\n\nthere are no deaths at time \\(t_i\\)\n\n↩︎\n\n~0.65\n\n↩︎\n\ncan’t tell because they cross (and also because d. the p-value is big)\n\n↩︎\n\nthe instantaneous rate of the event\n\n↩︎\n\nthe last observation was censored\n\n↩︎\n\nAre assumed to have the same survival chances as uncensored observations\n\n↩︎\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "Class notes can be found at http://st47s.com/Math150/Notes/.\n\n\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "handout/HW1_m150_s23.html",
    "href": "handout/HW1_m150_s23.html",
    "title": "Math 150 - Methods in Biostatistics - Homework 1",
    "section": "",
    "text": "Practice using R to run t-tests and linear models\nProvide details about what the models mean\n\n\n\nAt the bottom of this assignment, I’ve given an R Tutorial of sorts with some of the main ideas that we’ll be using this semester. You might want to read over them and try out some of the commands yourself.\nPlease ask questions as you go along! Asking questions about the R code (and about the course in general) is your key to success.\n\nLook carefully at the line of code in the R chunk immediately below. Notice that a dataset from the textbook is being loaded in so that it can be analyzed. The datasets for the textbook are all provided to you on Canvas. You’ll need to get the data from Canvas (the file for this HW is called C2 Games1.csv), and copy it either to your own computer or to the file system on the Pomona R Server (if you are using the server). Then you need to point to the location of that dataset.\nIf it is difficult to find the location, look at the upper right side of the R Studio window for the icon that says Import Dataset. By clicking through, import the dataset into R. But wait, you aren’t done! After you import the data, you’ll see the correct path in the Console. That path must be written into the R chunk which imports the data.\nYou will know that you have successfully imported the data if you can knit this file to a pdf without any errors. After you’ve imported the data (and before you move on to the rest of the assignment), try to knit to pdf. Does it work? Great! Does it not work? Read the paragraph above again (then ask questions on Slack).\n\ngames1 <- readr::read_csv(\"~/Dropbox/teaching/MA150/PracStatCD/Data Sets/Chapter 02/CSV Files/C2 Games1.csv\")\n\n\n\n\nDescribe one thing you learned from someone (a fellow student or mentor) in our class this week (it could be: content, logistical help, background material, R information, etc.) 1-3 sentences.\n\n\n\nUse R to calculate a two-sample test statistic (assuming equal variances) and find the p-value corresponding to this statistic. In addition, calculate a 95% confidence interval for the difference between the two means (\\(\\mu_1 - \\mu_2\\)). The end of chapter exercises will provide details on conducting this calculation by hand. If \\(H_0: \\mu_1 = \\mu_2\\) is true, the p-value states how likely that just random sampling variability would create a difference between two sample means (\\(\\overline{y}_1 - \\overline{y}_2\\)) at least as large as we observed. Based on the p-value, what can you conclude about these two types of games?\ngames1 %>%\n    t.test(Time ~ Type, data=., var.equal = TRUE)\n\ngames1 %>%\n    t.test(Time ~ Type, data=., var.equal = TRUE) %>%\n    tidy()\n\n\n\nTo fit a linear model, the Type variable will need to be binary. Fit a linear model in R using lm() and notice which level of Type gets set to 0 and which gets set to 1. How can you tell?\nDevelop a regression model using Time as the response and the indicator on Type as the explanatory variable.\nCreate a linear model (lm()) and then tidy() the model. The following example code might help.\ngames1 %>%\n  lm(Time ~ Type, data = .) %>%\n  summary()\n\ngames1 %>%\n  lm(Time ~ Type, data = .) %>%\n  tidy()\n\n\n\nUse R to calculate the t-statistic and p-value for the hypothesis test \\(H_0: \\beta_1 = 0\\) vs \\(H_a: \\beta_1 \\ne 0\\). In addition, construct at 95% confidence interval for \\(\\beta_1\\). Based on these statistics, can you conclude that the coefficient \\(\\beta_1\\) is significantly different from zero? How is the test of \\(\\beta_1\\) equivalent to the t.test() in the earlier question?\nThe argument conf.int = TRUE inside tidy() on the linear model will find confidence intervals for the coefficients.\n\n\n\nAssume you are conducting a t-test to determine if there is a difference between two means. You have the following summary statistics: \\(\\overline{x}_1 = 10, \\overline{x}_2 = 20\\) and \\(s_1=s_2=10\\). Without completing the hypothesis test, explain why \\(n_1=n_2=100\\) would result in a smaller p-value than \\(n_1=n_2=16\\).\n\n\n\nIf the hypothesis test \\(H_0: \\beta_1 = 0\\) vs \\(H_a: \\beta_1 \\ne 0\\) results in a small p-value, can we be confident that the regression model provides a good estimate of the response value for a given value of \\(x_i\\)? Provide an explanation for your answer.\n\n\n\nWhat model technical conditions (if any) need to be satisfied in order to calculate \\(b_0\\) and \\(b_1\\) in a simple linear regression model?\n\n\n\nExplain why the model notation \\(y_i = \\beta_0 + \\beta_1 x_i\\) is not appropriate, but \\(\\hat{y}_i = b_0 + b_1 x_i\\) is appropriate.\n\n\nHW assignments will be graded out of 5 points, which are based on a combination of accuracy and effort. Below are rough guidelines for grading."
  },
  {
    "objectID": "handout/HW1_m150_s23.html#getting-started",
    "href": "handout/HW1_m150_s23.html#getting-started",
    "title": "Math 150 - Methods in Biostatistics - Homework 1",
    "section": "Getting started",
    "text": "Getting started\n\nLoad packages\nHere we will explore the data using functions that can be found in the tidyverse package. The data can be found in the package nycflights13.\nLet’s load the packages.\n\nlibrary(tidyverse)\nlibrary(nycflights13)\n\n\n\nThe data\nThe Bureau of Transportation Statistics (BTS) is a statistical agency that is a part of the Research and Innovative Technology Administration (RITA). As its name implies, BTS collects and makes available transportation data, such as the flights data we will be working with here.\nWe begin by loading the flights data frame. Run the following command by clicking on the green triangle:\n\ndata(flights)\n\nThe data set flights that shows up in your workspace is a data matrix, with each row representing an observation and each column representing a variable. R calls this data format a data frame, which is a term that will be used throughout the course. For this data set, each observation is a single flight.\nTo view the names of the variables, run the command\n\nnames(flights)\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tailnum\"       \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\"     \n\n\nThis returns the names of the variables in this data frame. The codebook (description of the variables) can be accessed by pulling up the help file (run this line with the green triangle and then look at the box on the bottom right of the RStudio screen):\n\n?flights\n\nOne of the variables refers to the carrier (i.e. airline) of the flight, which is coded according to the following system.\n\ncarrier: Two letter carrier abbreviation.\n\n9E: Endeavor Air Inc.\nAA: American Airlines Inc.\nAS: Alaska Airlines Inc.\nB6: JetBlue Airways\nDL: Delta Air Lines Inc.\nEV: ExpressJet Airlines Inc.\nF9: Frontier Airlines Inc.\nFL: AirTran Airways Corporation\nHA: Hawaiian Airlines Inc.\nMQ: Envoy Air\nOO: SkyWest Airlines Inc.\nUA: United Air Lines Inc.\nUS: US Airways Inc.\nVX: Virgin America\nWN: Southwest Airlines Co.\nYV: Mesa Airlines Inc.\n\n\nA very useful function for taking a quick peek at your data frame and viewing its dimensions and data types is glimpse().\n\nglimpse(flights)\n\nRows: 336,776\nColumns: 19\n$ year           <int> 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       <int> 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, …\n$ sched_dep_time <int> 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, …\n$ dep_delay      <dbl> 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1…\n$ arr_time       <int> 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849,…\n$ sched_arr_time <int> 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851,…\n$ arr_delay      <dbl> 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -1…\n$ carrier        <chr> \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"…\n$ flight         <int> 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 4…\n$ tailnum        <chr> \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N394…\n$ origin         <chr> \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\",…\n$ dest           <chr> \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\",…\n$ air_time       <dbl> 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 1…\n$ distance       <dbl> 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, …\n$ hour           <dbl> 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6…\n$ minute         <dbl> 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0…\n$ time_hour      <dttm> 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0…\n\n\nThe flights data frame is a massive trove of information (336,776 observations!!!). Notice also that the glimpse() function let’s you know how the variables are stored: integer, double (a fancy way to say decimal number), character string, date/time, etc. Let’s think about some questions we might want to answer with these data:\n\nHow delayed were flights that were headed to Los Angeles?\nHow do departure delays vary over months?\nWhich of the three major NYC airports has a better on time percentage for departing flights?\n\n\n\nTidy Structure of Data\nFor plotting, analyses, model building, etc., the data should be structured according to certain principles.\n\nTidy Data: rows (cases/observational units) and columns (variables).\nThe key is that every row is a case and every column is a variable.\nNo exceptions.\nCreating tidy data is often not trivial.\n\nWithin R (really within any type of computing language, Python, SQL, Java, etc.), it is important to understand how to build data using the patterns of the language.\nSome things to consider:\n\nobject_name <- anything is a way of assigning anything to the new object_name.\nobject_name <- function_name(data_frame, arguments) is a way of using a function to create a new object.\nobject_name <- data_frame %>% function_name(arguments) uses chaining syntax as an extension of the ideas of functions.\nIn chaining, the value on the left side of %>% becomes the first argument to the function on the right side.\n\nobject_name <- data_frame %>%\n                    function_name(arguments) %>% \n                    another_function_name(other_arguments)\nis extended chaining. %>% is never at the front of the line, it is always connecting one idea with the continuation of that idea on the next line. * In R, all functions take arguments in round parentheses (as opposed to subsetting observations or variables from data objects which happen with square parentheses). Additionally, the spot to the left of %>% is always a data table. * The pipe syntax should be read as then, %>%.\n\n\nUsing the pipe to chain\nThe pipe syntax (%>%) takes a data frame (or data table) and sends it to the argument of a function. The mapping goes to the first available argument in the function.\nFor example:\nx %>% f(y) is the same as f(x, y)\ny %>% f(x, ., z) is the same as f(x,y,z)\nPipes are used commonly with functions in the dplyr package and they allow us to sequentially build data wrangling operations. We’ll start with short pipes and throughout the course build up to longer pipes that perform multiple operations."
  },
  {
    "objectID": "handout/HW1_m150_s23.html#analysis",
    "href": "handout/HW1_m150_s23.html#analysis",
    "title": "Math 150 - Methods in Biostatistics - Homework 1",
    "section": "Analysis",
    "text": "Analysis\n\nDeparture delays\nLet’s start by examining the distribution of departure delays of all flights using the summary function. The first item (on the left) is the data set. Subsequently, two functions are applied, (1) select() to get only the dep_delay variables, and (2) summary() to produce the numerical summary.\n\nflights %>% \n  dplyr::select(dep_delay) %>% \n  summary()\n\n   dep_delay      \n Min.   : -43.00  \n 1st Qu.:  -5.00  \n Median :  -2.00  \n Mean   :  12.64  \n 3rd Qu.:  11.00  \n Max.   :1301.00  \n NA's   :8255     \n\n\n\nfilter (create a smaller dataset)\nIf we want to focus only on departure delays of flights headed to Los Angeles, we need to first filter() the data for flights with that destination (dest == \"LAX\"). The departure delay for the LAX flights can then be summarized.\n\nlax_flights <- flights %>%\n  dplyr::filter(dest == \"LAX\")\n\nlax_flights %>% \n  dplyr::select(dep_delay) %>% \n  summary()\n\n   dep_delay      \n Min.   :-16.000  \n 1st Qu.: -4.000  \n Median : -1.000  \n Mean   :  9.401  \n 3rd Qu.:  7.000  \n Max.   :800.000  \n NA's   :98       \n\n\nLet’s decipher these two commands (It’s common to add a break to a new line after %>% to help readability).\n\nCommand 1: Take the flights data frame, filter() for flights headed to LAX, and save the result as a new data frame called lax_flights.\n\n== means “if it is equal to”. (notice that there are TWO equals signs)\nLAX is in quotation marks since it is a character string.\n\nCommand 2: Basically the same call for summarizing the departure delay.\n\nNotice that if we only want the summary of dep_delay for the LAX flights (and we don’t need to keep a copy of the dataset), we can perform the above tasks by combining them into fewer steps:\n\nflights %>%\n  filter(dest == \"LAX\") %>%\n  dplyr::select(dep_delay) %>% \n  summary()\n\n   dep_delay      \n Min.   :-16.000  \n 1st Qu.: -4.000  \n Median : -1.000  \n Mean   :  9.401  \n 3rd Qu.:  7.000  \n Max.   :800.000  \n NA's   :98       \n\n\n\nLogical operators:  Filtering for certain observations (e.g. flights from a particular airport) is often of interest in data frames where we might want to examine observations with certain characteristics separately from the rest of the data. To do so we use the filter() function and a series of logical operators. The most commonly used logical operators for data analysis are as follows:\n\n== means “equal to”\n!= means “not equal to”\n> or < means “greater than” or “less than”\n>= or <= means “greater than or equal to” or “less than or equal to”\n\n\n\n\nsummarize (calculate statistics)\nWe can also obtain numerical summaries for these flights:\n\nlax_flights %>%\n  summarize(mean_dd = mean(dep_delay, na.rm=TRUE), \n            median_dd = median(dep_delay, na.rm=TRUE), n_dd = n())\n\n# A tibble: 1 × 3\n  mean_dd median_dd  n_dd\n    <dbl>     <dbl> <int>\n1    9.40        -1 16174\n\n\nNote that in the summarize() function we created a list of three different numerical summaries that we were interested in. The names of these elements are user defined, like mean_dd, median_dd, n_dd, and you could customize these names as you like (just don’t use spaces in your names). Calculating these summary statistics also require that you know the function calls. Note that n() reports the sample size.\n\nSummary statistics:  Some useful function calls for summary statistics for a single numerical variable are as follows:\n\nmean\nmedian\nsd\nIQR\nmin\nmax\n\nNote that each of these functions take a single vector as an argument, and returns a single value.\n\nFunctions you may not be familiar with (and that we will see in more detail in coming weeks) include: \\[\\mbox{sd} = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\overline{X})^2}\\] \\[\\mbox{IQR} = 75\\% - 25\\%\\]\nWe can also filter based on multiple criteria. Suppose we are interested in flights headed to San Francisco (SFO) in February:\n\nsfo_feb_flights <- flights %>%\n  filter(dest == \"SFO\", month == 2)\n\nNote that we can separate the conditions using commas if we want flights that are both headed to SFO and in February. If we are interested in either flights headed to SFO or in February we can use the | instead of the comma.\n\nPractice\nCreate a new data frame that includes flights headed to SFO in February, and save this data frame as sfo_feb_flights. How many flights meet these criteria?\n\nsfo_feb_flights %>%\n  summarize(n())\n\n# A tibble: 1 × 1\n  `n()`\n  <int>\n1   791\n\n\nDescribe the distribution of the arrival delays of these flights using summary and/or appropriate summary statistics.\n\nsfo_feb_flights %>%\n  summarize(arrdelmean = mean(arr_delay, na.rm=TRUE), \n            arrdelsd = sd(arr_delay, na.rm=TRUE),\n            arrdelmed = median(arr_delay, na.rm=TRUE), \n            arrdeliqr = IQR(arr_delay, na.rm=TRUE))\n\n# A tibble: 1 × 4\n  arrdelmean arrdelsd arrdelmed arrdeliqr\n       <dbl>    <dbl>     <dbl>     <dbl>\n1      -9.14     31.4       -13        29\n\n\n\n\n\ngroup_by (group before summarizing)\nAnother useful technique is quickly calculating summary statistics for various groups in your data frame. For example, we can modify the above command using the group_by() function to get the same summary stats for each origin airport:\n\nsfo_feb_flights %>%\n  group_by(origin) %>%\n  summarize(median_dd = median(dep_delay, na.rm=TRUE), \n            iqr_dd = IQR(dep_delay, na.rm=TRUE), n_flights = n())\n\n# A tibble: 2 × 4\n  origin median_dd iqr_dd n_flights\n  <chr>      <dbl>  <dbl>     <int>\n1 EWR            0      9       194\n2 JFK           -2      8       597\n\n\nHere, we first grouped the data by origin, and then calculated the summary statistics.\n\nPractice\nCalculate the median and interquartile range for arr_delay of flights in in the sfo_feb_flights data frame, grouped by carrier. Which carrier has the most variable arrival delays (as measured by IQR)?\n\nsfo_feb_flights %>% \n  group_by(carrier) %>%\n  summarize(arrdelmed = median(arr_delay, na.rm=TRUE), \n            arrdeliqr = IQR(arr_delay, na.rm=TRUE)) %>%\n  arrange(desc(arrdeliqr))\n\n# A tibble: 5 × 3\n  carrier arrdelmed arrdeliqr\n  <chr>       <dbl>     <dbl>\n1 AA             -7      35  \n2 DL            -24      27.5\n3 UA             -9      27  \n4 B6            -11      25.5\n5 VX            -20      23  \n\n\n\n\n\n\narrange() departure delays over months\n\nPractice\nWhich month would you expect to have the highest average delay departing from an NYC airport?\nLet’s think about how we would answer this question:\n\nFirst, calculate monthly averages for departure delays. With the new language we are learning, we need to\n\ngroup_by() months, then\nsummarize() mean departure delays.\n\nThen, we need to arrange() these average delays in desc()ending order\n\n\nflights %>%\n  group_by(month) %>%\n  summarize(mean_dd = mean(dep_delay, na.rm=TRUE)) %>%\n  arrange(desc(mean_dd))\n\n# A tibble: 12 × 2\n   month mean_dd\n   <int>   <dbl>\n 1     7   21.7 \n 2     6   20.8 \n 3    12   16.6 \n 4     4   13.9 \n 5     3   13.2 \n 6     5   13.0 \n 7     8   12.6 \n 8     2   10.8 \n 9     1   10.0 \n10     9    6.72\n11    10    6.24\n12    11    5.44\n\n\n\n\nOn time departure rate for NYC airports\nSuppose you will be flying out of NYC and want to know which of the three major NYC airports has the best on time departure rate of departing flights. Suppose also that for you a flight that is delayed for less than 5 minutes is basically “on time”. You consider any flight delayed for 5 minutes of more to be “delayed”.\nIn order to determine which airport has the best on time departure rate, we need to\n\nfirst classify each flight as “on time” or “delayed”,\nthen group flights by origin airport,\nthen calculate on time departure rates for each origin airport,\nand finally arrange the airports in descending order for on time departure percentage.\n\n\n\nmutate() (create a new variable)\n\nPractice\nLet’s start with classifying each flight as “on time” or “delayed” by creating a new variable with the mutate() function.\n\nflights <- flights %>%\n  mutate(dep_type = ifelse(dep_delay < 5, \"on time\", \"delayed\"))\n\nThe first argument in the mutate() function is the name of the new variable we want to create, in this case dep_type. Then if dep_delay < 5 we classify the flight as \"on time\" and \"delayed\" if not, i.e. if the flight is delayed for 5 or more minutes.\nNote that we are also overwriting the flights data frame with the new version of this data frame that includes the new dep_type variable.\nWe can handle all the remaining steps in one code chunk:\n\nflights %>%\n  group_by(origin) %>%\n  summarize(ot_dep_rate = mean(dep_type == \"on time\", na.rm=TRUE)) %>%\n  arrange(desc(ot_dep_rate))\n\n# A tibble: 3 × 2\n  origin ot_dep_rate\n  <chr>        <dbl>\n1 LGA          0.728\n2 JFK          0.691\n3 EWR          0.639\n\n\n\n\nPractice\nIf you were selecting an airport (of the three NYC airports in the dataset) simply based on on time departure percentage, which NYC airport would you choose to fly out of? (How did you define “on time”? 0 min? 5 min? Something else?)\nLGA seems to have the highest on time departure percentage, so that’s the airport I would choose."
  },
  {
    "objectID": "handout/HW2_m150_s23.html",
    "href": "handout/HW2_m150_s23.html",
    "title": "Math 150 - Methods in Biostatistics - Homework 2",
    "section": "",
    "text": "Assignment Summary (Goals)\n\nRun a least square regression model, try different transformations on the explanatory and response variables to find a model for which the technical conditions hold.\nAnalyze two different datasets using a simulation method (you will need the infer package) as well as Fisher’s Exact Test\nFor plotting and infer code, see the class notes describing the Botox study:\nclick here to link for boxplots and click here to link for infer for simulating\n\n\nQ1. Collaborative Learning\nDescribe one thing you learned from someone (a fellow student or mentor) in our class this week (it could be: content, logistical help, background material, R information, etc.) 1-3 sentences.\n\n\nQ2. Hippel-Lindau disease\nEisenhofer et al. (1999) investigated the use of plasma normetanephrine and metanephrine for detecting pheochromocytoma in patients with von Hippel-Lindau disease and multiple endocrine neoplasia type 2. The data set (vonHippelLindau.csv, posted online) contains data from this study on 26 patients with von Hippel-Lindau disease and nine patients with multiple endocrineneoplasia. The variables in the data set are (problem from Dupont, chp 2.22, PubMed article at [http://www.ncbi.nlm.nih.gov/pubmed/10369850]):\nNote: the goal is to model p_ne (the response variable) from tumorvol (the explanatory variable).\n\n\n\nvariable\nunits\n\n\n\n\ndisease\n0: patient has von Hippel-Lindau disease\n\n\n\n1: patient has multiple endocrine neoplasia type 2\n\n\np_ne\nplasma norepinephrine (pg/ml)\n\n\ntumorvol\ntumor volume (ml)\n\n\n\nNote: the data this week is imported from the internet, so everyone can use the same link! The directories below do not go to my own computer, they go to a URL pointing to a dataset in the cloud.\n\ntumor <- readr::read_csv(\"http://pages.pomona.edu/~jsh04747/courses/math150/vonHippelLindau.csv\")\nhead(tumor, 3)\n\n# A tibble: 3 × 4\n  disease    id  p_ne tumorvol\n    <dbl> <dbl> <dbl>    <dbl>\n1       0     2  1845      336\n2       0     3  1734      216\n3       0     4   739      128\n\n\n\nRegress plasma norepinephrine against tumor volume. Draw a scatter plot of norepinephrine against tumor volume together with the estimated linear regression curve. What is the slope estimate for this regression? What proportion of the total variation in norepinephrine levels is explained by the regression?\n\n\nR hints:\nIf the linear model is piped into tidy(), the output will be important information on a per parameter basis. For example, coefficients, standard errors, etc.\nIf the linear model is piped into glance(), the output will be important information on a per model basis. For example, \\(R^2\\), overall model p-value, model degrees of freedom, etc.\nIf the linear model is piped into augment(), the output will be be important information on a per observation basis. For example, residuals (.resid), fitted values / predicted values (.fitted), etc.\nTo make a plot in R you want to add a series of layers. The code below is meant as an example, although the variables are totally wrong. Work through the lines of code below and see if you can follow. If you don’t follow the lines, ask me!\n\ntumor %>%                                 # which dataset?\n  ggplot(aes(x = id, y = tumorvol)) +     # set up the plot\n  geom_point() +                          # add the points\n  geom_smooth(method = \"lm\", se = FALSE)  # add the line a linear model without error bounds\n\n\n\n\n\n\n\n\n\nExperiment with different transformations of norepinephrine and tumor volume. Find transformations that provide a good fit to a linear model. Report your new linear model. What is your new \\(R^2\\)? Does the \\(R^2\\) matter in choosing your transformation? Explain.\n\n\n\nR hints:\nFirst transform one or both of your variables (see pg 49 in your text), then re-plot the data. Below is an example, but it turns out that I made a bad choice of transformation because the plot is terrible. Why (what makes the plot look bad)?\n\ntumor %>%\n  ggplot(aes(x = 1/tumorvol, y = p_ne)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nQ3. Regression Conditions\nWhich of the following conditions are required to test hypotheses using simple linear regression? If the condition isn’t valid, explain why not.\n\nThe random variable \\(Y\\) (not conditional on \\(X\\)) is normally distributed.\nThe variance of \\(Y\\) depends on \\(X\\).\nThe random variable \\(Y\\) is normally distributed at each value of \\(X\\).\nThe mean of \\(Y\\) (given \\(X\\)) is a linear function of \\(X\\).\nThe random variable \\(X\\) is randomly distributed on some scale.\n\n\n\nQ4. Chp 6, E1: Cancer and Smoking: Fisher’s Exact Test and Simulations Studies\nAnswer the following questions for the data displayed below. Hint: see the class notes for help with the R code. And ask lots of questions!\n\n\n\n\nlung cancer\nhealthy\n\n\n\n\n\nsmoker\n41\n28\n69\n\n\nnon-smoker\n19\n32\n51\n\n\n\n60\n60\n120\n\n\n\n\nsmokecancer <- data.frame(act = c(rep(\"non-smoker\", 51), rep(\"smoker\", 69)),\n                     outcome = c(rep(\"lung_cancer\", 19), rep(\"healthy\", 32), \n                                 rep(\"lung_cancer\", 41), rep(\"healthy\", 28)))\nsmokecancer %>% table()\n\n            outcome\nact          healthy lung_cancer\n  non-smoker      32          19\n  smoker          28          41\n\n\n\nWas either the explanatory variable (row) or the response (column) variable fixed before the study was conducted?\nIs this an example of an experiment or an observational study?\nIs this a cross-classification, cohort, or case-control study? Explain.\nCreated a segmented bar chart for the data.\nCreate a simulation study to test the one-sided hypothesis that smokers are more likely to have lung cancer. Provide a p-value and state your conclusions.\nUse Fisher’s exact test to test the one-sided hypothesis that smokers are more likely to have lung cancer. Provide a p-value and state your conclusions.\n\n\npraise()\n\n[1] \"You are laudable!\"\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "handout/HW3_m150_s23.html",
    "href": "handout/HW3_m150_s23.html",
    "title": "Math 150 - Methods in Biostatistics - Homework 3",
    "section": "",
    "text": "knitr::opts_chunk$set(message=FALSE, warning=FALSE, fig.height=4, fig.width=6.5, \n                      fig.align = \"center\")\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(praise)\n\n\nAssignment Summary (Goals)\n\nUnderstanding null hypotheses with respect to odds and proportions\nTesting via z-stat, Fisher, Chi-sq (note: if you did all for all scenarios, you’d almost always end up with the same conclusion each time!)\nMaking conclusions about different study types\n(Decided against the Chi Square test, you are not responsible for it.)\n\n\nQ1. Collaborative Learning\nDescribe one thing you learned from someone (a fellow student or mentor) in our class this week (it could be: content, logistical help, background material, R information, etc.) 1-3 sentences.\n\n\nQ2. Chp 6, A23\nShow that the null hypothesis \\(H_0: p_1 = p_2\\) is mathematically equivalent to the null hypothesis \\(H_0: \\theta_1 / \\theta_2 = 1\\) where \\(p\\) represents the proportion successful and \\(\\theta\\) represents the odds of success for any two groups (labeled 1 and 2).\n\n\nQ3. Chp 6, E7 Cancer Cells: Testing for Homogeneity of Odds\nUse the data from Table 6.1 and define a benign cell as a success. Conduct a hypothesis test for the homogeneity of odds.\n\nEnter the data, tabulate it, and create a barplot (see the R code in the class notes).\nState the null and alternative hypotheses.\nCalculate the odds ratio and the test statistic (the Z statistic!). See pgs 191-192 in your book.\nProvide the p-value and state your conclusions within the context of the study.\n\n\n\nQ4. Chp 6, E12 The Pill Scare: understanding relative risk reduction\nIn October 1995, the United Kingdom Committee on Safety of Medicines (CSM) issued a warning to 190,000 general practitioners, pharmacists, and directors of public health about oral contraceptive pills containing gestodene or desogestrel. The warning, based on three unpublished epidemiological research studies, stated > “It is well known that the pill may rarely produce thrombosis (blood clots) involving veins of the legs. New evidence has become available indicating that the chance of thrombosis occurring in a vein increases about two-fold for some types of pills compared to others.”\nTable 6.15 provides data from one of the studies.\nSince the occurrence of venous thrombosis is very rare (1 in 7000 for people using the second generation pill), 259 subjects were selected who had thrombosis and 651 similar subjects (from hospitals and community) who did not have thrombosis. Then these subjects were classified by the type of contraceptive they used.\n\nWas either the explanatory (row) or the response (column) variable fixed before the study was conducted?\nIs this an example of an experiment or an observational study?\nIs this a cross-classification, cohort, or case-control study?\nCreate a segmented bar chart for the data.\nUse a two-sided hypothesis and Fisher’s exact test to determine if the type of contraceptive impacts the likelihood of thrombosis. Do you expect the researchers took care to collect a simple random sample of subjects? What conclusions can be drawn?\n\nThe warning contained no numerical information other than the fact that the chance of blood clots was likely to double when birth control pills contained gestodene or desogestrel. This warning was widely publicized throughout the press, and evidence suggests that, as a result of this warning, many women ceased contraception altogether. Evidence shows a strong association between the warning and an increase in the number of unintended pregnancies and abortions (especially in women younger than 20 years old). This resulted in an estimated increase in cost of \\(\\textsterling\\) 21 million for maternity care and \\(\\textsterling\\) 4 to \\(\\textsterling\\) 6 million for abortion provision.\n\nRemember that the actual occurrence of venous thrombosis is only 1 in 7000.\nIf third generation pills double the chances of venous thrombosis, the likelihood of occurrence is still only 2 in 7000. Explain the difference between absolute risk reduction and relative risk reduction in this study.\nDeath from venous thrombosis related to third generation pills is estimated to be 1 in 11 million, much lower than the probability of death resulting from pregnancy. In 2005, the lifetime risk of maternal death in developed countries was 1 in 7300. The CSM warning did suggest that patients see a doctor before altering their contraceptives; however, it appears that many women simply stopped taking any contraceptives. Write a brief statement (just 1-2 sentences!) to the press, general practitioners, pharmacists, and directors of public health about this study.\n\n\npraise()\n\n[1] \"You are wonderful!\"\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "handout/HW4_m150_s23.html",
    "href": "handout/HW4_m150_s23.html",
    "title": "Math 150 - Methods in Biostatistics - Homework 4",
    "section": "",
    "text": "Assignment Summary (Goals)\n\nfluent use of the logistic model for prediction and for coefficient interpretation\npractice using ggplot() so that visualizations can inform the larger analysis\n\nNote that if you don’t know the R code either check my notes or ask me!!! Happy to scaffold, debug, send resources, etc. Don’t go down a rabbit hole trying to figure out an R function or syntax.\nAlso, note that you’ll need to get the data from Sakai and use it for this analysis. Look back to your own HW1 file to see the line of code you used to import the games1.csv dataset. Ask me if it isn’t obvious to you after you look at your own HW1.\n\nQ1. Collaborative Learning\nDescribe one thing you learned from someone (a fellow student or mentor) in our class this week (it could be: content, logistical help, background material, R information, etc.) 1-3 sentences.\n\n\nQ2. Chp 7, A1\nBased on the description of the Challenger disaster O-ring concerns, identify which variable in the Shuttle data set in Table 7.1 should be the explanatory variable and which should be the response variable.\n\n\nQ3. Chp 7, A2\nImagine you were an engineer working for Thiokol Corporation prior to January 1986. Create a few graphs of the data in Table 7.1. Is it obvious that temperature is related to the success of the O-rings? Submit any charts or graphs you have created that show a potential relationship between temperature and O-ring damage.\nnote: the data is coded with missing values represented by *. You may need to account for that. See how I did it below using na=\"*\". Again, ask me if you are having trouble!\nnote on graphs: if you tell me the type of graph you want, and you don’t know how to make it, ask me and I’ll send you code! Remember, your response is binary and your explanatory variable is continuous.\nnote on data: in order to get the assignment to work, you’ll need the data. Import it into the folder where the HW .Rmd file lives. Try not to use your downloads for everything!!\n\nshuttle <- read_csv(\"~/Dropbox/teaching/MA150/PracStatCD/Data Sets/Chapter 07/CSV Files/C7 Shuttle.csv\",\n                     na=\"*\")\n\n# new names that make the data easier to work with:\n# mine loads with an empty 5th column\n# so I had to give the 5th column a name, also.\nnames(shuttle) <- c(\"flight\", \"date\", \"temp\", \"launch\", \"X5\")  \n\n# remove the row that has a missing value for launch\n# also create a character variable for success\nshuttle <- shuttle %>% \n  filter(!is.na(launch)) %>%\n  mutate(launchsucc = as.factor(ifelse(launch == 1, \"success\", \"failure\")))\n\n\n\nQ4. Chp 7, A3\nUse the data in Table 7.1 to create a scatterplot with a least squares regression line for the space shuttle data. Calculate the predicted response values (\\(\\hat{y} = b_0 + b_1 x\\)) when the temperature is 60F and when the temperature is 85F.\n\n\nQ5. Chp 7, A4\nSolve Equation (7.5) for \\(\\pi_i\\) to show that Equation (7.6) is true. Note that your text uses \\(\\pi_i\\) to represent the true model (akin to \\(p_i\\) that has been used in class). The difference is only in notation, not in meaning.\n\n\nQ6. Chp 7, A5\nUse Equation (7.6) to create twelve graphs: In each graph plot the explanatory variable (x) versus the expected probability of success (\\(p_i\\)) using the following values:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\n\\(\\beta_0\\)\n-10\n-10\n-10\n-5\n-5\n-5\n10\n10\n10\n5\n5\n5\n\n\n\\(\\beta_1\\)\n0.5\n1\n1.5\n0.5\n1\n1.5\n-0.5\n-1\n-1.5\n-0.5\n-1\n-1.5\n\n\n\n\nDo not submit the graphs, but explain the impact of changing \\(\\beta_0\\) and \\(\\beta_1\\).\nFor all of the graphs, at what value of \\(\\pi\\) does there appear to be the steepest slope?\n\nI wrote the R code for you (hopefully you can follow along with what it is doing). All you need to do for this problem is change the parameter values and look at the graph. Do not include all the graphs in your assignment, just answer the questions based on your observations.\n\n#set the parameters\nbeta0 <- -10\nbeta1 <- 0.5\nvaluesofX <- seq(0, 40, by=0.01)  # create a vector of X values\n\nprobfunc <- function(b0, b1, ex){\n  exp(b0 + b1*ex) / (1 + exp(b0 + b1*ex))\n}\n\nvaluesofY <- probfunc(beta0, beta1, valuesofX)\n\ndatatoplot <- data.frame(explan = valuesofX, prob = valuesofY)\n\nggplot(datatoplot) + \n  geom_line(aes(x = explan, y = prob))\n\n\n\n\n\n\n\n\n\n\nQ7. Chp 7, A6\n[For the shuttle data:] Use statistical software to calculate the maximum likelihood estimates of \\(\\beta_0\\) and \\(\\beta_1\\). Compare the maximum likelihood estimates to the least squares estimates in A3. Use glm(response ~ explanatory, family = \"binomial\", data = yourdataset) %>% tidy().\n\n\nQ8. Chp 7, A7\nUse Equation (7.9) to predict the probability that a launch has no O-ring damage when the temperature is 31F, 50F, and 75F.\n\n\nQ9. Chp 7, A8\nCalculate the odds of a launch with no O-ring damage when the temperature is 60F and when the temperature is 70F.\n\n\nQ10. Chp 7, A9\nFor the shuttle model above, when \\(x_i\\) increases by 10, state in terms of \\(e^{b_1}\\) how much you would expect the odds to change. (Here you are calculating the odds ratio for an increase in 10 degrees.)\n\n\nQ11. Chp 7, A10\nThe difference between the odds of success at 60F and 59F is about 0.3285 - 0.2605 = 0.068. Would you expect the difference between the odds at 52F and 51F to also be about 0.068? Explain why or why not.\n\n\nQ12. Chp 7, A11\nCreate a plot of two prediction models (one logistic, one linear). Plot temperature versus the estimated probability using maximum likelihood estimates from A6, and plot temperature versus the estimated probability using the least squares estimates from A3.\n\nR code:\nStep1. Look up at probfunc() above. Write a very similar function that is linear instead. Give it a different name.\nStep2. Using the two sets of coefficients (one from the linear and one from the logistic), predict the “y” value for both models for a vector of possible explanatory variables (e.g., valuesofX <- seq(50,85,by=0.01)). You should have two different vectors of predictions (and the vector of X, the explanatory variable).\nStep3. Create a data.frame() with three columns. Let’s say you call it mypredictons. The ggplot code will look like this. Have fun with coloring the plot or changing the line types or something!\nggplot(shuttle) +\n   geom_point(aes(x = temp, y = launch)) + \n   geom_line(data = mypredictions, aes(x = valuesofX, y = yourlinearpreds)) +\n   geom_line(data = mypredictions, aes(x = valuesofX, y = yourlogisticpreds))\n\npraise()\n\n[1] \"You are unreal!\"\n\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#agenda",
    "href": "handout/2023-02-21-tidymodels.html#agenda",
    "title": "Tidymodels",
    "section": "Agenda",
    "text": "Agenda\n\n\nWorkflow to help us think about model building\nBreaking up data for independent assessment\nAssessment metrics"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#feeders",
    "href": "handout/2023-02-21-tidymodels.html#feeders",
    "title": "Tidymodels",
    "section": "Feeders",
    "text": "Feeders\nHow are other characteristics related to the presence of squirrels?\n\n\n# A tibble: 2 × 2\n  squirrels    nearby_feeders\n  <fct>                 <dbl>\n1 no squirrels          0.344\n2 squirrels             0.456"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#other-variables",
    "href": "handout/2023-02-21-tidymodels.html#other-variables",
    "title": "Tidymodels",
    "section": "Other variables",
    "text": "Other variables\nWhat about some of the variables describing the habitat?"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#train-test",
    "href": "handout/2023-02-21-tidymodels.html#train-test",
    "title": "Tidymodels",
    "section": "Train / test",
    "text": "Train / test\nCreate an initial split:\n\nset.seed(470)\nfeeder_split <- site_data %>%\n  initial_split(strata = squirrels) # prop = 3/4 in each group, by default\n\nSave training data\n\nfeeder_train <- training(feeder_split)\ndim(feeder_train)\n\n[1] 176763     59\n\n\nSave testing data\n\nfeeder_test  <- testing(feeder_split)\ndim(feeder_test)\n\n[1] 58922    59"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#training-data",
    "href": "handout/2023-02-21-tidymodels.html#training-data",
    "title": "Tidymodels",
    "section": "Training data",
    "text": "Training data\n\nfeeder_train\n\n# A tibble: 176,763 × 59\n   squirrels    yard_t…¹ yard_…² yard_…³ yard_…⁴ yard_…⁵ hab_d…⁶ hab_e…⁷ hab_m…⁸\n   <fct>           <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 no squirrels        0       0       1       0       0       1      NA       1\n 2 no squirrels        0       0       1       0       0       1      NA       1\n 3 no squirrels        0       0       1       0       0       1       0       1\n 4 no squirrels        0       0       1       0       0       1      NA      NA\n 5 no squirrels        0       0       1       1       0       1       0       0\n 6 no squirrels        0       0       1       0       0       1      NA       1\n 7 no squirrels        0       0       0       1       0       0       0       1\n 8 no squirrels        0       0       1       1       0      NA      NA      NA\n 9 no squirrels        0       0       1       0       0       1       1      NA\n10 no squirrels        0       0       1       1       0       0       0       1\n# … with 176,753 more rows, 50 more variables: hab_orchard <dbl>,\n#   hab_park <dbl>, hab_water_fresh <dbl>, hab_water_salt <dbl>,\n#   hab_residential <dbl>, hab_industrial <dbl>, hab_agricultural <dbl>,\n#   hab_desert_scrub <dbl>, hab_young_woods <dbl>, hab_swamp <dbl>,\n#   hab_marsh <dbl>, evgr_trees_atleast <dbl>, evgr_shrbs_atleast <dbl>,\n#   dcid_trees_atleast <dbl>, dcid_shrbs_atleast <dbl>,\n#   fru_trees_atleast <dbl>, cacti_atleast <dbl>, brsh_piles_atleast <dbl>, …"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#feature-engineering",
    "href": "handout/2023-02-21-tidymodels.html#feature-engineering",
    "title": "Tidymodels",
    "section": "Feature engineering",
    "text": "Feature engineering\n\nWe prefer simple models when possible, but parsimony does not mean sacrificing accuracy (or predictive performance) in the interest of simplicity\nVariables that go into the model and how they are represented are just as critical to success of the model\nFeature engineering allows us to get creative with our predictors in an effort to make them more useful for our model (to increase its predictive performance)"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#modeling-workflow",
    "href": "handout/2023-02-21-tidymodels.html#modeling-workflow",
    "title": "Tidymodels",
    "section": "Modeling workflow",
    "text": "Modeling workflow\n\nCreate a recipe for feature engineering steps to be applied to the training data\nFit the model to the training data after these steps have been applied\nUsing the model estimates from the training data, predict outcomes for the test data\nEvaluate the performance of the model on the test data"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#initiate-a-recipe",
    "href": "handout/2023-02-21-tidymodels.html#initiate-a-recipe",
    "title": "Tidymodels",
    "section": "Initiate a recipe",
    "text": "Initiate a recipe\n\nfeeder_rec <- recipe(\n  squirrels ~ .,    # formula\n  data = feeder_train \n  )\n\nfeeder_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         58"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#working-with-recipes",
    "href": "handout/2023-02-21-tidymodels.html#working-with-recipes",
    "title": "Tidymodels",
    "section": "Working with recipes",
    "text": "Working with recipes\n\nWhen building recipes you in a pipeline, you don’t get to see the effect of the recipe on your data, which can be unsettling\nYou can take a peek at what will happen when you ultimately apply the recipe to your data at the time of fitting the model\nThis requires two functions: prep() to train the recipe and bake() to apply it to your data\n\n\n\n\n\n\n\n\nNote\n\n\nUsing prep() and bake() are shown here for demonstrative purposes. They do not need to be a part of your pipeline. I do find them assuring, however, so that I can see the effects of the recipe steps as the recipe is built."
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#impute-missing-values-remove-zero-variance-predictors",
    "href": "handout/2023-02-21-tidymodels.html#impute-missing-values-remove-zero-variance-predictors",
    "title": "Tidymodels",
    "section": "Impute missing values & Remove zero variance predictors",
    "text": "Impute missing values & Remove zero variance predictors\nImpute missing values (replace with mean).\nRemove all predictors that contain only a single value\n\nfeeder_rec <- feeder_rec %>%\n  step_impute_mean(all_numeric_predictors()) %>%\n  step_nzv(all_numeric_predictors())\n\nfeeder_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         58\n\nOperations:\n\nMean imputation for all_numeric_predictors()\nSparse, unbalanced variable filter on all_numeric_predictors()"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#prep-and-bake",
    "href": "handout/2023-02-21-tidymodels.html#prep-and-bake",
    "title": "Tidymodels",
    "section": "Prep and bake",
    "text": "Prep and bake\n\nfeeder_rec_trained <- prep(feeder_rec)\n\nbake(feeder_rec_trained, feeder_train) %>%\n  glimpse()\n\nRows: 176,763\nColumns: 59\n$ yard_type_pavement           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ yard_type_garden             <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ yard_type_landsca            <dbl> 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,…\n$ yard_type_woods              <dbl> 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,…\n$ yard_type_desert             <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ hab_dcid_woods               <dbl> 1.0000000, 1.0000000, 1.0000000, 1.000000…\n$ hab_evgr_woods               <dbl> 0.223341, 0.223341, 0.000000, 0.223341, 0…\n$ hab_mixed_woods              <dbl> 1.000000, 1.000000, 1.000000, 0.655411, 0…\n$ hab_orchard                  <dbl> 0.09324933, 0.09324933, 0.00000000, 0.093…\n$ hab_park                     <dbl> 0.4502185, 0.4502185, 0.0000000, 0.450218…\n$ hab_water_fresh              <dbl> 1.0000000, 1.0000000, 1.0000000, 1.000000…\n$ hab_water_salt               <dbl> 0.05016023, 0.05016023, 0.00000000, 0.050…\n$ hab_residential              <dbl> 1.0000000, 1.0000000, 1.0000000, 1.000000…\n$ hab_industrial               <dbl> 0.2215792, 0.2215792, 0.0000000, 0.221579…\n$ hab_agricultural             <dbl> 1.0000000, 1.0000000, 1.0000000, 0.409835…\n$ hab_desert_scrub             <dbl> 0.09257371, 0.09257371, 0.00000000, 0.092…\n$ hab_young_woods              <dbl> 0.349782, 0.349782, 0.000000, 0.349782, 0…\n$ hab_swamp                    <dbl> 0.2917369, 0.2917369, 0.0000000, 0.291736…\n$ hab_marsh                    <dbl> 1.0000000, 1.0000000, 1.0000000, 0.175361…\n$ evgr_trees_atleast           <dbl> 11, 11, 11, 0, 11, 1, 4, 4, 4, 1, 1, 1, 1…\n$ evgr_shrbs_atleast           <dbl> 4, 4, 1, 4, 0, 1, 4, 4, 4, 1, 0, 4, 4, 11…\n$ dcid_trees_atleast           <dbl> 11, 11, 1, 4, 1, 4, 11, 11, 4, 1, 1, 1, 1…\n$ dcid_shrbs_atleast           <dbl> 4, 4, 4, 1, 1, 4, 11, 11, 1, 1, 0, 4, 4, …\n$ fru_trees_atleast            <dbl> 4.00000, 4.00000, 1.00000, 1.00000, 0.000…\n$ cacti_atleast                <dbl> 0.0000000, 0.0000000, 0.0000000, 0.000000…\n$ brsh_piles_atleast           <dbl> 0, 0, 0, 1, 0, 0, 1, 4, 1, 0, 0, 1, 1, 1,…\n$ water_srcs_atleast           <dbl> 1.0000000, 1.0000000, 1.0000000, 0.000000…\n$ bird_baths_atleast           <dbl> 0, 0, 0, 1, 0, 0, 1, 1, 4, 0, 0, 0, 0, 1,…\n$ nearby_feeders               <dbl> 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,…\n$ cats                         <dbl> 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,…\n$ dogs                         <dbl> 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,…\n$ humans                       <dbl> 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,…\n$ housing_density              <dbl> 2, 2, 2, 2, 2, 3, 1, 1, 1, 1, 2, 1, 2, 2,…\n$ fed_in_jan                   <dbl> 1.0000000, 1.0000000, 1.0000000, 1.000000…\n$ fed_in_feb                   <dbl> 1.000000, 1.000000, 1.000000, 1.000000, 1…\n$ fed_in_mar                   <dbl> 1.0000000, 1.0000000, 1.0000000, 1.000000…\n$ fed_in_apr                   <dbl> 1.0000000, 1.0000000, 0.0000000, 1.000000…\n$ fed_in_may                   <dbl> 0.0000000, 0.0000000, 0.0000000, 1.000000…\n$ fed_in_jun                   <dbl> 0.0000000, 0.0000000, 0.0000000, 1.000000…\n$ fed_in_jul                   <dbl> 0.000000, 0.000000, 0.000000, 1.000000, 1…\n$ fed_in_aug                   <dbl> 0.0000000, 0.0000000, 0.0000000, 1.000000…\n$ fed_in_sep                   <dbl> 0.0000000, 0.0000000, 0.0000000, 1.000000…\n$ fed_in_oct                   <dbl> 0.0000000, 0.0000000, 0.0000000, 1.000000…\n$ fed_in_nov                   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ fed_in_dec                   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ numfeeders_suet              <dbl> 1, 1, 1, 2, 1, 1, 1, 1, 3, 2, 2, 3, 4, 1,…\n$ numfeeders_ground            <dbl> 0.000000, 0.000000, 1.270686, 1.000000, 0…\n$ numfeeders_hanging           <dbl> 1.000000, 1.000000, 2.707598, 2.000000, 2…\n$ numfeeders_platfrm           <dbl> 1.000000, 1.000000, 1.033629, 1.033629, 0…\n$ numfeeders_humming           <dbl> 0.0000000, 0.0000000, 0.4989854, 0.498985…\n$ numfeeders_water             <dbl> 1.0000000, 1.0000000, 0.7887147, 0.788714…\n$ numfeeders_thistle           <dbl> 0.000000, 0.000000, 1.007624, 1.000000, 1…\n$ numfeeders_fruit             <dbl> 0.0000000, 0.0000000, 0.1442454, 0.144245…\n$ numfeeders_hopper            <dbl> 1.385205, 1.385205, 1.000000, 1.385205, 0…\n$ numfeeders_tube              <dbl> 2.162308, 2.162308, 1.000000, 2.162308, 2…\n$ numfeeders_other             <dbl> 0.6037683, 0.6037683, 0.6037683, 0.603768…\n$ population_atleast           <dbl> 1, 1, 1, 25001, 5001, 25001, 1, 1, 1, 1, …\n$ count_area_size_sq_m_atleast <dbl> 1.01, 1.01, 1.01, 1.01, 1.01, 1.01, 375.0…\n$ squirrels                    <fct> no squirrels, no squirrels, no squirrels,…"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#specify-model",
    "href": "handout/2023-02-21-tidymodels.html#specify-model",
    "title": "Tidymodels",
    "section": "Specify model",
    "text": "Specify model\n\nfeeder_log <- logistic_reg() %>%\n  set_engine(\"glm\")\n\nfeeder_log\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#build-workflow",
    "href": "handout/2023-02-21-tidymodels.html#build-workflow",
    "title": "Tidymodels",
    "section": "Build workflow",
    "text": "Build workflow\nWorkflows bring together models and recipes so that they can be easily applied to both the training and test data.\n\nfeeder_wflow <- workflow() %>%\n  add_recipe(feeder_rec) %>%\n  add_model(feeder_log) \n\n\nSee next slide for workflow…"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#view-workflow",
    "href": "handout/2023-02-21-tidymodels.html#view-workflow",
    "title": "Tidymodels",
    "section": "View workflow",
    "text": "View workflow\n\nfeeder_wflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_impute_mean()\n• step_nzv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#fit-model-to-training-data",
    "href": "handout/2023-02-21-tidymodels.html#fit-model-to-training-data",
    "title": "Tidymodels",
    "section": "Fit model to training data",
    "text": "Fit model to training data\n\nfeeder_fit <- feeder_wflow %>%\n  fit(data = feeder_train)\n\nfeeder_fit %>% tidy()\n\n# A tibble: 59 × 5\n   term               estimate std.error statistic   p.value\n   <chr>                 <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)         -1.42      0.0505    -28.2  2.26e-174\n 2 yard_type_pavement  -0.854     0.149      -5.74 9.23e-  9\n 3 yard_type_garden    -0.175     0.0392     -4.47 7.89e-  6\n 4 yard_type_landsca    0.168     0.0219      7.69 1.45e- 14\n 5 yard_type_woods      0.309     0.0170     18.1  1.59e- 73\n 6 yard_type_desert    -0.297     0.0789     -3.76 1.68e-  4\n 7 hab_dcid_woods       0.336     0.0161     20.9  6.55e- 97\n 8 hab_evgr_woods      -0.0797    0.0192     -4.15 3.36e-  5\n 9 hab_mixed_woods      0.420     0.0158     26.5  3.17e-155\n10 hab_orchard         -0.307     0.0252    -12.2  4.00e- 34\n# … with 49 more rows\n\n\n\n\nSo many predictors!"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#model-fit-summary",
    "href": "handout/2023-02-21-tidymodels.html#model-fit-summary",
    "title": "Tidymodels",
    "section": "Model fit summary",
    "text": "Model fit summary\n\nfeeder_fit %>% tidy() \n\n# A tibble: 59 × 5\n   term               estimate std.error statistic   p.value\n   <chr>                 <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)         -1.42      0.0505    -28.2  2.26e-174\n 2 yard_type_pavement  -0.854     0.149      -5.74 9.23e-  9\n 3 yard_type_garden    -0.175     0.0392     -4.47 7.89e-  6\n 4 yard_type_landsca    0.168     0.0219      7.69 1.45e- 14\n 5 yard_type_woods      0.309     0.0170     18.1  1.59e- 73\n 6 yard_type_desert    -0.297     0.0789     -3.76 1.68e-  4\n 7 hab_dcid_woods       0.336     0.0161     20.9  6.55e- 97\n 8 hab_evgr_woods      -0.0797    0.0192     -4.15 3.36e-  5\n 9 hab_mixed_woods      0.420     0.0158     26.5  3.17e-155\n10 hab_orchard         -0.307     0.0252    -12.2  4.00e- 34\n# … with 49 more rows"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#make-predictions-for-training-data",
    "href": "handout/2023-02-21-tidymodels.html#make-predictions-for-training-data",
    "title": "Tidymodels",
    "section": "Make predictions for training data",
    "text": "Make predictions for training data\n\nfeeder_train_pred <- predict(feeder_fit, feeder_train, type = \"prob\") %>%\n  mutate(.pred_class = as.factor(ifelse(.pred_squirrels >=0.5,\n                                        \"squirrels\", \"no squirrels\"))) %>%\n  bind_cols(feeder_train %>% select(squirrels))\n\nfeeder_train_pred\n\n# A tibble: 176,763 × 4\n   `.pred_no squirrels` .pred_squirrels .pred_class squirrels   \n                  <dbl>           <dbl> <fct>       <fct>       \n 1                0.168           0.832 squirrels   no squirrels\n 2                0.168           0.832 squirrels   no squirrels\n 3                0.358           0.642 squirrels   no squirrels\n 4                0.166           0.834 squirrels   no squirrels\n 5                0.274           0.726 squirrels   no squirrels\n 6                0.191           0.809 squirrels   no squirrels\n 7                0.288           0.712 squirrels   no squirrels\n 8                0.184           0.816 squirrels   no squirrels\n 9                0.227           0.773 squirrels   no squirrels\n10                0.350           0.650 squirrels   no squirrels\n# … with 176,753 more rows"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#accuracy",
    "href": "handout/2023-02-21-tidymodels.html#accuracy",
    "title": "Tidymodels",
    "section": "Accuracy",
    "text": "Accuracy\n\nrbind(accuracy(feeder_train_pred, truth = squirrels, \n               estimate = .pred_class),\n      sensitivity(feeder_train_pred, truth = squirrels, \n                  estimate = .pred_class, event_level = \"second\"),\n      specificity(feeder_train_pred, truth = squirrels, \n                  estimate = .pred_class, event_level = \"second\"))\n\n# A tibble: 3 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary         0.815\n2 sensitivity binary         0.985\n3 specificity binary         0.101"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#visualizing-accuracy",
    "href": "handout/2023-02-21-tidymodels.html#visualizing-accuracy",
    "title": "Tidymodels",
    "section": "Visualizing accuracy",
    "text": "Visualizing accuracy\n\nfeeder_train_pred %>%\n  select(squirrels, .pred_class) %>%\n  yardstick::conf_mat(squirrels, .pred_class) %>%\n  autoplot(type = \"heatmap\") + \n  scale_fill_gradient(low=\"#D6EAF8\", high=\"#2E86C1\")"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#but-really",
    "href": "handout/2023-02-21-tidymodels.html#but-really",
    "title": "Tidymodels",
    "section": "But, really…",
    "text": "But, really…\nwho cares about predictions on training data?"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#make-predictions-for-testing-data",
    "href": "handout/2023-02-21-tidymodels.html#make-predictions-for-testing-data",
    "title": "Tidymodels",
    "section": "Make predictions for testing data",
    "text": "Make predictions for testing data\n\nfeeder_test_pred <- predict(feeder_fit, feeder_test, type = \"prob\") %>%\n  mutate(.pred_class = as.factor(ifelse(.pred_squirrels >=0.5,\n                                        \"squirrels\", \"no squirrels\"))) %>%\n  bind_cols(feeder_test %>% select(squirrels))\n\nfeeder_test_pred\n\n# A tibble: 58,922 × 4\n   `.pred_no squirrels` .pred_squirrels .pred_class squirrels   \n                  <dbl>           <dbl> <fct>       <fct>       \n 1               0.201            0.799 squirrels   no squirrels\n 2               0.156            0.844 squirrels   no squirrels\n 3               0.352            0.648 squirrels   no squirrels\n 4               0.197            0.803 squirrels   squirrels   \n 5               0.121            0.879 squirrels   squirrels   \n 6               0.272            0.728 squirrels   squirrels   \n 7               0.0459           0.954 squirrels   squirrels   \n 8               0.0341           0.966 squirrels   squirrels   \n 9               0.0631           0.937 squirrels   squirrels   \n10               0.0312           0.969 squirrels   squirrels   \n# … with 58,912 more rows"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#evaluate-performance-for-testing-data",
    "href": "handout/2023-02-21-tidymodels.html#evaluate-performance-for-testing-data",
    "title": "Tidymodels",
    "section": "Evaluate performance for testing data",
    "text": "Evaluate performance for testing data\n\nrbind(accuracy(feeder_test_pred, truth = squirrels, estimate = .pred_class),\n      sensitivity(feeder_test_pred, truth = squirrels, estimate = .pred_class),\n      specificity(feeder_test_pred, truth = squirrels, estimate = .pred_class))\n\n# A tibble: 3 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary        0.814 \n2 sensitivity binary        0.0988\n3 specificity binary        0.985 \n\n\n\n\nfeeder_test_pred %>%\n  select(squirrels, .pred_class) %>%\n  yardstick::conf_mat(squirrels, .pred_class) %>%\n  autoplot(type = \"heatmap\") + \n  scale_fill_gradient(low=\"#D6EAF8\", high=\"#2E86C1\")"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#training-vs.-testing",
    "href": "handout/2023-02-21-tidymodels.html#training-vs.-testing",
    "title": "Tidymodels",
    "section": "Training vs. testing",
    "text": "Training vs. testing\n\n\n# A tibble: 3 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary         0.815\n2 sensitivity binary         0.985\n3 specificity binary         0.101\n\n\n# A tibble: 3 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary        0.814 \n2 sensitivity binary        0.985 \n3 specificity binary        0.0988"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#evaluating-performance-on-training-data",
    "href": "handout/2023-02-21-tidymodels.html#evaluating-performance-on-training-data",
    "title": "Tidymodels",
    "section": "Evaluating performance on training data",
    "text": "Evaluating performance on training data\n\nThe training set does not have the capacity to be a good arbiter of performance.\nIt is not an independent piece of information; predicting the training set can only reflect what the model already knows.\nSuppose you give a class a test, then give them the answers, then provide the same test. The student scores on the second test do not accurately reflect what they know about the subject; these scores would probably be higher than their results on the first test.\n\n\n\n\nhttps://m150-method-biostat.netlify.app/"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#evaluate-testing-data",
    "href": "handout/2023-02-21-tidymodels.html#evaluate-testing-data",
    "title": "Tidymodels",
    "section": "Evaluate testing data",
    "text": "Evaluate testing data\n\nrbind(accuracy(feeder_test_pred, truth = squirrels, \n               estimate = .pred_class),\n      sensitivity(feeder_test_pred, truth = squirrels, \n                  estimate = .pred_class, event_level = \"second\"),\n      specificity(feeder_test_pred, truth = squirrels, \n                  estimate = .pred_class, event_level = \"second\"))\n\n# A tibble: 3 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary        0.814 \n2 sensitivity binary        0.985 \n3 specificity binary        0.0988"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#evaluate-testing-data-1",
    "href": "handout/2023-02-21-tidymodels.html#evaluate-testing-data-1",
    "title": "Tidymodels",
    "section": "Evaluate testing data",
    "text": "Evaluate testing data\n\nfeeder_test_pred %>%\n  select(squirrels, .pred_class) %>%\n  yardstick::conf_mat(squirrels, .pred_class) %>%\n  autoplot(type = \"heatmap\") + \n  scale_fill_gradient(low=\"#D6EAF8\", high=\"#2E86C1\")"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html",
    "href": "handout/2023-02-21-tidymodels.html",
    "title": "Tidymodels",
    "section": "",
    "text": "Workflow to help us think about model building\nBreaking up data for independent assessment\nAssessment metrics\n\n\n\n# load packages\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.0 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.2     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.0.1     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.3     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(gghighlight)\nlibrary(knitr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#whats-up-with-training-data",
    "href": "handout/2023-02-21-tidymodels.html#whats-up-with-training-data",
    "title": "Tidymodels",
    "section": "What’s up with training data?",
    "text": "What’s up with training data?\n\nThe training set does not have the capacity to be a good arbiter of performance.\nIt is not an independent piece of information; predicting the training set can only reflect what the model already knows.\nSuppose you give a class a test, then give them the answers, then provide the same test. The student scores on the second test do not accurately reflect what they know about the subject; these scores would probably be higher than their results on the first test."
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#competing-models",
    "href": "handout/2023-02-21-tidymodels.html#competing-models",
    "title": "Tidymodels",
    "section": "Competing models",
    "text": "Competing models\n\nwe use the test data to assess how the model does. But we haven’t yet thought about how to use the data to build a particular model.\ncompare two different models to predict whether or not there are squirrels\n\nModel 1: removes the information about the habitat and about the trees and shrubs\nModel 2: removes the information about feeding the birds"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#compare-recipes",
    "href": "handout/2023-02-21-tidymodels.html#compare-recipes",
    "title": "Tidymodels",
    "section": "Compare recipes",
    "text": "Compare recipes\n\nrecipe 1recipe 2\n\n\n\nfeeder_rec1 <- recipe(squirrels ~ ., data = feeder_train) %>%\n  # delete the habitat variables\n  step_rm(contains(\"hab\")) %>%\n  # delete the tree/shrub info\n  step_rm(contains(\"atleast\")) %>%\n  step_impute_mean(all_numeric_predictors()) %>%\n  step_nzv(all_numeric_predictors())\n\n\n\n\nfeeder_rec2 <- recipe(squirrels ~ ., data = feeder_train) %>%\n  # delete the variables on when the birds were fed\n  step_rm(contains(\"fed\")) %>%\n  # delete the variables about the bird feeders\n  step_rm(contains(\"feed\")) %>%\n  step_impute_mean(all_numeric_predictors()) %>%\n  step_nzv(all_numeric_predictors())"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#recipe-1",
    "href": "handout/2023-02-21-tidymodels.html#recipe-1",
    "title": "Tidymodels",
    "section": "recipe 1",
    "text": "recipe 1"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#recipe-2",
    "href": "handout/2023-02-21-tidymodels.html#recipe-2",
    "title": "Tidymodels",
    "section": "recipe 2",
    "text": "recipe 2\n\n\n\n\n\n\nhttps://m150-method-biostat.netlify.app/"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#how-can-we-decide",
    "href": "handout/2023-02-21-tidymodels.html#how-can-we-decide",
    "title": "Tidymodels",
    "section": "How can we decide?",
    "text": "How can we decide?\n\nmeasure which model does better on the test data\nmeasure which model does better on the training data\nmeasure which model does better on the cross validated data"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#cross-validation-1",
    "href": "handout/2023-02-21-tidymodels.html#cross-validation-1",
    "title": "Tidymodels",
    "section": "Cross validation",
    "text": "Cross validation\nMore specifically, v-fold cross validation:\n\nRandomly partition the training data into v group\nUse v-1 groups to build the model (calculate MLEs); use 1 group for prediction / assessment\nRepeat v times, updating which group is used for assessment each time"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#cross-validation-step-1",
    "href": "handout/2023-02-21-tidymodels.html#cross-validation-step-1",
    "title": "Tidymodels",
    "section": "Cross validation, step 1",
    "text": "Cross validation, step 1\nConsider the example below where the training data are randomly split into 3 partitions:\n\nSplitting the data into a partition of v=3 groups. Source: (Kuhn and Silge 2022)"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#all-together",
    "href": "handout/2023-02-21-tidymodels.html#all-together",
    "title": "Tidymodels",
    "section": "All together",
    "text": "All together\n\nrecipemodelworkflowfitpredict\n\n\n\nfeeder_rec <- recipe(\n  squirrels ~ .,    # formula\n  data = feeder_train \n  ) %>%\n  step_impute_mean(all_numeric_predictors()) %>%\n  step_nzv(all_numeric_predictors())\n\nfeeder_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         58\n\nOperations:\n\nMean imputation for all_numeric_predictors()\nSparse, unbalanced variable filter on all_numeric_predictors()\n\n\n\n\n\nfeeder_log <- logistic_reg() %>%\n  set_engine(\"glm\")\n\nfeeder_log\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\n\nfeeder_wflow <- workflow() %>%\n  add_recipe(feeder_rec) %>%\n  add_model(feeder_log) \nfeeder_wflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_impute_mean()\n• step_nzv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\n\nfeeder_fit <- feeder_wflow %>%\n  fit(data = feeder_train)\n\nfeeder_fit %>% tidy()\n\n# A tibble: 59 × 5\n   term               estimate std.error statistic   p.value\n   <chr>                 <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)         -1.42      0.0505    -28.2  2.26e-174\n 2 yard_type_pavement  -0.854     0.149      -5.74 9.23e-  9\n 3 yard_type_garden    -0.175     0.0392     -4.47 7.89e-  6\n 4 yard_type_landsca    0.168     0.0219      7.69 1.45e- 14\n 5 yard_type_woods      0.309     0.0170     18.1  1.59e- 73\n 6 yard_type_desert    -0.297     0.0789     -3.76 1.68e-  4\n 7 hab_dcid_woods       0.336     0.0161     20.9  6.55e- 97\n 8 hab_evgr_woods      -0.0797    0.0192     -4.15 3.36e-  5\n 9 hab_mixed_woods      0.420     0.0158     26.5  3.17e-155\n10 hab_orchard         -0.307     0.0252    -12.2  4.00e- 34\n# … with 49 more rows\n\n\n\n\n\nfeeder_train_pred <- predict(feeder_fit, feeder_train, type = \"prob\") %>%\n  mutate(.pred_class = as.factor(ifelse(.pred_squirrels >=0.5,\n                                        \"squirrels\", \"no squirrels\"))) %>%\n  bind_cols(feeder_train %>% select(squirrels))\n\nfeeder_train_pred\n\n# A tibble: 176,763 × 4\n   `.pred_no squirrels` .pred_squirrels .pred_class squirrels   \n                  <dbl>           <dbl> <fct>       <fct>       \n 1                0.168           0.832 squirrels   no squirrels\n 2                0.168           0.832 squirrels   no squirrels\n 3                0.358           0.642 squirrels   no squirrels\n 4                0.166           0.834 squirrels   no squirrels\n 5                0.274           0.726 squirrels   no squirrels\n 6                0.191           0.809 squirrels   no squirrels\n 7                0.288           0.712 squirrels   no squirrels\n 8                0.184           0.816 squirrels   no squirrels\n 9                0.227           0.773 squirrels   no squirrels\n10                0.350           0.650 squirrels   no squirrels\n# … with 176,753 more rows"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#cross-validation-steps-2-and-3",
    "href": "handout/2023-02-21-tidymodels.html#cross-validation-steps-2-and-3",
    "title": "Tidymodels",
    "section": "Cross validation, steps 2 and 3",
    "text": "Cross validation, steps 2 and 3\n\nUse 1 partition for assessment, and the remaining v-1 partitions for analysis\nRepeat v times, updating which partition is used for assessment each time\n\n\nWith the data split into three groups, we can see how 2/3 of the observations are used to fit the model and 1/3 of the observations are used to estimate the performance of the model. Source: (Kuhn and Silge 2022)"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#cross-validation-using-tidymodels",
    "href": "handout/2023-02-21-tidymodels.html#cross-validation-using-tidymodels",
    "title": "Tidymodels",
    "section": "Cross validation using tidymodels",
    "text": "Cross validation using tidymodels\n\nset.seed(4747)\nfolds <- vfold_cv(feeder_train, v = 3, strata = squirrels)\nfolds\n\n#  3-fold cross-validation using stratification \n# A tibble: 3 × 2\n  splits                 id   \n  <list>                 <chr>\n1 <split [117841/58922]> Fold1\n2 <split [117842/58921]> Fold2\n3 <split [117843/58920]> Fold3"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#cross-validation-then-test-data",
    "href": "handout/2023-02-21-tidymodels.html#cross-validation-then-test-data",
    "title": "Tidymodels",
    "section": "Cross validation then test data",
    "text": "Cross validation then test data\n\nNested cross-validation: two cross-validation loops are run one inside the other. (Varoquaux et al. 2017)"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#bias-variance-trade-off",
    "href": "handout/2023-02-21-tidymodels.html#bias-variance-trade-off",
    "title": "Tidymodels",
    "section": "Bias-variance trade-off",
    "text": "Bias-variance trade-off\n\nTest and training error as a function of model complexity. Note that the error goes down monotonically only for the training data. Be careful not to overfit!! (Hastie, Tibshirani, and Friedman 2001)"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#all-together-1",
    "href": "handout/2023-02-21-tidymodels.html#all-together-1",
    "title": "Tidymodels",
    "section": "All together",
    "text": "All together\n\nrecipemodelworkflowfitpredictassess\n\n\n\nfeeder_rec <- recipe(\n  squirrels ~ .,    # formula\n  data = feeder_train \n  ) %>%\n  step_impute_mean(all_numeric_predictors()) %>%\n  step_nzv(all_numeric_predictors())\n\nfeeder_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         58\n\nOperations:\n\nMean imputation for all_numeric_predictors()\nSparse, unbalanced variable filter on all_numeric_predictors()\n\n\n\n\n\nfeeder_log <- logistic_reg() %>%\n  set_engine(\"glm\")\n\nfeeder_log\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\n\nfeeder_wflow <- workflow() %>%\n  add_recipe(feeder_rec) %>%\n  add_model(feeder_log) \n\nfeeder_wflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_impute_mean()\n• step_nzv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\n\nfeeder_fit <- feeder_wflow %>%\n  fit(data = feeder_train)\n\nfeeder_fit %>% tidy()\n\n# A tibble: 59 × 5\n   term               estimate std.error statistic   p.value\n   <chr>                 <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)         -1.42      0.0505    -28.2  2.26e-174\n 2 yard_type_pavement  -0.854     0.149      -5.74 9.23e-  9\n 3 yard_type_garden    -0.175     0.0392     -4.47 7.89e-  6\n 4 yard_type_landsca    0.168     0.0219      7.69 1.45e- 14\n 5 yard_type_woods      0.309     0.0170     18.1  1.59e- 73\n 6 yard_type_desert    -0.297     0.0789     -3.76 1.68e-  4\n 7 hab_dcid_woods       0.336     0.0161     20.9  6.55e- 97\n 8 hab_evgr_woods      -0.0797    0.0192     -4.15 3.36e-  5\n 9 hab_mixed_woods      0.420     0.0158     26.5  3.17e-155\n10 hab_orchard         -0.307     0.0252    -12.2  4.00e- 34\n# … with 49 more rows\n\n\n\n\n\nfeeder_test_pred <- predict(feeder_fit, feeder_test, type = \"prob\") %>%\n  mutate(.pred_class = as.factor(ifelse(.pred_squirrels >=0.5,\n                                        \"squirrels\", \"no squirrels\"))) %>%\n  bind_cols(feeder_test %>% select(squirrels))\n\nfeeder_train_pred\n\n# A tibble: 176,763 × 4\n   `.pred_no squirrels` .pred_squirrels .pred_class squirrels   \n                  <dbl>           <dbl> <fct>       <fct>       \n 1                0.168           0.832 squirrels   no squirrels\n 2                0.168           0.832 squirrels   no squirrels\n 3                0.358           0.642 squirrels   no squirrels\n 4                0.166           0.834 squirrels   no squirrels\n 5                0.274           0.726 squirrels   no squirrels\n 6                0.191           0.809 squirrels   no squirrels\n 7                0.288           0.712 squirrels   no squirrels\n 8                0.184           0.816 squirrels   no squirrels\n 9                0.227           0.773 squirrels   no squirrels\n10                0.350           0.650 squirrels   no squirrels\n# … with 176,753 more rows\n\n\n\n\n\nrbind(accuracy(feeder_test_pred, truth = squirrels, estimate = .pred_class),\n      sensitivity(feeder_test_pred, truth = squirrels, estimate = .pred_class),\n      specificity(feeder_test_pred, truth = squirrels, estimate = .pred_class))\n\n# A tibble: 3 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary        0.814 \n2 sensitivity binary        0.0988\n3 specificity binary        0.985"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#fit-the-model-separately-to-each-fold",
    "href": "handout/2023-02-21-tidymodels.html#fit-the-model-separately-to-each-fold",
    "title": "Tidymodels",
    "section": "Fit the model separately to each fold",
    "text": "Fit the model separately to each fold\n\nrecipemodelworkflowfitpredictassess\n\n\n\nfeeder_rec1 <- recipe(squirrels ~ ., data = feeder_train) %>%\n  # delete the habitat variables\n  step_rm(contains(\"hab\")) %>%\n  # delete the tree/shrub info\n  step_rm(contains(\"atleast\")) %>%\n  step_impute_mean(all_numeric_predictors()) %>%\n  step_nzv(all_numeric_predictors())\n\nfeeder_rec1\n\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         58\n\nOperations:\n\nVariables removed contains(\"hab\")\nVariables removed contains(\"atleast\")\nMean imputation for all_numeric_predictors()\nSparse, unbalanced variable filter on all_numeric_predictors()\n\n\n\n\n\nfeeder_log <- logistic_reg() %>%\n  set_engine(\"glm\")\n\nfeeder_log\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\n\nfeeder_wflow1 <- workflow() %>%\n  add_recipe(feeder_rec1) %>%\n  add_model(feeder_log) \n\nfeeder_wflow1\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_rm()\n• step_rm()\n• step_impute_mean()\n• step_nzv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\n\nmetrics_interest <- metric_set(accuracy, roc_auc, \n                              sensitivity, specificity)\n\nfeeder_fit_rs1 <- feeder_wflow1 %>%\n  fit_resamples(resamples = folds,\n                metrics = metrics_interest,\n                control = control_resamples(save_pred = TRUE,\n                                            event_level = \"second\"))\n\n\n\n\nfeeder_fit_rs1 %>% augment() %>%\n  select(squirrels, .pred_class) %>%\n  yardstick::conf_mat(squirrels, .pred_class) %>%\n  autoplot(type = \"heatmap\") + \n  scale_fill_gradient(low=\"#D6EAF8\", high=\"#2E86C1\") \n\n\n\n\n\n\n\n\n\n\n\ncollect_metrics(feeder_fit_rs1)\n\n# A tibble: 4 × 6\n  .metric     .estimator   mean     n  std_err .config             \n  <chr>       <chr>       <dbl> <int>    <dbl> <chr>               \n1 accuracy    binary     0.809      3 0.000247 Preprocessor1_Model1\n2 roc_auc     binary     0.663      3 0.00180  Preprocessor1_Model1\n3 sensitivity binary     0.996      3 0.000190 Preprocessor1_Model1\n4 specificity binary     0.0265     3 0.000545 Preprocessor1_Model1"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#repeat-the-cv-analysis-for-the-second-model",
    "href": "handout/2023-02-21-tidymodels.html#repeat-the-cv-analysis-for-the-second-model",
    "title": "Tidymodels",
    "section": "Repeat the CV analysis for the second model",
    "text": "Repeat the CV analysis for the second model\n\nrecipemodelworkflowfitpredictassess\n\n\n\nfeeder_rec2 <- recipe(squirrels ~ ., data = feeder_train) %>%\n  # delete the variables on when the birds were fed\n  step_rm(contains(\"fed\")) %>%\n  # delete the variables about the bird feeders\n  step_rm(contains(\"feed\")) %>%\n  step_impute_mean(all_numeric_predictors()) %>%\n  step_nzv(all_numeric_predictors())\n\nfeeder_rec2\n\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         58\n\nOperations:\n\nVariables removed contains(\"fed\")\nVariables removed contains(\"feed\")\nMean imputation for all_numeric_predictors()\nSparse, unbalanced variable filter on all_numeric_predictors()\n\n\n\n\n\nfeeder_log <- logistic_reg() %>%\n  set_engine(\"glm\")\n\nfeeder_log\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\n\nfeeder_wflow2 <- workflow() %>%\n  add_recipe(feeder_rec2) %>%\n  add_model(feeder_log) \n\nfeeder_wflow2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_rm()\n• step_rm()\n• step_impute_mean()\n• step_nzv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\n\nmetrics_interest <- metric_set(accuracy, roc_auc, \n                              sensitivity, specificity)\n\nfeeder_fit_rs2 <- feeder_wflow2 %>%\n  fit_resamples(resamples = folds,\n                metrics = metrics_interest,\n                control = control_resamples(save_pred = TRUE,\n                                            event_level = \"second\"))\n\n\n\n\nfeeder_fit_rs2 %>% augment() %>%\n  select(squirrels, .pred_class) %>%\n  yardstick::conf_mat(squirrels, .pred_class) %>%\n  autoplot(type = \"heatmap\") + \n  scale_fill_gradient(low=\"#D6EAF8\", high=\"#2E86C1\") \n\n\n\n\n\n\n\n\n\n\n\ncollect_metrics(feeder_fit_rs2)\n\n# A tibble: 4 × 6\n  .metric     .estimator   mean     n  std_err .config             \n  <chr>       <chr>       <dbl> <int>    <dbl> <chr>               \n1 accuracy    binary     0.813      3 0.000325 Preprocessor1_Model1\n2 roc_auc     binary     0.698      3 0.00228  Preprocessor1_Model1\n3 sensitivity binary     0.990      3 0.000424 Preprocessor1_Model1\n4 specificity binary     0.0693     3 0.000291 Preprocessor1_Model1"
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#how-does-cross-validation-work",
    "href": "handout/2023-02-21-tidymodels.html#how-does-cross-validation-work",
    "title": "Tidymodels",
    "section": "How does cross validation work?",
    "text": "How does cross validation work?\n\n4-fold CV is depicted. Notice that the holdout group is never used as part of the coefficient estimation process."
  },
  {
    "objectID": "handout/2023-02-21-tidymodels.html#compare-two-models",
    "href": "handout/2023-02-21-tidymodels.html#compare-two-models",
    "title": "Tidymodels",
    "section": "Compare two models",
    "text": "Compare two models\nModel 1\n\ncollect_metrics(feeder_fit_rs1)\n\n# A tibble: 4 × 6\n  .metric     .estimator   mean     n  std_err .config             \n  <chr>       <chr>       <dbl> <int>    <dbl> <chr>               \n1 accuracy    binary     0.809      3 0.000247 Preprocessor1_Model1\n2 roc_auc     binary     0.663      3 0.00180  Preprocessor1_Model1\n3 sensitivity binary     0.996      3 0.000190 Preprocessor1_Model1\n4 specificity binary     0.0265     3 0.000545 Preprocessor1_Model1\n\n\nModel 2\n\ncollect_metrics(feeder_fit_rs2)\n\n# A tibble: 4 × 6\n  .metric     .estimator   mean     n  std_err .config             \n  <chr>       <chr>       <dbl> <int>    <dbl> <chr>               \n1 accuracy    binary     0.813      3 0.000325 Preprocessor1_Model1\n2 roc_auc     binary     0.698      3 0.00228  Preprocessor1_Model1\n3 sensitivity binary     0.990      3 0.000424 Preprocessor1_Model1\n4 specificity binary     0.0693     3 0.000291 Preprocessor1_Model1"
  },
  {
    "objectID": "handout/HW6_m150_s23.html",
    "href": "handout/HW6_m150_s23.html",
    "title": "Math 150 - Methods in Biostatistics - Homework 6",
    "section": "",
    "text": "Assignment Summary (Goals)\n\nconsiderations of working with variables\nfluent use of the multiple logistic model for prediction using the tidymodels framework\n\nNote that if you don’t know the R code either check the class notes or ask me!!! Happy to scaffold, debug, send resources, etc. Don’t go down a rabbit hole trying to figure out an R function or syntax.\nAlso, note that you’ll need to get the data from Canvas and use it for this analysis. Look back to your own HW1 file to see the line of code you used to import the games1.csv dataset. Ask me if it isn’t obvious to you after you look at your own HW1.\n\nQ1. Collaborative Learning\nDescribe one thing you learned from someone (a fellow student or mentor) in our class this week (it could be: content, logistical help, background material, R information, etc.) 1-3 sentences.\n\n\nQ2. And the Winner Is…\nThe data this week come from kaggle as a compilation form Academy Award winners since the award began. https://www.kaggle.com/datasets/unanimad/the-oscar-award\nThe data wrangling below are an effort to consolidate the labels so that the variables measure the same over basic quality over the last 95 years. https://www.verdict.co.uk/oscars-90-whats-changed-years-oscars-records/\nThe dataset is in the files tab on Canvas (in a folder called “data”).\n\n# the only thing you should change in this R chunk is \n# the path of the dataset\nthe_oscar <- readr::read_csv(\"~/Dropbox/teaching/MA150/the_oscar_award.csv\") %>%\n  rename(year = year_ceremony) %>%\n  filter(year != 2022) %>%\n  select(-year_film, -ceremony, -name) %>%\n  drop_na() %>%\n  mutate(winner = case_when(\n    winner == TRUE ~ 1,\n    winner == FALSE ~ 0\n  )) %>%\n  distinct(category, film, .keep_all = TRUE) %>%\n  mutate(category = case_when(\n    category == \"OUTSTANDING PICTURE\" ~ \"BEST PICTURE\",\n    category == \"OUTSTANDING MOTION PICTURE\" ~ \"BEST PICTURE\",\n    category == \"OUTSTANDING PRODUCTION\" ~ \"BEST PICTURE\",\n    category == \"BEST MOTION PICTURE\" ~ \"BEST PICTURE\",\n    category == \"ACTOR\" ~ \"ACTOR IN A LEADING ROLE\",\n    category == \"ACTRESS\" ~ \"ACTRESS IN A LEADING ROLE\",\n    category == \"INTERNATIONAL FEATURE FILM\" ~ \"FOREIGN LANGUAGE FILM\",\n    str_detect(category, \"DIRECTING\") ~ \"DIRECTING\",\n    str_detect(category, \"WRITING\") ~ \"WRITING\",\n    str_detect(category, \"VISUAL EFFECTS\") ~ \"VISUAL EFFECTS\",\n    str_detect(category, \"SOUND\") ~ \"SOUND\",\n    str_detect(category, \"SHORT SUBJECT\") ~ \"SHORT SUBJECT\",\n    str_detect(category, \"SHORT FILM\") ~ \"SHORT FILM\",\n    str_detect(category, \"MUSIC\") ~ \"MUSIC\",\n    str_detect(category, \"MAKEUP\") ~ \"MAKEUP\",\n    str_detect(category, \"DOCUMENTARY\") ~ \"DOCUMENTARY\",\n    str_detect(category, \"COSTUME DESIGN\") ~ \"COSTUME DESIGN\",\n    str_detect(category, \"CINEMATOGRAPHY\") ~ \"CINEMATOGRAPHY\",\n    str_detect(category, \"ART DIRECTION\") ~ \"ART DIRECTION\",\n    str_detect(category, \"PRODUCTION\") ~ \"PRODUCTION\",\n    TRUE ~ category)) %>%\n  filter(!(category %in% c(\"OUTSTANDING PICUTRE\",\n                         \"UNIQUE AND ARTISTIC PICTURE\",\n                         \"SPECIAL ACHIEVEMENT AWARD (Sound Effects)\",\n                         \"SPECIAL ACHIEVEMENT AWARD (Visual Effects)\",\n                         \"SPECIAL ACHIEVEMENT AWARD (Sound Effects Editing)\",\n                         \"SPECIAL ACHIEVEMENT AWARD (Sound Editing)\",\n                         \"ENGINEERING EFFECTS\",\n                         \"DANCE DIRECTION\",\n                         \"ASSISTANT DIRECTOR\"\n                         ))) %>%\n  group_by(film, category) %>%\n  arrange(desc(winner)) %>%\n  filter(row_number() == 1) %>%\n  ungroup() %>%\n  pivot_wider(id_cols = c(\"year\", \"film\"),\n              names_from = category, values_from = winner,\n              values_fill = 0) %>%\n  janitor::clean_names() %>%\n  mutate(best_picture = as.factor(ifelse(best_picture == 1, \"win\", \"not win\")))\n\n\nCreate a logistic regression model using all the explanatory variables except film (which is the title of the film).\n\nUse the framework from tidymodels which consists of the following steps:\n\nsplit the data into test training. you likely want to stratify on best_picture (because the dataset is very imbalanced).\nbuild a recipe. to communicate that you don’t consider film to be an identifier, add the following step to your recipe: update_role(film, new_role = \"ID\")\nset the model to be logistic regression\nfit the model on the training data\ntidy the model to see the coefficients / p-values\n\n\nThe glm.fit likely said that the fitted probabilities were numerically 0 or 1. Check the following three probability of best picture win: Cinema Paradiso, Parasite, The Hurt Locker (you’ll likely need to Google / look at wikipedia).\nUse the test data to predict whether or not each of the test movies will win an Academy Award for Best Picture. Summarize using accuracy, sensitivity, and specificity (here “successes” is “win”). Feel free to also make a plot to describe the table of predictions.\n\nNot due, but maybe fun? (d) Is your model able to predict the winner for best picture from 2022? (The dataset only goes up until 2021, so you’ll need to find the relevant information from the Google.)\n\n\nQ3. And the Winner Is…\nContinue to use the data on the Academy Awards. Using 10-fold Cross Validation, compare the following two models:\n\nA model based only on the four actor awards, makeup, and music\nA model based only on directing and writing\n\n\nBuild the models on the training data only using cross validation. (Note: in the formula add the variables and also add + film before updating the film role to be only an ID.)\nCross validate to assess which model is better. Choose a model based on overall accuracy. Commit to that model using only the training data. Which model did you choose?\nWhat do you think the accuracy of the model (from part (b)) will be when you apply your model in the real world? That is, use the variables from part (b), train the model using the training data, test the model using the test data.\n\n\n\nQ4. Voting\nAnother dataset which could have been used for this HW set was a dataset that comes from 538 on voting behavior. See the information about the dataset here: https://github.com/fivethirtyeight/data/tree/master/non-voters and the article about it here: https://projects.fivethirtyeight.com/non-voters-poll-2020-election/.\nIf you want, you can also import the data into R using the following code.\n\nvoters <- read_csv(\"https://raw.githubusercontent.com/fivethirtyeight/data/master/non-voters/nonvoters_data.csv\")\n\nConsider the following variables:\n\nQ21: do you plan to vote in Nov 2020?\nQ30: which political party do you consider yourself aligned with?\nINCOME_CAT: household income category\n\nFor each variable, explain (in words, no code here) how the variable would need to be transformed to be able to be used in the logistic regression model.\n\npraise()\n\n[1] \"You are wicked!\"\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#agenda",
    "href": "handout/2023-02-27-ROC-onestep.html#agenda",
    "title": "Tidymodels",
    "section": "Agenda",
    "text": "Agenda\n\n\nMetric: Receiver Operating Characteristic (ROC) Curves\nMetrics: AIC & BIC\nModel building one variables at a time"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#make-predictions-for-test-data",
    "href": "handout/2023-02-27-ROC-onestep.html#make-predictions-for-test-data",
    "title": "Tidymodels",
    "section": "Make predictions for test data",
    "text": "Make predictions for test data\n\nfeeder_test_pred <- predict(feeder_fit, feeder_test, type = \"prob\") %>%\n  mutate(.pred_class = as.factor(ifelse(.pred_squirrels >=0.5,\n                                        \"squirrels\", \"no squirrels\"))) %>%\n  bind_cols(feeder_test %>% select(squirrels))\n\nfeeder_test_pred\n\n# A tibble: 58,922 × 4\n   `.pred_no squirrels` .pred_squirrels .pred_class squirrels   \n                  <dbl>           <dbl> <fct>       <fct>       \n 1               0.201            0.799 squirrels   no squirrels\n 2               0.156            0.844 squirrels   no squirrels\n 3               0.352            0.648 squirrels   no squirrels\n 4               0.197            0.803 squirrels   squirrels   \n 5               0.121            0.879 squirrels   squirrels   \n 6               0.272            0.728 squirrels   squirrels   \n 7               0.0459           0.954 squirrels   squirrels   \n 8               0.0341           0.966 squirrels   squirrels   \n 9               0.0631           0.937 squirrels   squirrels   \n10               0.0312           0.969 squirrels   squirrels   \n# … with 58,912 more rows"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#accuracy",
    "href": "handout/2023-02-27-ROC-onestep.html#accuracy",
    "title": "Tidymodels",
    "section": "Accuracy",
    "text": "Accuracy\n\nrbind(accuracy(feeder_test_pred, truth = squirrels, \n               estimate = .pred_class),\n      sensitivity(feeder_test_pred, truth = squirrels, \n                  estimate = .pred_class, event_level = \"second\"),\n      specificity(feeder_test_pred, truth = squirrels, \n                  estimate = .pred_class, event_level = \"second\"),\n      roc_auc(feeder_test_pred, truth = squirrels, \n                  estimate = .pred_squirrels, event_level = \"second\"))\n\n# A tibble: 4 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary        0.814 \n2 sensitivity binary        0.985 \n3 specificity binary        0.0988\n4 roc_auc     binary        0.721"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#roc-curves",
    "href": "handout/2023-02-27-ROC-onestep.html#roc-curves",
    "title": "Tidymodels",
    "section": "ROC Curves",
    "text": "ROC Curves\nReceiver Operating Characteristic Curves\n\nTPR = sensitivity = # of true predicted true / # true\nFPR = 1 - specificity = # false predicted true / # false\n\nHow can the plot use many TPRs and FPRs ???"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#visualizing-accuracy",
    "href": "handout/2023-02-27-ROC-onestep.html#visualizing-accuracy",
    "title": "Tidymodels",
    "section": "Visualizing accuracy",
    "text": "Visualizing accuracy\n\n\n# A tibble: 4 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary        0.814 \n2 sensitivity binary        0.985 \n3 specificity binary        0.0988\n4 roc_auc     binary        0.721"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#different-cut-off-0.8",
    "href": "handout/2023-02-27-ROC-onestep.html#different-cut-off-0.8",
    "title": "Tidymodels",
    "section": "Different cut-off = 0.8?",
    "text": "Different cut-off = 0.8?\n\nfeeder_test_pred <- predict(feeder_fit, feeder_test, type = \"prob\") %>%\n  mutate(.pred_class = as.factor(ifelse(.pred_squirrels >=0.8,\n                                        \"squirrels\", \"no squirrels\"))) %>%\n  bind_cols(feeder_test %>% select(squirrels))\n\n\n\n# A tibble: 4 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary         0.675\n2 sensitivity binary         0.683\n3 specificity binary         0.641\n4 roc_auc     binary         0.721"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#different-cut-off-0.15",
    "href": "handout/2023-02-27-ROC-onestep.html#different-cut-off-0.15",
    "title": "Tidymodels",
    "section": "Different cut-off = 0.15?",
    "text": "Different cut-off = 0.15?\n\nfeeder_test_pred <- predict(feeder_fit, feeder_test, type = \"prob\") %>%\n  mutate(.pred_class = as.factor(ifelse(.pred_squirrels >=0.15,\n                                        \"squirrels\", \"no squirrels\"))) %>%\n  bind_cols(feeder_test %>% select(squirrels))\n\n\n\n# A tibble: 4 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary       0.807  \n2 sensitivity binary       0.999  \n3 specificity binary       0.00141\n4 roc_auc     binary       0.721"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#roc-curve",
    "href": "handout/2023-02-27-ROC-onestep.html#roc-curve",
    "title": "Tidymodels",
    "section": "ROC Curve",
    "text": "ROC Curve"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#roc-curve-1",
    "href": "handout/2023-02-27-ROC-onestep.html#roc-curve-1",
    "title": "Tidymodels",
    "section": "ROC Curve",
    "text": "ROC Curve\n\nroc_auc(feeder_test_pred, truth = squirrels, \n                  estimate = .pred_squirrels, event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.721\n\n\n\nTo get a single value (for model comparison), we use the area under the ROC curve."
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#area-over-the-curve",
    "href": "handout/2023-02-27-ROC-onestep.html#area-over-the-curve",
    "title": "Tidymodels",
    "section": "Area Over the Curve",
    "text": "Area Over the Curve\n\nAlexandria Ocasio-Cortez as Area Over the Curve. I didn’t make the image, and I don’t know who did!"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html",
    "href": "handout/2023-02-27-ROC-onestep.html",
    "title": "Tidymodels",
    "section": "",
    "text": "New metric: Receiver Operating Characteristic (ROC) Curves\nModel building one variables at a time\n\n\n\n# load packages\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.0 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.2     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.0.1     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.3     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(gghighlight)\nlibrary(knitr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#more-metrics",
    "href": "handout/2023-02-27-ROC-onestep.html#more-metrics",
    "title": "Tidymodels",
    "section": "More metrics",
    "text": "More metrics\n\nAIC: Akaike’s Information Criteria = \\(-2\\ln L + 2p\\)\nBIC: Bayesian Information Criteria = \\(-2 \\ln L + p \\ln(n)\\)\n\n\nchoose a model with the smallest AIC or BIC"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#tools",
    "href": "handout/2023-02-27-ROC-onestep.html#tools",
    "title": "Tidymodels",
    "section": "Tools 😖",
    "text": "Tools 😖\n\ntidymodels does not make it easy to add or drop 1 variable at a time.\nadd1() and drop1() functions do not make it easy to work with dozens of predictors and missing data.\n\nTherefore, we’ll go back to the bird data from HW 5.\n\n\n\n\n\nLocation\n  bank  conif  decid ground  shrub   snag   wall \n     3     14     25     19     17      4      4"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#forward-1",
    "href": "handout/2023-02-27-ROC-onestep.html#forward-1",
    "title": "Tidymodels",
    "section": "Forward +1",
    "text": "Forward +1\n\nglm(`Closed?` ~ 1, data = nests, family=\"binomial\") %>%\n  add1(scope = ~ Length + Location + No.eggs + Color +\n         Incubate + Nestling + Totcare, test = \"Chisq\")\n\nSingle term additions\n\nModel:\n`Closed?` ~ 1\n         Df Deviance     AIC     LRT  Pr(>Chi)    \n<none>       108.533 110.533                      \nLength    1  105.296 109.296  3.2373 0.0719792 .  \nLocation  6   77.065  91.065 31.4684 2.063e-05 ***\nNo.eggs   1   90.951  94.951 17.5816 2.752e-05 ***\nColor     1  108.087 112.087  0.4463 0.5041175    \nIncubate  1  108.267 112.267  0.2658 0.6061875    \nNestling  1   93.825  97.825 14.7078 0.0001255 ***\nTotcare   1   98.964 102.964  9.5688 0.0019791 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#forward-2",
    "href": "handout/2023-02-27-ROC-onestep.html#forward-2",
    "title": "Tidymodels",
    "section": "Forward +2",
    "text": "Forward +2\n\nglm(`Closed?` ~ Location, data = nests, family=\"binomial\") %>%\n  add1(scope = ~ Length + Location + No.eggs + Color +\n         Incubate + Nestling + Totcare, test = \"Chisq\")\n\nSingle term additions\n\nModel:\n`Closed?` ~ Location\n         Df Deviance    AIC     LRT  Pr(>Chi)    \n<none>        77.065 91.065                      \nLength    1   71.704 87.704  5.3605    0.0206 *  \nNo.eggs   1   61.211 77.211 15.8530 6.846e-05 ***\nColor     1   74.758 90.758  2.3070    0.1288    \nIncubate  1   74.829 90.829  2.2355    0.1349    \nNestling  1   74.722 90.722  2.3425    0.1259    \nTotcare   1   76.635 92.635  0.4300    0.5120    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#forward-3",
    "href": "handout/2023-02-27-ROC-onestep.html#forward-3",
    "title": "Tidymodels",
    "section": "Forward +3",
    "text": "Forward +3\n\nglm(`Closed?` ~ No.eggs + Location, data = nests, family=\"binomial\") %>%\n  add1(scope = ~ Length + Location + No.eggs + Color +\n         Incubate + Nestling + Totcare, test = \"Chisq\")\n\nSingle term additions\n\nModel:\n`Closed?` ~ No.eggs + Location\n         Df Deviance    AIC     LRT Pr(>Chi)  \n<none>        61.211 77.211                   \nLength    1   58.229 76.229 2.98230  0.08418 .\nColor     1   59.925 77.925 1.28650  0.25669  \nIncubate  1   59.891 77.891 1.32019  0.25056  \nNestling  1   59.247 77.247 1.96461  0.16102  \nTotcare   1   60.751 78.751 0.46084  0.49723  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#backward--1",
    "href": "handout/2023-02-27-ROC-onestep.html#backward--1",
    "title": "Tidymodels",
    "section": "Backward -1",
    "text": "Backward -1\n\nglm(`Closed?` ~ Length + Location + No.eggs + Color +\n         Incubate + Nestling + Totcare, data = nests, family=\"binomial\") %>%\n  drop1(test = \"Chisq\")\n\nSingle term deletions\n\nModel:\n`Closed?` ~ Length + Location + No.eggs + Color + Incubate + \n    Nestling + Totcare\n         Df Deviance    AIC     LRT Pr(>Chi)   \n<none>        46.252 70.252                    \nLength    1   52.812 74.812  6.5600 0.010430 * \nLocation  6   66.017 78.017 19.7648 0.003049 **\nNo.eggs   1   56.049 78.049  9.7973 0.001748 **\nColor     1   46.997 68.997  0.7457 0.387857   \nIncubate  0   46.252 70.252  0.0000            \nNestling  0   46.252 70.252  0.0000            \nTotcare   0   46.252 70.252  0.0000            \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#backward--2",
    "href": "handout/2023-02-27-ROC-onestep.html#backward--2",
    "title": "Tidymodels",
    "section": "Backward -2",
    "text": "Backward -2\n\nglm(`Closed?` ~ Length + Location + No.eggs + Color +\n         Incubate  + Totcare, data = nests, family=\"binomial\") %>%\n  drop1(test = \"Chisq\")\n\nSingle term deletions\n\nModel:\n`Closed?` ~ Length + Location + No.eggs + Color + Incubate + \n    Totcare\n         Df Deviance    AIC     LRT Pr(>Chi)   \n<none>        46.252 70.252                    \nLength    1   52.812 74.812  6.5600 0.010430 * \nLocation  6   66.017 78.017 19.7648 0.003049 **\nNo.eggs   1   56.049 78.049  9.7973 0.001748 **\nColor     1   46.997 68.997  0.7457 0.387857   \nIncubate  1   49.031 71.031  2.7796 0.095472 . \nTotcare   1   56.989 78.989 10.7368 0.001050 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#backward--2-1",
    "href": "handout/2023-02-27-ROC-onestep.html#backward--2-1",
    "title": "Tidymodels",
    "section": "Backward -2",
    "text": "Backward -2\n\nglm(`Closed?` ~ Length + Location + No.eggs + Incubate  + Totcare, \n    data = nests, family=\"binomial\") %>%\n  drop1(test = \"Chisq\")\n\nSingle term deletions\n\nModel:\n`Closed?` ~ Length + Location + No.eggs + Incubate + Totcare\n         Df Deviance    AIC     LRT Pr(>Chi)    \n<none>        46.997 68.997                     \nLength    1   53.878 73.878  6.8809 0.008712 ** \nLocation  6   66.664 76.664 19.6663 0.003175 ** \nNo.eggs   1   57.418 77.418 10.4201 0.001247 ** \nIncubate  1   49.839 69.839  2.8416 0.091854 .  \nTotcare   1   58.227 78.227 11.2297 0.000805 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#backward--3",
    "href": "handout/2023-02-27-ROC-onestep.html#backward--3",
    "title": "Tidymodels",
    "section": "Backward -3",
    "text": "Backward -3\n\nglm(`Closed?` ~ Length + Location + No.eggs + Totcare, \n    data = nests, family=\"binomial\") %>%\n  drop1(test = \"Chisq\")\n\nSingle term deletions\n\nModel:\n`Closed?` ~ Length + Location + No.eggs + Totcare\n         Df Deviance    AIC     LRT  Pr(>Chi)    \n<none>        49.839 69.839                      \nLength    1   60.751 78.751 10.9116 0.0009556 ***\nLocation  6   69.236 77.236 19.3974 0.0035425 ** \nNo.eggs   1   61.940 79.940 12.1013 0.0005039 ***\nTotcare   1   58.229 76.229  8.3902 0.0037725 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#automatic-forward-w-aic",
    "href": "handout/2023-02-27-ROC-onestep.html#automatic-forward-w-aic",
    "title": "Tidymodels",
    "section": "Automatic: Forward w AIC",
    "text": "Automatic: Forward w AIC\n\nglm(`Closed?` ~ 1, data = nests, family=\"binomial\") %>%\n  stats::step(scope = ~ Length + Location + No.eggs + Color +\n         Incubate + Nestling + Totcare, \n         direction = \"forward\", k = 2)\n\nStart:  AIC=110.53\n`Closed?` ~ 1\n\n           Df Deviance     AIC\n+ Location  6   77.065  91.065\n+ No.eggs   1   90.951  94.951\n+ Nestling  1   93.825  97.825\n+ Totcare   1   98.964 102.964\n+ Length    1  105.296 109.296\n<none>         108.533 110.533\n+ Color     1  108.087 112.087\n+ Incubate  1  108.267 112.267\n\nStep:  AIC=91.06\n`Closed?` ~ Location\n\n           Df Deviance    AIC\n+ No.eggs   1   61.211 77.211\n+ Length    1   71.704 87.704\n+ Nestling  1   74.722 90.722\n+ Color     1   74.758 90.758\n+ Incubate  1   74.829 90.829\n<none>          77.065 91.065\n+ Totcare   1   76.635 92.635\n\nStep:  AIC=77.21\n`Closed?` ~ Location + No.eggs\n\n           Df Deviance    AIC\n+ Length    1   58.229 76.229\n<none>          61.211 77.211\n+ Nestling  1   59.247 77.247\n+ Incubate  1   59.891 77.891\n+ Color     1   59.925 77.925\n+ Totcare   1   60.751 78.751\n\nStep:  AIC=76.23\n`Closed?` ~ Location + No.eggs + Length\n\n           Df Deviance    AIC\n+ Nestling  1   47.292 67.292\n+ Totcare   1   49.839 69.839\n<none>          58.229 76.229\n+ Color     1   56.989 76.989\n+ Incubate  1   58.227 78.227\n\nStep:  AIC=67.29\n`Closed?` ~ Location + No.eggs + Length + Nestling\n\n           Df Deviance    AIC\n<none>          47.292 67.292\n+ Color     1   46.580 68.580\n+ Incubate  1   46.997 68.997\n+ Totcare   1   46.997 68.997\n\n\n\nCall:  glm(formula = `Closed?` ~ Location + No.eggs + Length + Nestling, \n    family = \"binomial\", data = nests)\n\nCoefficients:\n   (Intercept)   Locationconif   Locationdecid  Locationground   Locationshrub  \n       11.1085        -19.2865        -16.8603        -20.5222        -18.6448  \n  Locationsnag    Locationwall         No.eggs          Length        Nestling  \n        0.6949        -18.3127          0.7950         -0.2194          0.3983  \n\nDegrees of Freedom: 85 Total (i.e. Null);  76 Residual\nNull Deviance:      108.5 \nResidual Deviance: 47.29    AIC: 67.29"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#final-forward-automatic",
    "href": "handout/2023-02-27-ROC-onestep.html#final-forward-automatic",
    "title": "Tidymodels",
    "section": "Final Forward Automatic",
    "text": "Final Forward Automatic\n\n\n# A tibble: 10 × 5\n   term           estimate std.error statistic p.value\n   <chr>             <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)      11.1   3328.      0.00334  0.997  \n 2 Length           -0.219    0.0754 -2.91     0.00364\n 3 Locationconif   -19.3   3328.     -0.00580  0.995  \n 4 Locationdecid   -16.9   3328.     -0.00507  0.996  \n 5 Locationground  -20.5   3328.     -0.00617  0.995  \n 6 Locationshrub   -18.6   3328.     -0.00560  0.996  \n 7 Locationsnag      0.695 4313.      0.000161 1.00   \n 8 Locationwall    -18.3   3328.     -0.00550  0.996  \n 9 No.eggs           0.795    0.262   3.04     0.00238\n10 Nestling          0.398    0.144   2.76     0.00577"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#automatic-bakcward-w-bic",
    "href": "handout/2023-02-27-ROC-onestep.html#automatic-bakcward-w-bic",
    "title": "Tidymodels",
    "section": "Automatic: Bakcward w BIC",
    "text": "Automatic: Bakcward w BIC\n\n\nStart:  AIC=99.7\n`Closed?` ~ Length + Location + No.eggs + Color + Incubate + \n    Nestling + Totcare\n\n\nStep:  AIC=99.7\n`Closed?` ~ Length + Location + No.eggs + Color + Incubate + \n    Nestling\n\n           Df Deviance     AIC\n- Location  6   66.017  92.743\n- Incubate  1   46.580  95.577\n- Color     1   46.997  95.995\n<none>          46.252  99.704\n- Length    1   52.812 101.810\n- No.eggs   1   56.049 105.047\n- Nestling  1   56.989 105.986\n\nStep:  AIC=92.74\n`Closed?` ~ Length + No.eggs + Color + Incubate + Nestling\n\n           Df Deviance     AIC\n- Incubate  1   66.175  88.447\n- Color     1   66.664  88.935\n<none>          66.017  92.743\n- No.eggs   1   74.635  96.907\n- Length    1   75.000  97.272\n- Nestling  1   85.891 108.163\n\nStep:  AIC=88.45\n`Closed?` ~ Length + No.eggs + Color + Nestling\n\n           Df Deviance     AIC\n- Color     1   66.762  84.579\n<none>          66.175  88.447\n- No.eggs   1   75.577  93.395\n- Length    1   79.115  96.932\n- Nestling  1   89.064 106.881\n\nStep:  AIC=84.58\n`Closed?` ~ Length + No.eggs + Nestling\n\n           Df Deviance     AIC\n<none>          66.762  84.579\n- No.eggs   1   76.704  90.067\n- Length    1   79.162  92.525\n- Nestling  1   90.053 103.416\n\n\n\nCall:  glm(formula = `Closed?` ~ Length + No.eggs + Nestling, family = \"binomial\", \n    data = nests)\n\nCoefficients:\n(Intercept)       Length      No.eggs     Nestling  \n    -6.7711      -0.1871       0.6476       0.4062  \n\nDegrees of Freedom: 85 Total (i.e. Null);  82 Residual\nNull Deviance:      108.5 \nResidual Deviance: 66.76    AIC: 74.76"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#final-forward-aic",
    "href": "handout/2023-02-27-ROC-onestep.html#final-forward-aic",
    "title": "Tidymodels",
    "section": "Final Forward AIC",
    "text": "Final Forward AIC\n\nglm(`Closed?` ~ Length + Location + No.eggs + Nestling,\n    data = nests, family=\"binomial\") %>% tidy()\n\n# A tibble: 10 × 5\n   term           estimate std.error statistic p.value\n   <chr>             <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)      11.1   3328.      0.00334  0.997  \n 2 Length           -0.219    0.0754 -2.91     0.00364\n 3 Locationconif   -19.3   3328.     -0.00580  0.995  \n 4 Locationdecid   -16.9   3328.     -0.00507  0.996  \n 5 Locationground  -20.5   3328.     -0.00617  0.995  \n 6 Locationshrub   -18.6   3328.     -0.00560  0.996  \n 7 Locationsnag      0.695 4313.      0.000161 1.00   \n 8 Locationwall    -18.3   3328.     -0.00550  0.996  \n 9 No.eggs           0.795    0.262   3.04     0.00238\n10 Nestling          0.398    0.144   2.76     0.00577"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#automatic-backward-w-bic",
    "href": "handout/2023-02-27-ROC-onestep.html#automatic-backward-w-bic",
    "title": "Tidymodels",
    "section": "Automatic: Backward w BIC",
    "text": "Automatic: Backward w BIC\n\nglm(`Closed?` ~ Length + Location + No.eggs + Color +\n         Incubate + Nestling + Totcare,\n    data = nests, family=\"binomial\") %>%\n  stats::step(scope = ~ Length + Location + No.eggs + Color +\n         Incubate + Nestling + Totcare, \n         direction = \"backward\", k = log(86))\n\nStart:  AIC=99.7\n`Closed?` ~ Length + Location + No.eggs + Color + Incubate + \n    Nestling + Totcare\n\n\nStep:  AIC=99.7\n`Closed?` ~ Length + Location + No.eggs + Color + Incubate + \n    Nestling\n\n           Df Deviance     AIC\n- Location  6   66.017  92.743\n- Incubate  1   46.580  95.577\n- Color     1   46.997  95.995\n<none>          46.252  99.704\n- Length    1   52.812 101.810\n- No.eggs   1   56.049 105.047\n- Nestling  1   56.989 105.986\n\nStep:  AIC=92.74\n`Closed?` ~ Length + No.eggs + Color + Incubate + Nestling\n\n           Df Deviance     AIC\n- Incubate  1   66.175  88.447\n- Color     1   66.664  88.935\n<none>          66.017  92.743\n- No.eggs   1   74.635  96.907\n- Length    1   75.000  97.272\n- Nestling  1   85.891 108.163\n\nStep:  AIC=88.45\n`Closed?` ~ Length + No.eggs + Color + Nestling\n\n           Df Deviance     AIC\n- Color     1   66.762  84.579\n<none>          66.175  88.447\n- No.eggs   1   75.577  93.395\n- Length    1   79.115  96.932\n- Nestling  1   89.064 106.881\n\nStep:  AIC=84.58\n`Closed?` ~ Length + No.eggs + Nestling\n\n           Df Deviance     AIC\n<none>          66.762  84.579\n- No.eggs   1   76.704  90.067\n- Length    1   79.162  92.525\n- Nestling  1   90.053 103.416\n\n\n\nCall:  glm(formula = `Closed?` ~ Length + No.eggs + Nestling, family = \"binomial\", \n    data = nests)\n\nCoefficients:\n(Intercept)       Length      No.eggs     Nestling  \n    -6.7711      -0.1871       0.6476       0.4062  \n\nDegrees of Freedom: 85 Total (i.e. Null);  82 Residual\nNull Deviance:      108.5 \nResidual Deviance: 66.76    AIC: 74.76"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#final-backward-bic",
    "href": "handout/2023-02-27-ROC-onestep.html#final-backward-bic",
    "title": "Tidymodels",
    "section": "Final Backward BIC",
    "text": "Final Backward BIC\n\nglm(`Closed?` ~ Length + No.eggs + Nestling,\n    data = nests, family=\"binomial\") %>% tidy()\n\n# A tibble: 4 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)   -6.77     1.73       -3.90 0.0000946\n2 Length        -0.187    0.0598     -3.13 0.00177  \n3 No.eggs        0.648    0.245       2.65 0.00815  \n4 Nestling       0.406    0.107       3.78 0.000156 \n\n\n\n\n\nhttps://m150-method-biostat.netlify.app/"
  },
  {
    "objectID": "handout/2023-02-27-ROC-onestep.html#aoc",
    "href": "handout/2023-02-27-ROC-onestep.html#aoc",
    "title": "Tidymodels",
    "section": "AOC",
    "text": "AOC\n\nAlexandria Ocasio-Cortez as Area Over the Curve. I didn’t make the image, and I don’t know who did!"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#agenda",
    "href": "handout/2023-02-28-ROC-onestep.html#agenda",
    "title": "ROC + Adding Variables",
    "section": "Agenda",
    "text": "Agenda\n\n\nMetric: Receiver Operating Characteristic (ROC) Curves\nMetrics: AIC & BIC\nModel building one variables at a time"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#make-predictions-for-test-data",
    "href": "handout/2023-02-28-ROC-onestep.html#make-predictions-for-test-data",
    "title": "ROC + Adding Variables",
    "section": "Make predictions for test data",
    "text": "Make predictions for test data\n\nfeeder_test_pred <- predict(feeder_fit, feeder_test, type = \"prob\") %>%\n  mutate(.pred_class = as.factor(ifelse(.pred_squirrels >=0.5,\n                                        \"squirrels\", \"no squirrels\"))) %>%\n  bind_cols(feeder_test %>% select(squirrels))\n\nfeeder_test_pred\n\n# A tibble: 58,922 × 4\n   `.pred_no squirrels` .pred_squirrels .pred_class squirrels   \n                  <dbl>           <dbl> <fct>       <fct>       \n 1               0.201            0.799 squirrels   no squirrels\n 2               0.156            0.844 squirrels   no squirrels\n 3               0.352            0.648 squirrels   no squirrels\n 4               0.197            0.803 squirrels   squirrels   \n 5               0.121            0.879 squirrels   squirrels   \n 6               0.272            0.728 squirrels   squirrels   \n 7               0.0459           0.954 squirrels   squirrels   \n 8               0.0341           0.966 squirrels   squirrels   \n 9               0.0631           0.937 squirrels   squirrels   \n10               0.0312           0.969 squirrels   squirrels   \n# … with 58,912 more rows"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#accuracy",
    "href": "handout/2023-02-28-ROC-onestep.html#accuracy",
    "title": "ROC + Adding Variables",
    "section": "Accuracy",
    "text": "Accuracy\n\nrbind(accuracy(feeder_test_pred, truth = squirrels, \n               estimate = .pred_class),\n      sensitivity(feeder_test_pred, truth = squirrels, \n                  estimate = .pred_class, event_level = \"second\"),\n      specificity(feeder_test_pred, truth = squirrels, \n                  estimate = .pred_class, event_level = \"second\"),\n      roc_auc(feeder_test_pred, truth = squirrels, \n                  estimate = .pred_squirrels, event_level = \"second\"))\n\n# A tibble: 4 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary        0.814 \n2 sensitivity binary        0.985 \n3 specificity binary        0.0988\n4 roc_auc     binary        0.721"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#roc-curves",
    "href": "handout/2023-02-28-ROC-onestep.html#roc-curves",
    "title": "ROC + Adding Variables",
    "section": "ROC Curves",
    "text": "ROC Curves\nReceiver Operating Characteristic Curves\n\nTPR = sensitivity = # of true predicted true / # true\nFPR = 1 - specificity = # false predicted true / # false\n\nHow can the plot use many TPRs and FPRs ???"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#roc-curve",
    "href": "handout/2023-02-28-ROC-onestep.html#roc-curve",
    "title": "ROC + Adding Variables",
    "section": "ROC Curve",
    "text": "ROC Curve"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#visualizing-accuracy",
    "href": "handout/2023-02-28-ROC-onestep.html#visualizing-accuracy",
    "title": "ROC + Adding Variables",
    "section": "Visualizing accuracy",
    "text": "Visualizing accuracy\n\n\n# A tibble: 4 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary        0.814 \n2 sensitivity binary        0.985 \n3 specificity binary        0.0988\n4 roc_auc     binary        0.721"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#different-cut-off-0.8",
    "href": "handout/2023-02-28-ROC-onestep.html#different-cut-off-0.8",
    "title": "ROC + Adding Variables",
    "section": "Different cut-off = 0.8?",
    "text": "Different cut-off = 0.8?\n\nfeeder_test_pred <- predict(feeder_fit, feeder_test, type = \"prob\") %>%\n  mutate(.pred_class = as.factor(ifelse(.pred_squirrels >=0.8,\n                                        \"squirrels\", \"no squirrels\"))) %>%\n  bind_cols(feeder_test %>% select(squirrels))\n\n\n\n# A tibble: 4 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary         0.675\n2 sensitivity binary         0.683\n3 specificity binary         0.641\n4 roc_auc     binary         0.721"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#different-cut-off-0.15",
    "href": "handout/2023-02-28-ROC-onestep.html#different-cut-off-0.15",
    "title": "ROC + Adding Variables",
    "section": "Different cut-off = 0.15?",
    "text": "Different cut-off = 0.15?\n\nfeeder_test_pred <- predict(feeder_fit, feeder_test, type = \"prob\") %>%\n  mutate(.pred_class = as.factor(ifelse(.pred_squirrels >=0.15,\n                                        \"squirrels\", \"no squirrels\"))) %>%\n  bind_cols(feeder_test %>% select(squirrels))\n\n\n\n# A tibble: 4 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary       0.807  \n2 sensitivity binary       0.999  \n3 specificity binary       0.00141\n4 roc_auc     binary       0.721"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#roc-curve-1",
    "href": "handout/2023-02-28-ROC-onestep.html#roc-curve-1",
    "title": "ROC + Adding Variables",
    "section": "ROC Curve",
    "text": "ROC Curve\n\nroc_auc(feeder_test_pred, truth = squirrels, \n                  estimate = .pred_squirrels, event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.721\n\n\n\nTo get a single value (for model comparison), we use the area under the ROC curve."
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#aoc",
    "href": "handout/2023-02-28-ROC-onestep.html#aoc",
    "title": "ROC + Adding Variables",
    "section": "AOC",
    "text": "AOC\n\nAlexandria Ocasio-Cortez as Area Over the Curve. I didn’t make the image, and I don’t know who did!"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#more-metrics",
    "href": "handout/2023-02-28-ROC-onestep.html#more-metrics",
    "title": "ROC + Adding Variables",
    "section": "More metrics",
    "text": "More metrics\n\nAIC: Akaike’s Information Criteria = \\(-2\\ln L + 2p\\)\nBIC: Bayesian Information Criteria = \\(-2 \\ln L + p \\ln(n)\\)\n\n\nchoose a model with the smallest AIC or BIC"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#tools",
    "href": "handout/2023-02-28-ROC-onestep.html#tools",
    "title": "ROC + Adding Variables",
    "section": "Tools 😖",
    "text": "Tools 😖\n\ntidymodels does not make it easy to add or drop 1 variable at a time.\nadd1() and drop1() functions do not make it easy to work with dozens of predictors and missing data.\n\nTherefore, we’ll go back to the bird data from HW 5.\n\n\n\n\n\nLocation\n  bank  conif  decid ground  shrub   snag   wall \n     3     14     25     19     17      4      4"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#forward-1",
    "href": "handout/2023-02-28-ROC-onestep.html#forward-1",
    "title": "ROC + Adding Variables",
    "section": "Forward +1",
    "text": "Forward +1\n\nglm(`Closed?` ~ 1, data = nests, family=\"binomial\") %>%\n  add1(scope = ~ Length + Location + No.eggs + Color +\n         Incubate + Nestling + Totcare, test = \"Chisq\")\n\nSingle term additions\n\nModel:\n`Closed?` ~ 1\n         Df Deviance     AIC     LRT  Pr(>Chi)    \n<none>       108.533 110.533                      \nLength    1  105.296 109.296  3.2373 0.0719792 .  \nLocation  6   77.065  91.065 31.4684 2.063e-05 ***\nNo.eggs   1   90.951  94.951 17.5816 2.752e-05 ***\nColor     1  108.087 112.087  0.4463 0.5041175    \nIncubate  1  108.267 112.267  0.2658 0.6061875    \nNestling  1   93.825  97.825 14.7078 0.0001255 ***\nTotcare   1   98.964 102.964  9.5688 0.0019791 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#forward-2",
    "href": "handout/2023-02-28-ROC-onestep.html#forward-2",
    "title": "ROC + Adding Variables",
    "section": "Forward +2",
    "text": "Forward +2\n\nglm(`Closed?` ~ Location, data = nests, family=\"binomial\") %>%\n  add1(scope = ~ Length + Location + No.eggs + Color +\n         Incubate + Nestling + Totcare, test = \"Chisq\")\n\nSingle term additions\n\nModel:\n`Closed?` ~ Location\n         Df Deviance    AIC     LRT  Pr(>Chi)    \n<none>        77.065 91.065                      \nLength    1   71.704 87.704  5.3605    0.0206 *  \nNo.eggs   1   61.211 77.211 15.8530 6.846e-05 ***\nColor     1   74.758 90.758  2.3070    0.1288    \nIncubate  1   74.829 90.829  2.2355    0.1349    \nNestling  1   74.722 90.722  2.3425    0.1259    \nTotcare   1   76.635 92.635  0.4300    0.5120    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#forward-3",
    "href": "handout/2023-02-28-ROC-onestep.html#forward-3",
    "title": "ROC + Adding Variables",
    "section": "Forward +3",
    "text": "Forward +3\n\nglm(`Closed?` ~ No.eggs + Location, data = nests, family=\"binomial\") %>%\n  add1(scope = ~ Length + Location + No.eggs + Color +\n         Incubate + Nestling + Totcare, test = \"Chisq\")\n\nSingle term additions\n\nModel:\n`Closed?` ~ No.eggs + Location\n         Df Deviance    AIC     LRT Pr(>Chi)  \n<none>        61.211 77.211                   \nLength    1   58.229 76.229 2.98230  0.08418 .\nColor     1   59.925 77.925 1.28650  0.25669  \nIncubate  1   59.891 77.891 1.32019  0.25056  \nNestling  1   59.247 77.247 1.96461  0.16102  \nTotcare   1   60.751 78.751 0.46084  0.49723  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#backward--1",
    "href": "handout/2023-02-28-ROC-onestep.html#backward--1",
    "title": "ROC + Adding Variables",
    "section": "Backward -1",
    "text": "Backward -1\n\nglm(`Closed?` ~ Length + Location + No.eggs + Color +\n         Incubate + Nestling + Totcare, data = nests, family=\"binomial\") %>%\n  drop1(test = \"Chisq\")\n\nSingle term deletions\n\nModel:\n`Closed?` ~ Length + Location + No.eggs + Color + Incubate + \n    Nestling + Totcare\n         Df Deviance    AIC     LRT Pr(>Chi)   \n<none>        46.252 70.252                    \nLength    1   52.812 74.812  6.5600 0.010430 * \nLocation  6   66.017 78.017 19.7648 0.003049 **\nNo.eggs   1   56.049 78.049  9.7973 0.001748 **\nColor     1   46.997 68.997  0.7457 0.387857   \nIncubate  0   46.252 70.252  0.0000            \nNestling  0   46.252 70.252  0.0000            \nTotcare   0   46.252 70.252  0.0000            \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#backward--2",
    "href": "handout/2023-02-28-ROC-onestep.html#backward--2",
    "title": "ROC + Adding Variables",
    "section": "Backward -2",
    "text": "Backward -2\n\nglm(`Closed?` ~ Length + Location + No.eggs + Color +\n         Incubate  + Totcare, data = nests, family=\"binomial\") %>%\n  drop1(test = \"Chisq\")\n\nSingle term deletions\n\nModel:\n`Closed?` ~ Length + Location + No.eggs + Color + Incubate + \n    Totcare\n         Df Deviance    AIC     LRT Pr(>Chi)   \n<none>        46.252 70.252                    \nLength    1   52.812 74.812  6.5600 0.010430 * \nLocation  6   66.017 78.017 19.7648 0.003049 **\nNo.eggs   1   56.049 78.049  9.7973 0.001748 **\nColor     1   46.997 68.997  0.7457 0.387857   \nIncubate  1   49.031 71.031  2.7796 0.095472 . \nTotcare   1   56.989 78.989 10.7368 0.001050 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#backward--2-1",
    "href": "handout/2023-02-28-ROC-onestep.html#backward--2-1",
    "title": "ROC + Adding Variables",
    "section": "Backward -2",
    "text": "Backward -2\n\nglm(`Closed?` ~ Length + Location + No.eggs + Incubate  + Totcare, \n    data = nests, family=\"binomial\") %>%\n  drop1(test = \"Chisq\")\n\nSingle term deletions\n\nModel:\n`Closed?` ~ Length + Location + No.eggs + Incubate + Totcare\n         Df Deviance    AIC     LRT Pr(>Chi)    \n<none>        46.997 68.997                     \nLength    1   53.878 73.878  6.8809 0.008712 ** \nLocation  6   66.664 76.664 19.6663 0.003175 ** \nNo.eggs   1   57.418 77.418 10.4201 0.001247 ** \nIncubate  1   49.839 69.839  2.8416 0.091854 .  \nTotcare   1   58.227 78.227 11.2297 0.000805 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#backward--3",
    "href": "handout/2023-02-28-ROC-onestep.html#backward--3",
    "title": "ROC + Adding Variables",
    "section": "Backward -3",
    "text": "Backward -3\n\nglm(`Closed?` ~ Length + Location + No.eggs + Totcare, \n    data = nests, family=\"binomial\") %>%\n  drop1(test = \"Chisq\")\n\nSingle term deletions\n\nModel:\n`Closed?` ~ Length + Location + No.eggs + Totcare\n         Df Deviance    AIC     LRT  Pr(>Chi)    \n<none>        49.839 69.839                      \nLength    1   60.751 78.751 10.9116 0.0009556 ***\nLocation  6   69.236 77.236 19.3974 0.0035425 ** \nNo.eggs   1   61.940 79.940 12.1013 0.0005039 ***\nTotcare   1   58.229 76.229  8.3902 0.0037725 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#automatic-forward-w-aic",
    "href": "handout/2023-02-28-ROC-onestep.html#automatic-forward-w-aic",
    "title": "ROC + Adding Variables",
    "section": "Automatic: Forward w AIC",
    "text": "Automatic: Forward w AIC\n\nglm(`Closed?` ~ 1, data = nests, family=\"binomial\") %>%\n  stats::step(scope = ~ Length + Location + No.eggs + Color +\n         Incubate + Nestling + Totcare, \n         direction = \"forward\", k = 2)\n\nStart:  AIC=110.53\n`Closed?` ~ 1\n\n           Df Deviance     AIC\n+ Location  6   77.065  91.065\n+ No.eggs   1   90.951  94.951\n+ Nestling  1   93.825  97.825\n+ Totcare   1   98.964 102.964\n+ Length    1  105.296 109.296\n<none>         108.533 110.533\n+ Color     1  108.087 112.087\n+ Incubate  1  108.267 112.267\n\nStep:  AIC=91.06\n`Closed?` ~ Location\n\n           Df Deviance    AIC\n+ No.eggs   1   61.211 77.211\n+ Length    1   71.704 87.704\n+ Nestling  1   74.722 90.722\n+ Color     1   74.758 90.758\n+ Incubate  1   74.829 90.829\n<none>          77.065 91.065\n+ Totcare   1   76.635 92.635\n\nStep:  AIC=77.21\n`Closed?` ~ Location + No.eggs\n\n           Df Deviance    AIC\n+ Length    1   58.229 76.229\n<none>          61.211 77.211\n+ Nestling  1   59.247 77.247\n+ Incubate  1   59.891 77.891\n+ Color     1   59.925 77.925\n+ Totcare   1   60.751 78.751\n\nStep:  AIC=76.23\n`Closed?` ~ Location + No.eggs + Length\n\n           Df Deviance    AIC\n+ Nestling  1   47.292 67.292\n+ Totcare   1   49.839 69.839\n<none>          58.229 76.229\n+ Color     1   56.989 76.989\n+ Incubate  1   58.227 78.227\n\nStep:  AIC=67.29\n`Closed?` ~ Location + No.eggs + Length + Nestling\n\n           Df Deviance    AIC\n<none>          47.292 67.292\n+ Color     1   46.580 68.580\n+ Incubate  1   46.997 68.997\n+ Totcare   1   46.997 68.997\n\n\n\nCall:  glm(formula = `Closed?` ~ Location + No.eggs + Length + Nestling, \n    family = \"binomial\", data = nests)\n\nCoefficients:\n   (Intercept)   Locationconif   Locationdecid  Locationground   Locationshrub  \n       11.1085        -19.2865        -16.8603        -20.5222        -18.6448  \n  Locationsnag    Locationwall         No.eggs          Length        Nestling  \n        0.6949        -18.3127          0.7950         -0.2194          0.3983  \n\nDegrees of Freedom: 85 Total (i.e. Null);  76 Residual\nNull Deviance:      108.5 \nResidual Deviance: 47.29    AIC: 67.29"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#final-forward-aic",
    "href": "handout/2023-02-28-ROC-onestep.html#final-forward-aic",
    "title": "ROC + Adding Variables",
    "section": "Final Forward AIC",
    "text": "Final Forward AIC\n\nglm(`Closed?` ~ Length + Location + No.eggs + Nestling,\n    data = nests, family=\"binomial\") %>% tidy()\n\n# A tibble: 10 × 5\n   term           estimate std.error statistic p.value\n   <chr>             <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)      11.1   3328.      0.00334  0.997  \n 2 Length           -0.219    0.0754 -2.91     0.00364\n 3 Locationconif   -19.3   3328.     -0.00580  0.995  \n 4 Locationdecid   -16.9   3328.     -0.00507  0.996  \n 5 Locationground  -20.5   3328.     -0.00617  0.995  \n 6 Locationshrub   -18.6   3328.     -0.00560  0.996  \n 7 Locationsnag      0.695 4313.      0.000161 1.00   \n 8 Locationwall    -18.3   3328.     -0.00550  0.996  \n 9 No.eggs           0.795    0.262   3.04     0.00238\n10 Nestling          0.398    0.144   2.76     0.00577"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#automatic-backward-w-bic",
    "href": "handout/2023-02-28-ROC-onestep.html#automatic-backward-w-bic",
    "title": "ROC + Adding Variables",
    "section": "Automatic: Backward w BIC",
    "text": "Automatic: Backward w BIC\n\nglm(`Closed?` ~ Length + Location + No.eggs + Color +\n         Incubate + Nestling + Totcare,\n    data = nests, family=\"binomial\") %>%\n  stats::step(scope = ~ Length + Location + No.eggs + Color +\n         Incubate + Nestling + Totcare, \n         direction = \"backward\", k = log(86))\n\nStart:  AIC=99.7\n`Closed?` ~ Length + Location + No.eggs + Color + Incubate + \n    Nestling + Totcare\n\n\nStep:  AIC=99.7\n`Closed?` ~ Length + Location + No.eggs + Color + Incubate + \n    Nestling\n\n           Df Deviance     AIC\n- Location  6   66.017  92.743\n- Incubate  1   46.580  95.577\n- Color     1   46.997  95.995\n<none>          46.252  99.704\n- Length    1   52.812 101.810\n- No.eggs   1   56.049 105.047\n- Nestling  1   56.989 105.986\n\nStep:  AIC=92.74\n`Closed?` ~ Length + No.eggs + Color + Incubate + Nestling\n\n           Df Deviance     AIC\n- Incubate  1   66.175  88.447\n- Color     1   66.664  88.935\n<none>          66.017  92.743\n- No.eggs   1   74.635  96.907\n- Length    1   75.000  97.272\n- Nestling  1   85.891 108.163\n\nStep:  AIC=88.45\n`Closed?` ~ Length + No.eggs + Color + Nestling\n\n           Df Deviance     AIC\n- Color     1   66.762  84.579\n<none>          66.175  88.447\n- No.eggs   1   75.577  93.395\n- Length    1   79.115  96.932\n- Nestling  1   89.064 106.881\n\nStep:  AIC=84.58\n`Closed?` ~ Length + No.eggs + Nestling\n\n           Df Deviance     AIC\n<none>          66.762  84.579\n- No.eggs   1   76.704  90.067\n- Length    1   79.162  92.525\n- Nestling  1   90.053 103.416\n\n\n\nCall:  glm(formula = `Closed?` ~ Length + No.eggs + Nestling, family = \"binomial\", \n    data = nests)\n\nCoefficients:\n(Intercept)       Length      No.eggs     Nestling  \n    -6.7711      -0.1871       0.6476       0.4062  \n\nDegrees of Freedom: 85 Total (i.e. Null);  82 Residual\nNull Deviance:      108.5 \nResidual Deviance: 66.76    AIC: 74.76"
  },
  {
    "objectID": "handout/2023-02-28-ROC-onestep.html#final-backward-bic",
    "href": "handout/2023-02-28-ROC-onestep.html#final-backward-bic",
    "title": "ROC + Adding Variables",
    "section": "Final Backward BIC",
    "text": "Final Backward BIC\n\nglm(`Closed?` ~ Length + No.eggs + Nestling,\n    data = nests, family=\"binomial\") %>% tidy()\n\n# A tibble: 4 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)   -6.77     1.73       -3.90 0.0000946\n2 Length        -0.187    0.0598     -3.13 0.00177  \n3 No.eggs        0.648    0.245       2.65 0.00815  \n4 Nestling       0.406    0.107       3.78 0.000156"
  },
  {
    "objectID": "handout/HW7_m150_s23.html",
    "href": "handout/HW7_m150_s23.html",
    "title": "Math 150 - Methods in Biostatistics - Homework 7",
    "section": "",
    "text": "Assignment Summary (Goals)\n\nbuilding multiple regression models one variable at a time\nfluent use of the multiple logistic model for prediction and for coefficient interpretation\npractice using ggplot() so that visualizations can inform the larger analysis (e.g., ROC curves)\n\nNote that if you don’t know the R code either check my notes or ask me!!! Happy to scaffold, debug, send resources, etc. Don’t go down a rabbit hole trying to figure out an R function or syntax.\nAlso, note that you’ll need to get the data from Canvas and use it for this analysis. Look back to your own HW1 file to see the line of code you used to import the games1.csv dataset. Ask me if it isn’t obvious to you after you look at your own HW1. And just like in HW4, you’ll need to deal with the missing variables coded as “*“.\n\nQ1. Collaborative Learning\nDescribe one thing you learned from someone (a fellow student or mentor) in our class this week (it could be: content, logistical help, background material, R information, etc.) 1-3 sentences.\n\n\nQ2. Reflecting\nMaybe this question would be better after you work on the modeling for a bit, but I didn’t want it to get lost at the end of the assignment.\n\nDo we need to CV or test / training to model fit with LRT? Said differently, does LRT keep the model from overfitting?\nDo we need CV or test / training to understand predictions? Said differently, does LRT supply independent predictions which will provide unbiased ideas of the accuracy of the model in the wild?\n\n\n\nQ3. And the Winner Is… take 3\nThe data this week come from kaggle as a compilation form Academy Award winners since the award began. https://www.kaggle.com/datasets/unanimad/the-oscar-award\nThe data wrangling below are an effort to consolidate the labels so that the variables measure the same over basic quality over the last 95 years. https://www.verdict.co.uk/oscars-90-whats-changed-years-oscars-records/\nThe dataset is in the files tab on Canvas (in a folder called “data”).\n\n# the only thing you should change in this R chunk is \n# the path of the dataset\nthe_oscar <- readr::read_csv(\"~/Dropbox/teaching/MA150/the_oscar_award.csv\") %>%\n  rename(year = year_ceremony) %>%\n  filter(year != 2022) %>%\n  select(-year_film, -ceremony, -name) %>%\n  drop_na() %>%\n  mutate(winner = case_when(\n    winner == TRUE ~ 1,\n    winner == FALSE ~ 0\n  )) %>%\n  distinct(category, film, .keep_all = TRUE) %>%\n  mutate(category = case_when(\n    category == \"OUTSTANDING PICTURE\" ~ \"BEST PICTURE\",\n    category == \"OUTSTANDING MOTION PICTURE\" ~ \"BEST PICTURE\",\n    category == \"OUTSTANDING PRODUCTION\" ~ \"BEST PICTURE\",\n    category == \"BEST MOTION PICTURE\" ~ \"BEST PICTURE\",\n    category == \"ACTOR\" ~ \"ACTOR IN A LEADING ROLE\",\n    category == \"ACTRESS\" ~ \"ACTRESS IN A LEADING ROLE\",\n    category == \"INTERNATIONAL FEATURE FILM\" ~ \"FOREIGN LANGUAGE FILM\",\n    str_detect(category, \"DIRECTING\") ~ \"DIRECTING\",\n    str_detect(category, \"WRITING\") ~ \"WRITING\",\n    str_detect(category, \"VISUAL EFFECTS\") ~ \"VISUAL EFFECTS\",\n    str_detect(category, \"SOUND\") ~ \"SOUND\",\n    str_detect(category, \"SHORT SUBJECT\") ~ \"SHORT SUBJECT\",\n    str_detect(category, \"SHORT FILM\") ~ \"SHORT FILM\",\n    str_detect(category, \"MUSIC\") ~ \"MUSIC\",\n    str_detect(category, \"MAKEUP\") ~ \"MAKEUP\",\n    str_detect(category, \"DOCUMENTARY\") ~ \"DOCUMENTARY\",\n    str_detect(category, \"COSTUME DESIGN\") ~ \"COSTUME DESIGN\",\n    str_detect(category, \"CINEMATOGRAPHY\") ~ \"CINEMATOGRAPHY\",\n    str_detect(category, \"ART DIRECTION\") ~ \"ART DIRECTION\",\n    str_detect(category, \"PRODUCTION\") ~ \"PRODUCTION\",\n    TRUE ~ category)) %>%\n  filter(!(category %in% c(\"OUTSTANDING PICUTRE\",\n                         \"UNIQUE AND ARTISTIC PICTURE\",\n                         \"SPECIAL ACHIEVEMENT AWARD (Sound Effects)\",\n                         \"SPECIAL ACHIEVEMENT AWARD (Visual Effects)\",\n                         \"SPECIAL ACHIEVEMENT AWARD (Sound Effects Editing)\",\n                         \"SPECIAL ACHIEVEMENT AWARD (Sound Editing)\",\n                         \"ENGINEERING EFFECTS\",\n                         \"DANCE DIRECTION\",\n                         \"ASSISTANT DIRECTOR\"\n                         ))) %>%\n  group_by(film, category) %>%\n  arrange(desc(winner)) %>%\n  filter(row_number() == 1) %>%\n  ungroup() %>%\n  pivot_wider(id_cols = c(\"year\", \"film\"),\n              names_from = category, values_from = winner,\n              values_fill = 0) %>%\n  janitor::clean_names() %>%\n  mutate(best_picture = as.factor(ifelse(best_picture == 1, \"win\", \"not win\"))) %>%\n  select(-film)  # note that I took out the film title\n\n\nCreate a logistic regression model using all 22 explanatory variables. Which variables appear to be most significant? (Feel free to use only the glm() function without all of the tidymodels scaffolding. I took out the film title above.)\nCreate and compare a few different multiple logistic regression models. Submit the model with the fewest number of terms that best estimates the probability of winning the Best Picture award. You might start with no variables and add one at a time (see the add1() function.) Or you might start with all the variables and drop one at a time (see the `drop1() function).\n\nHere are the variables written out in a way to make model building easier for you:\nyear + actor_in_a_leading_role + actress_in_a_leading_role + art_direction + cinematography + directing + writing + sound + short_subject + film_editing + music + actor_in_a_supporting_role + actress_in_a_supporting_role + special_effects + documentary + costume_design + foreign_language_film + visual_effects + short_film + makeup + animated_feature_film + production\n\nProvide ROC curves (ideally on the same plot) for your two best models. Comment on your graph.\n\nRecall that there were two ways of model building:\n\nIf you used tidymodels then you could predict using something like: predict(my_fit, data = the_oscar, type = \"prob\")\nIf you used straight glm(), then you have to use a slightly different version of predict: predict(my_glm, data = the_oscar, type = \"response\") or you can use: augment(my_glm, data = the_oscar, type.predict = \"response\")\n\n\npraise()\n\n[1] \"You are praiseworthy!\"\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "handout/HW8_m150_s23.html",
    "href": "handout/HW8_m150_s23.html",
    "title": "Math 150 - Methods in Biostatistics - Homework 7",
    "section": "",
    "text": "understanding of what a KM curve measures\nusing R to plot KM curves and CIs\nconsidering KM curves separately for a categorical explanatory variable\ntesting the null hypothesis of equality of S(t) across an explanatory variable\n\nNote that if you don’t know the R code either check my notes or ask me!!! Happy to scaffold, debug, send resources, etc. Don’t go down a rabbit hole trying to figure out an R function or syntax."
  },
  {
    "objectID": "handout/HW8_m150_s23.html#important",
    "href": "handout/HW8_m150_s23.html#important",
    "title": "Math 150 - Methods in Biostatistics - Homework 7",
    "section": "Important",
    "text": "Important\nThe data are in the files tab on Canvas (in a folder called “data”).\nMake sure you have the survival (for the survival estimates) and the survminer (for the plots) packages installed.\n\nQ1. Collaborative Learning\nDescribe one thing you learned from someone (a fellow student or mentor) in our class this week (it could be: content, logistical help, background material, R information, etc.) 1-3 sentences.\n\n\nQ2. Chp 9, A26\nProvide a brief explanation of why the estimated variance of \\(\\hat{S}_{KM}(0)\\), and hence the standard error of \\(\\hat{S}_{KM}(0)\\), is equal to 0.\n\n\nQ3. Chp 9, E4\nImmediately after a heart transplant, patients are randomly assigned to two treatment therapies to improve recovery from the transplant, therapy 1 and therapy 2. The patients are then followed for up to 5 years after their surgery. Define the time-to-event random variable T as the time (in months) until recovery (the event) after a heart transplant. For each of the following study descriptions that involve T, sketch the graph of the survival curve (or curves) with as much detail as necessary. Please note that parts (a) through (d) are completely independent of each other.\n\nTherapy 1 is not very effective shortly after surgery, but everybody recovers before the study period is over.\nTherapy 2 is very effective shortly after surgery, but becomes less effective after 3 years. Not every patient fully recovers by the end of the study period.\nTwo curves on the same plot: Therapy 1 is consistently more effective than Therapy 2 over time.\nTwo curves on the same plot: Therapy 1 is more effective than Therapy 2 for the first 2.5 years, and then Therapy 2 is more effective than Therapy 1 for the remaining duration of the study.\n\n\n\nQ4. Chp 9, E6\nThe Kaplan-Meier curve in Figure 9.17 (see the text, on Sakai) displays hypothetical estimated survival probabilities of death due to brain cancer, where time (from diagnosis) until death is measured in months.\n\nIs the largest event time censored or complete? How do you know?\nUse the curve to estimate the mean time until death due to brain cancer. [Read page 295 in the text.]\n\n\n\nQ5. Chp 9, E11 Male Fruit Fly Longevity\n(Lots to read in the text about the dataset.)\n\nConstruct the Kaplan-Meier curve with a confidence interval for the Fruitfly data and describe the survival pattern for the fruitflies over time. Use Longevity as the time-to-event variable.\n\nLook at the online notes example (http://st47s.com/Math150/Notes/survival-analysis.html#Rsurv) for how to implement the R code, but the basics of what you need are below. Look up ?ggsurvplot (in the survival package) to see the different confidence interval types.\nNotice that the “response variable” is now two variables!!! And we put them together with the Surv() function The Surv() function takes two arguments. The first argument is the time variable. The second argument is the censoring information. You shouldn’t have to transform any of the variables in the dataset which is provided.\n# look at the fruitfly data after you read it in!\nfruitfly <- read_csv(\"https://pomona.box.com/shared/static/qnsl0sp0twdutz6azidxb5yt37boee7v\",\n                     na=\"*\")\n\nfly_surv <- survfit(Surv(___, ____ ) ~ 1, data=___ )\n\nggsurvplot(___, conf.type = \"___\") + \n  ggtitle(\"___\")\n\nConstruct the Kaplan-Meier curve for the lifetimes of the fruitflies by number of partners, using Partners as the grouping variable. Briefly comment on the observed relationship between survival and number of female partners.\n\nThe R code will be very similar to part (a), but model the survival response variable as a function of the explanatory variable Partners.\nfly_surv_part <- survfit(Surv(___, ____ ) ~ Partners, data=___ )\n\nPerform the log-rank and Wilcoxon tests. Report the test statistics and p-values for both tests. State the conclusions for both tests. If the tests yield different conclusions, briefly explain why. [We will cover these tests on Monday in class.]\n\nThe R function which runs the two tests is called survdiff(). It acts on the Surv() response variable broken down by the explanatory variable, Partners.\nThe argument “rho = ___” controls which test you’d like to run. “rho = 0” gives the log-rank test. “rho = 1” gives the Wilcoxon test. Try typing ?survdiff to see the help file.\nsurvdiff(Surv(___,___) ~ ___, data= ___, rho=___)\nsurvdiff(Surv(___,___) ~ ___, data=___, rho=___)\n\npraise()\n\n[1] \"You are phenomenal!\""
  }
]