# Clicker Q

to go with **Practicing Statistics** by Kuiper & Sklar.  Math 150 - Methods in Biostatistics.

```{=html}
<style>
.reveal ol ol {
   list-style-type: lower-alpha;
}
</style>
```

```{r}
#| echo: false
#| message: false
#| warning: false

# figure options
knitr::opts_chunk$set(warning = FALSE, message = FALSE,
  fig.width = 10, fig.asp = 0.618, out.width = "90%",
  fig.retina = 3, dpi = 300, fig.align = "center"
)

library(tidyverse)
library(plotROC)
library(survival)
```

---

In terms of the prerequisite for Math 150, Methods in Biostatistics, you should know at least a little bit (hopefully a lotta bit) about the following topics.

(@) Hypothesis test, confidence interval, sample mean, central limit theorem, standard deviation, standard error of a statistics, p-value, t-test, chi-squared test.[^1]

   (a) Never heard of it
   (b) Heard of it, but don't know anything about it
   (c) Know a little about it (or did once)
   (d) Know something about it
   (e) Confident about it

[^1]: preferably d or e.  maybe c on some of them.

---

In terms of the prerequisite for Math 150, Methods in Biostatisitcs, you do not need to know the following topics

(@) Interaction, simple linear regression, multiple linear regression, logistic regression, survival analysis, R.[^2]

   (a) Never heard of it
   (b) Heard of it, but don't know anything about it
   (c) Know a little about it (or did once)
   (d) Know something about it
   (e) Confident about it

[^2]: these are the topics we will be covering.  Would be nice if you have heard of them.

---

(@) R / R Studio / Quarto[^1b]
    (a) all good
    (b) started, progress is slow and steady
    (c) started, very stuck
    (d) haven’t started yet
    (e) what do you mean by "R"?

[^1b]: wherever you are, make sure you are communicating with me when you have questions!

---

(@) Git / GitHub[^2b]
    (a) all good
    (b) started, progress is slow and steady
    (c) started, very stuck
    (d) haven’t started yet
    (e) what do you mean by "Git"?

[^2b]: wherever you are, make sure you are communicating with me when you have questions!

---

(@) Where can I get feedback on my HW assignments / quizzes?[^2c]
    (a) prof will return paper versions
    (b) on Gradescope
    (c) on Canvas
    (d) on GitHub
    
[^2c]: b. on Gradescope

---

(@) Which of the following includes talking to the remote version of GitHub?[^3b]
    (a) changing your name (updating the YAML)
    (b) committing the file(s)
    (c) pushing the file(s)
    (d) some of the above
    (e) all of the above
    
[^3b]: c. pushing the file(s)


---

(@) The Central Limit Theorem (CLT) says:[^3]
   a. The sample average (statistic) converges to the true average (parameter)
   b. The sample average (statistic) converges to some point
   c. The distribution of the sample average (statistic) converges to a normal distribution
   d. The distribution of the sample average (statistic) converges to some distribution
   e. I have no idea what the CLT says
   

[^3]: c. The distribution of the sample average (statistic) converges to a normal distribution

---

(@) The p-value is the probability:[^4]
   a. that the null hypothesis is true given the observed data.
   b. of data as or more extreme than the observed data given that the null hypothesis is true.

[^4]: b. of data as or more extreme than the observed data given that the null hypothesis is true.

---

(@) Why do we use a t distribution (instead of a z / normal distribution) in the t-test?[^5]
   a. the technical conditions don't hold
   b. the means are quite variable
   c. we like the letter t
   d. we have two samples
   e. we don't know the true standard deviation parameter

[^5]:  e. we don't know the true standard deviation parameter

---


(@) What happens if a t-test is used but isn't appropriate (technical conditions don't hold)?[^6]
   (a) the p-value isn't actually the probability of our data or more extreme if H0 is true.
   (b) the software won't give a p-value as output
   (c) the rejection region needs to be calculated in the opposite direction
   (d) the world blows up

[^6]: a. the p-value isn't actually the probability of our data or more extreme if H0 is true.

---

(@) We use linear regression to run a test of means 
($x_i = 0$ for controls, group 1; $x_i = 1$ for cases, group 2)
What is: $\sum_{i=1}^n x_i?$[^7]
   (a) $n$
   (b) $n_1$
   (c) $n_2$
   (d) $n_1 \cdot \overline{y}_1$
   (e) $n_2 \cdot \overline{y}_2$

[^7]: c. $n_2$

---

(@) We use linear regression to run a test of means 
($x_i = 0$ for controls, group 1; $x_i = 1$ for cases, group 2)
What is: $\sum_{i=1}^n x_iy_i?$[^8]
   (a) $n$
   (b) $n_1$
   (c) $n_2$
   (d) $n_1 \cdot \overline{y}_1$
   (e) $n_2 \cdot \overline{y}_2$

[^8]: e. $n_2 \cdot \overline{y}_2$

---

(@) The regression technical conditions include:[^9]
    (a) The Y variable is normally distributed
    (b) The X variable is normally distributed
    (c) The residuals are normally distributed
    (d) The slope coefficient is normally distributed
    (e) The intercept coefficient is normally distributed

[^9]: d. The residuals are normally distributed (which induces a., d., and e.).  There is nothing in the technical conditions about the distribution of X (remember, X can be binary!).

---

(@) We need the technical conditions to hold in order to calculate $b_0$ and $b_1.$[^10]

    (a) TRUE
    (b) FALSE
    (c) It depends
    
[^10]: FALSE.  We can always minimize the sums of squares, regardless of whether or not the model is any good.

---

(@) Why do we check technical conditions?[^11]
    (a) so that the inference is valid
    (b) so that the estimates are valid
    (c) so that the p-value is more likely to be small
    (d) so that the confidence level is right
    (e) for fun

[^11]: a. so that the inference is valid (and also for fun).  Note that d. so that the confidence level is right is also a correct answer because confidence intervals are all part of the "inference" paradigm.

---

(@) When writing the regression equation, why is there a hat $(\ \hat{} \ )$ on the response variable?[^12]
    (a) because the prediction is an estimate
    (b) because the prediction is an average
    (c) because the prediction may be due to extrapolation
    (d) a & b
    (e) all of the above

[^12]: d. due to estimation and average

---

(@) With a strong correlation and very small p-value, what can we conclude about happiness and life expectancy?[^13]
    (a) happiness causes longer lives
    (b) longer lives cause happiness
    (c) happiness and longer life are correlated
    (d) happiness and longer life are perfectly predictive
    (e) happiness and longer life are unrelated

[^13]: c. happiness and longer life are correlated

---

(@) If there is no relationship in the population (true correlation = 0), then r = 0.[^14]
    (a) TRUE
    (b) FALSE

[^14]: b. FALSE, there is no reason that the statistic will equal the parameter.

---

(@) If there is no relationship in the population (true slope $\beta_1 = 0$), then $b_1=0$.[^15]
    (a) TRUE
    (b) FALSE

[^15]: b. FALSE, there is no reason that the statistic will equal the parameter.



---

(@) Smaller variability around the regression line $(\sigma):$[^16]
    (a) increases the variability of $b_1$.
    (b) decreases the variability of $b_1$.
    (c) doesn't necessarily change the variability of $b_1$.

[^16]: b. decreases the variability of $b_1$.

---

(@) Smaller variability in the explanatory variable (SD(X) = $s_X):$[^17]
    (a) increases the variability of $b_1$.
    (b) decreases the variability of $b_1$.
    (c) doesn't necessarily change the variability of $b_1$.

[^17]: a. increases the variability of $b_1$.

---

(@) A smaller sample size $(n):$[^18]
    (a) increases the variability of $b_1$.
    (b) decreases the variability of $b_1$.
    (c) doesn't necessarily change the variability of $b_1$.

[^18]: a. increases the variability of $b_1$.

---

(@) We transform our variables...[^19]
    (a) ... to find the highest $r^2$ value.
    (b) ... when the X variable is not normally distributed.
    (c) ... to make the model easier to interpret.
    (d) ... so that the technical conditions are met.

[^19]: d. so that the technical conditions are met.


---

(@) In the Botox and Pain Relief example, the p-value is calculated.  What does "probability" refer to?[^20]
    (a) random allocation
    (b) random sample

[^20]: a. random allocation

---

p-value = probability of the observed data or more extreme given the null hypothesis is true.

---

(@) "Observed data or more extreme" is:[^21]
    (a) fewer than 9
    (b) 9 or fewer
    (c) 9 or more
    (d) more than 9

[^21]: c. 9 or more

---


(@) What is the mean value of the null sampling distribution for the number of Botox therapy who showed pain reduction?[^22]
    (a) 0
    (b) 9
    (c) 5.3
    (d) 11
    (e) 15

[^22]: c. 5.3 because (15/31)*11 = 5.3

---

(@) What conclusion would you draw from the Back Pain and Botox study?[^23]
    (a) Not enough evidence to conclude that Botox is more effective than the placebo.
    (b) Strong evidence that Botox is equally as effective as the placebo.
    (c) Strong evidence that Botox is more effective than the placebo.
    
[^23]: c. Strong evidence that Botox is more effective than the placebo.

---

(@) If we consider those in the study with back pain to be representative of all people with back pain, what would you conclude about the percentage of people who will have reduced back pain if they use Botox?[^24]
    (a) Substantially greater than 50%
    (b) Substantially less than 50%
    (c) Close to 50%

[^24]: c. Close to 50%  (the point estimate is 0.6)

---

(@) Material check-in
    (a) So far, so good
    (b) Concepts are good, R is confusing
    (c) R is good, concepts are confusing
    (d) Everything is confusing
    
---

(@) People check-in
    (a) So far, so good
    (b) I can go to office hours / mentor sessions, but I didn't happen to this week.
    (c) I can't make the scheduled office hours / mentor sessions
    (d) I'm looking for someone to study with
    
---

See Canvas front page for **anonymous** survey / feedback for the class.  Also, if you are looking for people to work with, please contact me directly (non-anonymously!) so that I can connect you to people.

---
    
(@) Sample 1,000,000 people who are over 6' tall and 1,000,000 people who are under 6' tall.  Record if the person is in the NBA.  What is measurable?[^27]
    (a) P(NBA if 6' tall)
    (b) P(6' tall if in the NBA)
    (c) both
    (d) neither  

[^27]: a. P(NBA if 6' tall) (cohort: cannot measure the probability of the explanatory variable given the response)

---

(@) Sample 100 people who are in the NBA and 100 people who are not in the NBA. Record if the person is over 6' tall. What is measurable?[^28]
    (a) P(NBA if 6' tall)
    (b) P(6' tall if in the NBA)
    (c) both
    (d) neither  

[^28]: b. P(6' tall if in the NBA) (case-control:  cannot measure the probability of the response variable given a level of the explanatory variable)

---

(@) Sample 10,000,000 people.  Record their height and whether or not they are in the NBA. What is measurable?[^29]
    (a) P(NBA if 6' tall)
    (b) P(6' tall if in the NBA)
    (c) both
    (d) neither  

[^29]: c. both (cross-classification: can measure all the probabilities)

---

From the NYT, March 21, 2023, https://www.nytimes.com/2023/03/21/sports/basketball/tall-basketball-march-madness.html

> American men who are between 6 feet and 6-2 — significantly taller than the 5-9 average — have about a five in a million chance of making the N.B.A., according to "The Sports Gene," a 2013 book by David Epstein about the science of athletic performance. But if you hit the genetic lottery and happen to be 7 feet tall, your chances of landing in the N.B.A. are roughly one in six. (There are 38 players on active rosters who are 7 feet or taller, according to N.B.A. Advanced Stats; the average height of an N.B.A. player is 6 feet 6.5 inches.)


https://davidepstein.com/david-epstein-the-sports-gene/

---

(@) Calcium channel blockers have recently been reported to be associated with increased mortality. Cardiac patients who recently died of their heart disease were compared to control cardiac patients with similar disease who survive. Assume such a study had found that 40% of the recent cardiac deaths were taking calcium channel blockers at the time of death, as compared to 25% of the controls.[^30]
    (a) Case-control
    (b) Cohort
    (c) Cross-classification

[^30]: a. case-control (they selected based on people who had died or not)

---

(@) It is well known that the use of urinary catheters conveys a substantial risk of urinary tract infection (UTI). A group of physicians believe that, in an intensive care setting, use of one particular type of urinary catheter is more likely to encourage infection than use of other types. They therefore review medical records over a recent period for all uses of urinary catheters in an ICU. They find that 200 new UTIs occurred during 1000 ICU patient-days of catheterization with the suspect type of catheter, as compared to 100 new UTIs during 5000 ICU-patient days of catheterization with all other types. Noting the increased frequency of new UTIs when the suspect catheter type is used, they regard their hypothesis as confirmed. To reduce nosocomial UTIs, they recommend discontinuing use of that type of catheter in the ICU.[^31]
    (a) Case-control
    (b) Cohort
    (c) Cross-classification

[^31]: b. cross-classification (they selected all uses of catheters)

---

(@) When we select individuals based on the explanatory variable, we cannot accurately measure[^32]
    (a) the proportion of people in the population in each explanatory category
    (b) the proportion of people in the population in each response group
    (c) anything about the population
    (d) confounding variables

[^32]: a. the proportion of people in the population in each explanatory category (tbh, we can't measure b either, but we can measure the proportion of people in each response group, separated by the explanatory variable)

---

(@) Relative Risk is[^33]
    (a) the difference of two proportions
    (b) the ratio of two proportions
    (c) the log of the ratio of two proportions
    (d) the log of the difference of two proportions

[^33]: b. the ratio of two proportions

---

(@) The odds ratio is "invariant to which variable is explanatory and which is response" means:[^34]
    (a) we always put the bigger odds in the numerator
    (b) we must collect data so that we can estimate the response in the population
    (c) which variable is called the explanatory changes the value of the OR
    (d) which variable is called the explanatory does not change the value of the OR

[^34]: d. which variable is called the explanatory does not change the value of the OR

---

(@) In finding a CI for RR = p1/p2, why is it okay to exponentiate the end points of the interval for ln(p1/p2)?[^35]
    (a) Because if ln(p1/p2) is in the original interval, p1/p2 will be in the exponentiated interval.
    (b) Because taking the natural log of the RR makes the  distribution approximately normal.
    (c) Because the natural log compresses values that are  bigger than 1 and spreads values that are smaller than 1.
    (d) Because we can get exact p-values using Fisher's Exact Test.

[^35]: a. Because if ln(p1/p2) is in the original interval, p1/p2 will be in the exponentiated interval.

---

(@) In order to find a CI for the true OR, our steps are:[^36]
 i. find $\widehat{\ln(\mbox{OR})}$
 ii. add $\pm \ z^* \sqrt{\frac{1}{n_1 \hat{p}_1 (1-\hat{p}_1)} + \frac{1}{n_2 \hat{p}_2 (1-\hat{p}_2)}}$
 iii. take exp of the endpoints 
 
   (a) because the sampling distribution of $\widehat{\mbox{OR}}$ is normal
   (b) because OR is typically greater than 1
   (c) because the $\ln$ transformation makes the sampling distribution almost normal
   (d) because OR is invariant to the choice of explanatory or response variable

[^36]: c. because the $\ln$ transformation makes the sampling distribution almost normal

---

(@) I know where to find: the solutions to the worksheets, the clicker questions (with solutions), and the HW solutions[^37]
     (a) TRUE
     (b) FALSE
     
[^37]: The worksheet solutions and clicker questions are on the main course website.  The HW solutions are on Canvas under Files.


---


(@) At the value $x = -\beta_0 / \beta_1$, the probability of success is:[^38]
    (a) 0
    (b) 0.5
    (c) 1
    (d) depends on $\beta_0$
    (e) depends on $\beta_1$

[^38]: b. 0.5

---

(@) The logistic model gives probability of failure:[^39]
    (a) $\frac{e^{\beta_0+ \beta_1 x}}{1+ e^{\beta_0+ \beta_1 x}}$
    (b) $\frac{1}{1+ e^{\beta_0+ \beta_1 x}}$
    (c) $e^{\beta_0+ \beta_1 x}$
    (d) $e^{-(\beta_0+ \beta_1 x)}$
    (e) $\beta_0+ \beta_1 x$

[^39]: b. $\frac{1}{1+ e^{\beta_0+ \beta_1 x}}$

---

(@) The logistic model gives odds of success:[^40]
    (a) $\frac{e^{\beta_0+ \beta_1 x}}{1+ e^{\beta_0+ \beta_1 x}}$
    (b) $\frac{1}{1+ e^{\beta_0+ \beta_1 x}}$
    (c) $e^{\beta_0+ \beta_1 x}$
    (d) $e^{-(\beta_0+ \beta_1 x)}$
    (e) $\beta_0+ \beta_1 x$

[^40]: c. $e^{\beta_0+ \beta_1 x}$

---

(@) The logistic model gives odds of failure:[^41]
    (a) $\frac{e^{\beta_0+ \beta_1 x}}{1+ e^{\beta_0+ \beta_1 x}}$
    (b) $\frac{1}{1+ e^{\beta_0+ \beta_1 x}}$
    (c) $e^{\beta_0+ \beta_1 x}$
    (d) $e^{-(\beta_0+ \beta_1 x)}$
    (e) $\beta_0+ \beta_1 x$

[^41]: d. $e^{-(\beta_0+ \beta_1 x)}$

---

(@) With a logistic regression model, the relative risk of success (for a one unit increase in X) is:[^42]
    (a) $- \beta_0/\beta_1$
    (b) $\beta_0+ \beta_1 x$
    (c) $e^{\beta_0+ \beta_1 x}$
    (d) a non-linear function of X (which depends on X )

[^42]: d. a non-linear function of X (which depends on X )

---

(@) If we want the relative risk of survival (for a one unit increase in X) to be independent of X, we should use which link:[^43]
    (a) linear
    (b) logistic
    (c) complementary log-log
    (d) log-linear

[^43]: d. log-linear

---

(@) You take a sample of size 4 from a binary population and get: FSFF. 
(failure, success, failure, failure) What is your guess for p = P(success)?[^44]
     (a) 0.05
     (b) 0.15
     (c) 0.25
     (d) 0.5
     (e) 0.75
 
[^44]: c. 0.25

---

(@) In a logistic regression model, the variability is given by[^45]
     (a) Normal Y given X
     (b) Binomial Y given X
     (c) Bernoulli Y given X
     (d) Poisson Y given X

[^45]: c. Bernoulli Y given X

---

(@) When trying to find estimates for $\beta_0$  and $\beta_1$, we maximize the likelihood.  $$\prod_{i=1}^n \bigg(\frac{e^{\beta_0+ \beta_1 x_i}}{1+ e^{\beta_0+ \beta_1 x_i}}\bigg)^{y_i}\bigg(\frac{1}{1+ e^{\beta_0+ \beta_1 x_i}}\bigg)^{1 - y_i}$$
Take the derivative with respect to which variable(s):[^46]
     (a) X
     (b) Y
     (c) $\beta_0$
     (d) $\beta_1$
     (e) $\beta_0$ and $\beta_1$

[^46]: e. $\beta_0$ and $\beta_1$

---

(@) Maximum likelihood estimation seeks to:[^47]
    (a) Find the data which are most likely under the model.
    (b) Find the parameters which are most likely under the model.
    (c) Find the parameters which make the data most likely under the model.
    (d) Find the data which make the parameters most likely under the model.

[^47]: c. Find the parameters which make the data most likely under the model.

---

(@) We use maximum likelihood estimation because:[^48]
     (a) It gives an principled approach for estimating the parameters.
     (b) The estimates are asymptotically normally distributed.
     (c) The estimates are always easy to compute.
     (d) All of the above.
     (e) Some of the above.

[^48]: e. Some of the above (a. It gives an principled approach for estimating the parameters. and b. The estimates are asymptotically normally distributed.)

---

(@) We know that for a given data set (with MLEs of $b_0$,$b_1$):[^49]
    (a) $L(b_0,b_1)< L(b_0,\beta_1=0)$ always
    (b) $L(b_0,b_1)> L(b_0,\beta_1=0)$ always
    (c) $L(b_0,b_1) \leq L(b_0,\beta_1=0)$ always
    (d) $L(b_0,b_1) \geq L(b_0,\beta_1=0)$ always

[^49]: d. $L(b_0,b_1) \geq L(b_0,\beta_1=0)$ always

---

(@) In a logistic regresion if $H_0$ is true, what is the probability of success?[^49a]
   (a) $p_0$
   (b) $\frac{e^{b_0}}{1 + e^{b_0}}$
   (c) $\frac{e^{b_1}}{1 + e^{b_1}}$
   (d) $e^{b_0}$
   (e) $\frac{e^{b_0 + b_1 x_i}}{1 + e^{b_0 + b_1 x_i}}$

   
[^49a]: (b) $\frac{e^{b_0}}{1 + e^{b_0}}$

---

(@) Which is the correct logistic regression model to predict disease status based on snoring (never, occasionally, often, always): $X_1 = 1$ for occasionally; $X_2 = 1$ for often; $X_3 = 1$ for always.[^49b]
   (a) logit$(p) = \beta_0$   
   (b) logit$(p) = \beta_0 + \beta_1 X$   
   (c) logit$(p) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3$   
   (d) logit$(p) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \beta_4 X_4$   
   (e) logit$(p) = \beta_0 + \beta_1 (X_1 + X_2 + X_3)$   
   
[^49b]: (d) logit$(p) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \beta_4 X_4$ 

---

(@) How many parameters did we estimate in the HERS worksheet with the additive model?[^50]
     a. 1
     b. 3
     c. 4
     d. 2757
     e. 2761

[^50]: c. 4 parameter estimates: $b_0, b_1, b_2, b_3$

---

(@) How many parameters did we estimate in the HERS worksheet with the interaction model?[^51]
     a. 3
     b. 4
     c. 6
     d. 7
     e. 12

[^51]: d. 7 parameter estimates: $b_0, b_1, b_2, b_3, b_4, b_5, b_6$

---

(@) What are the df for the LRT addressing whether interaction is needed in the HERS worksheet?[^52]
     a. 2
     b. 3
     c. 2760
     d. 2754
     e. 2757

[^52]: b. 3 (7 - 4 = 3)

---

(@) (Bird nest example) How many parameters do we estimate when considering Length as a categorical variable?  (the only variable)[^53]
    (a) 0
    (b) 1
    (c) 2
    (d) 33
    (e) 34

[^53]: e. 34

---

(@) (Bird nest example) How many df for the LRT addressing whether Length (as a categorical variable) belongs in the model?[^54]
    (a) 0
    (b) 1
    (c) 2
    (d) 33
    (e) 34

[^54]: d. 33 (34 - 1 = 33)

---

(@) (Bird nest example) How many df for the LRT addressing whether Incubate and Color belong in the model (given Length is determined to be in the model)?[^55]
    (a) 0
    (b) 1
    (c) 2
    (d) 3
    (e) 4 

[^55]: c. 2 (4 - 2 = 2)

---

(@) An interaction term in a multiple logistic regression model may be used when:[^56]
    (a) the model fit is poor.
    (b) there is a quadratic relationship between the response and explanatory variables.
    (c) neither one of two explanatory variables contribute significantly to the regression model.
    (d) the relationship between X1 and P(success) changes for differing values of X2.

[^56]: d. the relationship between X1 and P(success) changes for differing values of X2.

---

(@) The interpretations of the main effects (on their own) make sense only when the interaction component is not significant.[^57]
    (a)  TRUE
    (b)	 FALSE

[^57]: a. TRUE

---

(@) If the interaction is significant but the main effects aren't:[^58]
    (a) report on the significance of the main effects
    (b) remove the main effects from the model
    (c) avoid talking about main effects on their own
    (d) test whether the main effects are significant without interaction in the model

[^58]: c. avoid talking about main effects on their own

---

(@) With two variables of interest, what should you test first?[^59]
    (a) Variable 1.
    (b) Variable 2.
    (c) The interaction between variables 1 and 2.
    (d) None of the above.

[^59]: c. The interaction between variables 1 and 2. (probably...  although there are many schools of thought on how to build models)

---

(@) Consider variable 1 is continuous and variable 2 has 4 levels.  How many degrees of freedom are associated with the drop in deviance test (LRT) of their overall interaction?[^60]
    (a) 1
    (b) 2
    (c) 3
    (d) 4
    (e) 5

[^60]: c. 3 (1 * (4-1) = 3)

---

(@) When selecting variables, it is important that[^61]
    (a) The model predicts training data well
    (b) The model predicts test data well
    (c) The coefficients on the variables are all significant
    (d) The relationships between the variables make sense

[^61]: b. The model predicts test data well

---

(@) To get a sense of the true accuracy of the model, the test data should be assessed (for accuracy)[^62]
     a. on the first model only.
     b. on the last model only.
     c. on every model in the process.

[^62]: b. on the last model only.

---

(@) If I am using all features of my dataset and I achieve 100% accuracy on my training set, but ~70% on testing set, what should I look out for?[^63]
    (a) Underfitting
    (b) Nothing, the model is perfect
    (c) Overfitting

[^63]: c. overfitting

---

(@) If I am picking and choosing between features of my dataset and I achieve 30% accuracy on my training set, and ~30% on testing set, what should I look out for?[^64]
    (a) Underfitting
    (b) Nothing, the model is perfect
    (c) Overfitting

[^64]: a. underfitting

---

(@) Cross validating will guarantee that the model does not overfit.[^65]
    (a)	TRUE
    (b)	FALSE

[^65]: b. FALSE.  CV reduces the effect of overfitting, but at the end of the day, you are still building a model on the dataset at hand, and it is possible that you will overfit that dataet.

---

(@) Suppose we want to compute 10-Fold Cross-Validation error on 200 training examples. We need to compute a model error rate N1 times, and the Cross-Validation error is the average of the errors. To compute each error, we need to train a model with data of size N2, and test the model on the data of size N3.
What are the numbers for N1, N2, N3?[^66]
    (a) N1 = 1, N2 = 180, N3 = 20
    (b) N1 = 10, N2 = 180, N3 = 20
    (c) N1 = 10, N2 = 200, N3 = 20
    (d) N1 = 10, N2 = 200, N3 = 200
    (e) N1 = 20, N2 = 180, N3 = 20

[^66]: b. N1 = 10, N2 = 180, N3 = 20

---

(@) You are reviewing papers for Fancy Conference, and you see submissions with the following claims. Which ones would you consider accepting?[^67]
     (a) My method achieves a training error lower than all previous  methods!
     (b) My method achieves a test error lower than all previous methods! (Footnote: When variables are chosen so as to min test error.)
     (c) My method achieves a test error lower than all previous methods! (Footnote: When variables are chosen so as to min CV error.)
     (d) My method achieves a CV error lower than all previous methods! (Footnote: When variables are chosen so as to min CV error.)

[^67]: c. My method achieves a test error lower than all previous methods! (Footnote: When variables are chosen so as to min CV error.)

```{r}
#| echo: false
#| eval: false

(@) From the burn data, consider:  
$$P(\mbox{surv if } X = 0.4) = 0.3$$
$$P(\mbox{surv if } X = 0.2) = 0.9$$
The two points are concordant if[^68]
    (a)	X = 0.4 survives and X = 0.2 dies
    (b)	X = 0.4 dies and X= 0.2 survives
    (c)	They both survive
    (d)	They both die

[^68]: b. X = 0.4 dies and X= 0.2 survives
```

---

(@) Which model is better (according to ROC)?[^69]
    (a) pink because it goes closer to (1,1)
    (b) pink because it is closer to y=x
    (c) blue because it is farther from y=x
    (d) blue because it is steeper
    (e) neither

```{r}
#| echo: false

set.seed(47)
D.ex <- rbinom(50, 1, .5)
rocdata <- data.frame(D = c(D.ex, D.ex), 
                   M = c(rnorm(50, mean = D.ex/4, sd = .1), rnorm(50, mean = (D.ex+1)/4, sd = .2)), 
                   Z = c(rep("A", 50), rep("B", 50)))

ggplot(rocdata, aes(m = M, d = D, color = Z)) + geom_roc() +
  theme(legend.title = element_blank()) +
  scale_color_manual(values = c("blue", "pink")) + 
  geom_abline(slope = 1, intercept = 0)

```

[^69]: c. blue because it is farther from the line y=x

---

(@) In ROC curve, the x-axis measures[^70]
    (a) True Pos Rate which we want high
    (b) False Pos Rate which we want low
    (c) True Neg Rate which we want high
    (d) False Neg Rate which we want low

[^70]: b. False Pos Rate which we want low

---

(@) Quiz on 11 topics (you know nothing).  Your friends know topics:  
A: {1, 2, 3, 4, 5, 6, 7}  
B: {8, 9, 10}  
C: {1, 2, 3, 4, 8, 10}  
D: {5, 6, 7, 9, 11}  
Who should you choose to help you answer the questions?[^71]
    (a) A
    (b) B
    (c) C
    (d) D
    (e) can't tell

[^71]: a. A

---

(@) Who do you want to choose next?[^72]  
A: {1, 2, 3, 4, 5, 6, 7}  
B: {8, 9, 10}  
C: {1, 2, 3, 4, 8, 10}  
D: {5, 6, 7, 9, 11}  
     (a) A
     (b) B
     (c) C
     (d) D
     (e) can't tell

[^72]: b. B

---

(@) If you can pick two people, who do you pick?[^73]  
A: {1, 2, 3, 4, 5, 6, 7}   
B: {8, 9, 10}   
C: {1, 2, 3, 4, 8, 10}  
D: {5, 6, 7, 9, 11}   
     (a) A, B
     (b) A, C
     (c) A, D
     (d) C, B
     (e) C, D

[^73]:  e. C and D


---

(@) Which variable should I put in first for the forward model process?[^73a]
    (a)	`Location` 
    (b)	`No.eggs`
    (c) `Color`
    (d) `Incubate` 
    (e) `Nestling` 


[^73a]: a. Location has the largest test statistic and correspondingly smallest p-value.


---

(@) Which variable should I put in second for the forward model process?[^73b]
    (a)	`Location` 
    (b)	`No.eggs`
    (c) `Color`
    (d) `Incubate` 
    (e) `Nestling` 

[^73b]: a. `No.eggs` has the largest test statistic and correspondingly smallest p-value.

---

(@) Which variable should I remove first for the backward model process?[^73a]
    (a)	`Location` 
    (b)	`No.eggs`
    (c) `Color`
    (d) `Incubate` 
    (e) `Nestling` 


[^73a]: d. or e. Hard to say, could have removed `Incubate`, `Nestling`, or `Totcare`.  (I removed `Nestling`.)


---

(@) Which variable should I remove second for the backward model process?[^73b]
    (a)	`Location` 
    (b)	`No.eggs`
    (c) `Color`
    (d) `Incubate` 
    (e) `Nestling` 

[^73b]: c. `Color` has the smalles test statistic and correspondingly largest p-value.



---

(@) The variables in the k-variable model identified by **forward** selection are a subset of the variables in the (k+1)-variable model identified by **forward** selection.[^74]
    (a)	TRUE (always TRUE)
    (b)	FALSE (not always TRUE)

[^74]: a. TRUE

---

(@) The variables in the k-variable model identified by **backward** selection are a subset of the variables in the (k+1)-variable model identified by **backward** selection.[^75]
    (a)	TRUE (always TRUE)
    (b)	FALSE (not always TRUE)

[^75]: a. TRUE

---

(@) The variables in the k-variable model identified by **backward** selection are a subset of the variables in the (k+1)-variable model identified by **forward** selection.[^76]
    (a)	TRUE (always TRUE)
    (b)	FALSE (not always TRUE)

[^76]: b. FALSE

---

(@) The variables in the k-variable model identified by **forward** selection are a subset of the variables in the (k+1)-variable model identified by **backward** selection.[^77]
    (a)	TRUE (always TRUE)
    (b)	FALSE (not always TRUE)

[^77]: b. FALSE

---

(@) The variables in the k-variable model identified by **best-subsets** selection are a subset of the variables in the (k+1)-variable model identified by **best-subsets** selection.[^78]
    (a)	TRUE (always TRUE)
    (b)	FALSE (not always TRUE)

[^78]: b. FALSE

---

(@) In a drop-in-deviance test (LRT), the reduced model corresponds to the null hypothesis being true.[^79]
    (a) TRUE
    (b) FALSE

[^79]: a. TRUE (the coefficient values are forced to be zero)

---

(@) In a drop-in-deviance test (LRT), the full model corresponds to the alternative hypothesis being true.[^80]
     (a) TRUE
     (b) FALSE

[^80]: b. FALSE (the null model can exist within the full model because there is flexibility in the values of the coefficients)

---

(@) With model building:[^81]
    (a)	There are many ways to find a good model.
    (b)	There is always one right answer.
    (c)	There is no end to the fun.
    (d)	Can we take a pure math class yet?

[^81]: a. There are many ways to find a good model.  Also, c. there is no end to the fun.

---

(@) When probability of being able to buy a candy bar is modeled as a function of the number of coins, the coefficient on number of coins is:[^82]
     (a) positive
     (b) negative
     (c) zero
     (d) no intuition exists for being able to answer this question

[^82]: a. positive

---

(@) When probability of being able to buy a candy bar is modeled as a function of the number of low coins, the coefficient on number of low coins is:[^83]
     (a) positive
     (b) negative
     (c) zero
     (d) no intuition exists for being able to answer this question 

[^83]: a. positive

---

(@) When probability of being able to buy a candy bar is modeled as a function of the number of coins and number of low coins, the coefficient on number of coins is:[^84]
     (a) positive
     (b) negative
     (c) zero
     (d) no intuition exists for being able to answer this question

[^84]: a. positive

---

(@) When probability of being able to buy a candy bar is modeled as a function of the number of coins and number of low coins, the coefficient on number of low coins is:[^85]
     (a) positive
     (b) negative
     (c) zero
     (d) no intuition exists for being able to answer this question

[^85]: b. negative

---

(@) If we consider the censored times to be event times, the empirical survival curve will (on average)[^86]
    (a) underestimate the parameter
    (b) overestimate the parameter
    (c) sometimes under and sometimes overestimate the parameter

[^86]: a. underestimate the parameter

---

(@) $n_i - d_i = n_{i+1}$ when:[^87]
    (a) there are no deaths at time $t_i$
    (b) there is no censoring at time $t_i$
    (c) there are no deaths at time $t_{i+1}$
    (d) there is no censoring at time $t_{i+1}$
    (e) there is no censoring at time $t_{i-1}$

[^87]: b. there is no censoring at time $t_i$

---

(@) $\frac{(n_i - d_i)}{n_i} = 1$ when:[^88]
    (a) there are no deaths at time $t_i$
    (b) there is no censoring at time $t_i$
    (c) there are no deaths at time $t_{i+1}$
    (d) there is no censoring at time $t_{i+1}$
    (e) there is no censoring at time $t_{i-1}$

[^88]: a. there are no deaths at time $t_i$

---


(@) Prop survive > 50 days, `treated` (turquoise line)[^89]
    (a) ~0.65
    (b) ~0.35
    (c) ~0.45
    (d) we only know it's bigger than red
    (e) we only know it's smaller than red
    
```{r}
#| echo: false

surv_data <- data.frame(time = c(45, 35, 48, 24, 42, 52, 55, 47, 42, 74, 62, 32, 41, 69, 17),
censor = c(0,1,0,1,1,1,0,1,1,1,0,0,0,1,0), group = c("control", "control", "control", "control", "control", "control","treated", "treated", "treated", "treated","treated", "treated", "treated", "treated", "treated"))

survfit(Surv(time, censor) ~ group, data = surv_data) %>%
survminer::ggsurvplot(conf.int = FALSE)
```

[^89]: a. ~0.65


---

```{r}
#| echo: false

surv_data <- data.frame(time = c(45, 35, 48, 24, 42, 52, 55, 47, 42, 74, 62, 32, 41, 69, 17),
censor = c(0,1,0,1,1,1,0,1,1,1,0,0,0,1,0), group = c("control", "control", "control", "control", "control", "control","treated", "treated", "treated", "treated","treated", "treated", "treated", "treated", "treated"))

survfit(Surv(time, censor) ~ group, data = surv_data) %>%
survminer::ggsurvplot(conf.int = FALSE)
```

---

(@) Kaplan Meier curves (Log-Rank p-value),[^90]
    (a) blue is clearly better
    (b) red is clearly better
    (c) can't tell because they cross
    (d) can't tell because the p-value is big
    (e) can't tell because the p-value is small
    
```{r fig.height = 4}
#| echo: false

surv_data <- data.frame(time = c(45, 35, 48, 64, 42, 52, 55, 37, 42, 74, 32, 32, 41, 49, 17),
censor = c(0,1,0,1,1,1,0,1,1,1,0,0,0,1,0), group = c("control", "control", "control", "control", "control", "control","treated", "treated", "treated", "treated","treated", "treated", "treated", "treated", "treated"))

survfit(Surv(time, censor) ~ group, data = surv_data) %>%
survminer::ggsurvplot(conf.int = FALSE, pval=TRUE)
```

[^90]: c. can't tell because they cross (and also because d. the p-value is big)

---

```{r}
#| echo: false

surv_data <- data.frame(time = c(45, 35, 48, 64, 42, 52, 55, 37, 42, 74, 32, 32, 41, 49, 17),
censor = c(0,1,0,1,1,1,0,1,1,1,0,0,0,1,0), group = c("control", "control", "control", "control", "control", "control","treated", "treated", "treated", "treated","treated", "treated", "treated", "treated", "treated"))

survfit(Surv(time, censor) ~ group, data = surv_data) %>%
survminer::ggsurvplot(conf.int = FALSE, pval=TRUE)
```
---

(@) In the log-rank test, why is it okay to consider only one cell of the 2x2 table at time $t_j$?[^91]
     a. Because the row totals are fixed.
     b. Because the column totals are fixed.
     c. Because the row and column totals are fixed.
     d. Because the total number of observations is fixed.

[^91]: c. Because the row and column totals are fixed.

---

(@) What does it mean for the log rank test to be more powerful than the Wilcoxon test?[^92]
    a. log rank is more likely to reject $H_0$ when $H_0$ is true.
    b. log rank is more likely to reject $H_0$ when $H_0$ is false.
    c. log rank is less likely to reject $H_0$ when $H_0$ is true.
    d. log rank is less likely to reject $H_0$ when $H_0$ is false.

[^92]: b. log rank is more likely to reject $H_0$ when $H_0$ is false.

---

(@) The hazard at time $t$ represents:[^93]
    (a) the probability of the event
    (b) the instantaneous rate of the event
    (c) the relative risk of the event
    (d) the odds ratio of the event
    
[^93]: b. the instantaneous rate of the event

---

(@) The last entry in the table for the h(t) column is `NA` because:[^94]
    (a) the last observation was a death
    (b) the last observation was censored
    (c) the time interval is too big
    (d) the time interval is too small
    
```{r fig.cap = "Table 9.6  [@KuiperSklar]", out.width='100%', fig.align='center', echo=FALSE}
knitr::include_graphics("handout/figs/hazard_NA.jpg")
```

[^94]: b. the last observation was censored.  The reason the hazard is zero is because the width of the time interval is unknown, that is we don't know when the last event time is.

---


(@) Censored observations are$\ldots$?[^95]
    (a) More important than non-censored ones in survival analysis
    (b) Are assumed to be normally distributed over time
    (c) Are assumed to have the same survival chances as uncensored observations
    (d) Are essential to allow calculation of the Kaplan Meier plot
    (e) Are allocated to the baseline survival curve

[^95]: c. Are assumed to have the same survival chances as uncensored observations


---

(@) Survival Analysis: for a one unit change of an explanatory variable, the corresponding coefficient $e^\beta$ represents:[^96]
    (a) baseline survival
    (b) survival ratio
    (c) baseline hazard
    (d) hazard ratio

[^96]: d. hazard ratio

---

(@) In survival analysis, the closest interpretation of the value $e^\beta$ is:[^97]
    (a) odds
    (b) probability
    (c) time to event
    (d) relative risk
    (e) odds ratio

[^97]: d. relative risk

---

(@) Let the event be death.  If larger values of the explanatory variable are associated with higher likelihood of survival, the coefficient $(\beta)$ should be [^98]
    (a) bigger than 1
    (b) smaller than 1
    (c) positive
    (d) negative
    (e) zero

[^98]: d. negative

---

(@) Let the event be death.  If larger values of the variable are NOT associated with higher (or lower) likelihood of survival, the coefficient $(\beta)$ should be[^99]
    (a) bigger than 1
    (b) smaller than 1
    (c) positive
    (d) negative
    (e) zero

[^99]: e. zero

---

(@) BP violates the "linear HR" condition if:[^100]
     (a) the ln ratio of the hazard curves is not linear with respect to BP
     (b) the ln ratio of the survival curves is not linear with respect to BP
     (c) the effect of BP is to increase the hazard
     (d) the effect of BP is to decrease the hazard
     (e) there is no effect due to BP

[^100]: a. the ln ratio of the hazard curves is not linear with respect to BP

---

(@) A Cox regression analysis:[^101]
      (a) Is used to analyze survival data when individuals in the study are followed for varying lengths of time.
      (b) Can only be used when there are censored data
      (c) Assumes that the relative hazard for a particular variable is always constant 
      (d) Uses the logrank statistic to compare two survival curves
      (e) Relies on the condition that the explanatory variables (covariates) in the model are normally distributed.

[^101]: a. Is used to analyze survival data when individuals in the study are followed for varying lengths of time. **and** c. Assumes that the relative hazard for a particular variable is always constant 

---

(@) The effect of weight could violate PH if:[^102]
     (a) people of different weights are in control vs treatment group
     (b) people tend to weigh less over time
     (c) the hazard function for weight is not monotonic
     (d) the hazard function changes as a function of weight which is also changing over time

[^102]: d. the hazard function changes as a function of weight which is also changing over time

---

(@) The effect of treatment could violate PH if:[^103]
     (a) the treatment has no effect
     (b) the treatment produces short term benefits only
     (c) the treatment effect interacts with a different variable, like gender
     (d) there is more than one treatment group

[^103]: b. the treatment produces short term benefits only

---

(@) AIC, BIC, model validation, and stepwise regression are methods for[^104]
      a. parameter estimation 
      b. variable selection

[^104]: b. variable selection

---

(@) If $\alpha = 0.05$, I would expect 5% of all hypotheses to be rejected.[^105]
     (a) TRUE
     (b) FALSE

[^105]: b. FALSE, we'd expect 5% of all null hypotheses to be rejected

---

(@) Power is:[^106]
      (a) P(type I error)
      (b) P(type II error)
      (c) 1 – P(type I error)
      (d) 1 – P(type II error)
      
type I = $H_0$ true, but we reject  
type II = $H_0$ false, but we fail to reject  
power = P(rejecting when $H_0$ false)  

[^106]: d. 1 – P(type II error)

---

(@) The p-value is[^107]
     (a) P($H_0$ is true | data)
     (b) P($H_a$ is true | data)
     (c) P(data | $H_0$ is true)
     (d) P(data | $H_a$ is true)
     (e) 1 – P(data | $H_0$ is true)

[^107]: c. P(data | $H_0$ is true)

---

RA Fisher (1929)
>"... An observation is judged significant, if it would rarely have been produced, in the absence of a real cause of the kind we are seeking. **It is a common practice to judge a result significant, if it is of such a magnitude that it would have been produced by chance not more frequently than once in twenty trials. This is an arbitrary, but convenient, level of significance for the practical investigator, but it does not mean that he allows himself to be deceived once in every twenty experiments.** The test of significance only tells him what to ignore, namely all experiments in which significant results are not obtained. He should only claim that a phenomenon is experimentally demonstrable when he knows how to design an experiment so that it will rarely fail to give a significant result. Consequently, isolated significant results which he does not know how to reproduce are left in suspense pending further investigation."

---

(@) For hypothesis testing, the problem of multiple comparisons (also known as the multiple testing problem) results from the increase in ________ that occurs when statistical tests are used repeatedly.[^108]
     (a) Type I errors 
     (b) Type II errors 
     (c) Null hypothesis
     (d) Statistical hypothesis testing

[^108]: a. Type I errors

---

(@) If $H_0$ is true, the p-values should be distributed:[^109]
     (a) Uniformly (equal prob) on 0  to 1 
     (b) Uniformly on -1 to 1
     (c) Unimodal on 0 to 1
     (d) Skewed left on 0 to 1
     (e) Skewed right on 0 to 1

[^109]: a. Uniformly (equal prob) on 0  to 1

---

(@) Given many many tests (presumably some are null and some are "true"), a good estimate of the number of null tests is:[^110]
     (a) (# p-values > 0.5) / 2
     (b) (# p-values > 0.5) * 2
     (c) (# p-values < 0.5) / 2
     (d) (# p-values < 0.5) * 2

[^110]: b. (# p-values > 0.5) * 2

---

(@) What do I do if the adjusted p-value is bigger than 1?[^111]
     (a) Leave it unadjusted
     (b) Assign the value of the previous (“smaller”) p-value
     (c) Round it to 1
     (d) Divide by 2

[^111]: c. Round it to 1

---

(@) With Holm’s method, what do I do if the (m+1)^th adjusted p-value is smaller than the m^th adjusted p-value?[^112]
     (a) Leave it unadjusted
     (b) Assign the value of the m^th adjusted p-value to the (m+1)^th adjusted p-value
     (c) Round it to 1
     (d) Divide by 2

[^112]: b. Assign the value of the m^th adjusted p-value to the (m+1)^th adjusted p-value

---

(@) The false discovery rate represents[^113]
     (a) the proportion of true discoveries out of the total tests
     (b) the proportion of true discoveries out of the total discoveries
     (c) the ratio of the number of true discoveries divided by the number of null discoveries
     (d) the number of null discoveries out of the total tests
     (e) the number of null discoveries out of the total discoveries

[^113]: e. the number of null discoveries out of the total discoveries

---

(@) FDR and FWER differ in that[^114]
     (a) FDR is a rate and FWER is a probability
     (b) FDR controls the rate of false positives
     (c) FWER controls the probability of getting a false positive
     (d) some of the above
     (e) all of the above

[^114]: e. all of the above

---

(@) Which multiple comparisons adjustment gives the highest power?[^115]
     (a) Bonferonni
     (b) Holm
     (c) Benjamini-Hochberg
     (d) Storey (q-values)

[^115]: d. Storey (q-values)

---









